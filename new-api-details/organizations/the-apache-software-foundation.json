{
  "id": "692251e953dd9d7326d33ecc",
  "slug": "the-apache-software-foundation",
  "name": "The Apache Software Foundation",
  "category": "Web",
  "description": "Open source software to the public free of charge",
  "image_url": "https://summerofcode.withgoogle.com/media/org/apache-software-foundation/hq22fwtmvdfjnsh9-360.png",
  "img_r2_url": "https://pub-268c3a1efc8b4f8a99115507a760ca14.r2.dev/the-apache-software-foundation.webp",
  "logo_r2_url": null,
  "url": "https://apache.org",
  "active_years": [
    2016,
    2017,
    2018,
    2019,
    2020,
    2021,
    2022,
    2023,
    2024,
    2025
  ],
  "first_year": 2016,
  "last_year": 2025,
  "is_currently_active": true,
  "technologies": [
    "python",
    "javascript",
    "java",
    "ruby",
    "couchdb",
    "c",
    "erlang",
    "c++",
    "rust"
  ],
  "topics": [
    "web",
    "database",
    "cloud",
    "ddd",
    "dsl",
    "big data",
    "libraries",
    "other"
  ],
  "total_projects": 248,
  "stats": {
    "avg_projects_per_appeared_year": 24.8,
    "projects_by_year": {
      "year_2016": 35,
      "year_2017": 23,
      "year_2018": 23,
      "year_2019": 17,
      "year_2020": 17,
      "year_2021": 28,
      "year_2022": 33,
      "year_2023": 25,
      "year_2024": 20,
      "year_2025": 27
    },
    "students_by_year": {
      "year_2016": 35,
      "year_2017": 23,
      "year_2018": 23,
      "year_2019": 17,
      "year_2020": 17,
      "year_2021": 28,
      "year_2022": 33,
      "year_2023": 25,
      "year_2024": 20,
      "year_2025": 27
    },
    "total_students": 238
  },
  "years": {
    "year_2016": {
      "num_projects": 35,
      "projects": [
        {
          "code_url": "http://haonguyen123.blogspot.com/2016/08/mapping-between-geotiff-metadata-to-iso-19115.html",
          "description": "<p>The goal of this project is to improve the Apache SIS coverage module in order to meet the needs of space agencies. Particularly, this includes translate the formats GeoTIFF metadata to ISO 19115  , and creating a simple applycation web prototype (VNSC)  to ensure the module is on the right track</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6447441695997952/",
          "proposal_id": null,
          "short_description": "The goal of this project is to improve the Apache SIS coverage module in order to meet the needs of space agencies. Particularly, this includes...",
          "slug": "mapping-between-the-geotiff-metadata-to-iso-19115",
          "status": "completed",
          "student_name": "haonguyen",
          "student_profile": null,
          "tags": [
            "web"
          ],
          "title": "Mapping between the GeoTIFF metadata to ISO 19115"
        },
        {
          "code_url": "https://github.com/bsikander/GSoC-16",
          "description": "<p>Distributed system performance benchmarks are an important source of information for decision makers who must choose the right technology for their next compute or data intensive problems. Since, important decisions rely on trustworthy experimental data, so a benchmark of Apache Hama with other available systems might prove to get additional attention by big data community. After working on Hama last year, I know its capabilities and where it stands in comparison to other in-memory distributed systems. Yet lack of experimental results makes it hard to convince data engineers to move to Hama. So for this year's GSoC, I am planning to do a performance benchmark against Apache Spark and Flink. In addition to this, I will contribute to multiple Jira tickets that are in open or pending status for quite some time.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6604885264957440/",
          "proposal_id": null,
          "short_description": "Distributed system performance benchmarks are an important source of information for decision makers who must choose the right technology for their...",
          "slug": "apache-hama-benchmark-against-spark-and-flink",
          "status": "completed",
          "student_name": "bsikander",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Apache Hama benchmark against Spark and Flink"
        },
        {
          "code_url": "https://github.com/apache/incubator-taverna-common-activities/commits/docker?author=NadeeshDilanga",
          "description": "<p>Taverna is a comprehensive workflow engine which has several ways of creating work flows and there are multiple layers/interfaces exposed to interact with the workflows, such as desktop workbench, command line tool, web interactions through a dedicated Taverna server which expose REST/SOAP interfaces.</p>\n<p>When creating workflows, there can be various use cases to talk to external environments/systems and execute/pull information from them. OSGi based Taverna core platform provides plugins architecture to install custom plugins in ad hoc manner. This project is basically about creating a new Taverna activity plugin for Docker.  With this feature, Taverna users will be able to invoke/run docker images inside their workflows.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6625717198520320/",
          "proposal_id": null,
          "short_description": "Taverna is a comprehensive workflow engine which has several ways of creating work flows and there are multiple layers/interfaces exposed to interact...",
          "slug": "running-docker-from-apache-taverna",
          "status": "completed",
          "student_name": "nadeesh092",
          "student_profile": null,
          "tags": [
            "web",
            "docker"
          ],
          "title": "Running Docker from Apache Taverna"
        },
        {
          "code_url": "https://allura.apache.org/posts/2016-gsoc-16.html",
          "description": "<h3>Improving Discussion Threads and UI/UX of Apache Allura</h3>\n<h4>Goals</h4>\n<ul>\n<li>Improve Discussion Threads (ForgeDiscussion) </li>\n<li>Improve landing page on installation and general UI improvements and UX bug fixes (Allura)</li>\n<li>Implementing a Mobile Web View similar to GitHub</li>\n</ul>\n<h4>Brief Points</h4>\n<ul>\n<li>Implement async loading of comments and allow them to be paginated.  </li>\n<li>Improve emails sent out by the platform, look into how to integrate them with email clients like done by GitHub.</li>\n<li>Improve viewing attachments, allow embedding some types of attachments. Preview feature.</li>\n<li>Extend the models in the threads to allow voting(express +1, LGTM etc.) on individual comments. Add support for emoji.</li>\n<li>Improve the landing page of Forge.</li>\n<li>Implement a separate Mobile Web View, this involves extending the API and creating new views specifically for mobile web browsers.</li>\n</ul>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6641326720286720/",
          "proposal_id": null,
          "short_description": "Improving Discussion Threads and UI/UX of Apache Allura\nGoals\n\nImprove Discussion Threads (ForgeDiscussion) \nImprove landing page on installation and...",
          "slug": "improving-discussion-threads-and-uiux-of-apache-allura",
          "status": "completed",
          "student_name": "rhnvrm",
          "student_profile": null,
          "tags": [
            "web",
            "mobile",
            "api",
            "ai",
            "ui"
          ],
          "title": "Improving Discussion Threads and UI/UX of Apache Allura"
        },
        {
          "code_url": "https://github.com/apache/airavata-sandbox/tree/master/Interacting_with_Airavata_using_ipython_Notebook",
          "description": "<p>My primary goal with this project is to build a notebook­ front ends so users can interact with weather data. As an initial goal, I will work with Apache Airavata community to build a data pipeline to perform Extract-­Transform-­Load (ETL). I was inspired by the ZEPPELIN-684 idea but eventually got drifted into a concrete suggestion from Apache Airavata.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6665478663569408/",
          "proposal_id": null,
          "short_description": "My primary goal with this project is to build a notebook­ front ends so users can interact with weather data. As an initial goal, I will work with...",
          "slug": "notebooks-for-weather-data-analytics",
          "status": "completed",
          "student_name": "Pradyut",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Notebooks for Weather Data Analytics"
        },
        {
          "code_url": "https://gist.github.com/NgesBrian/3e4521c0228f6c635e7b69318f38dccb",
          "description": "<p>This Project is based on testing.\nThe aim of this project is to have a white box and regression test carried out on the mynewt os.\nThis is very important for the operating system especially at this time of the development stage where there have been a rapid growth in the development of the OS.\nIf given the opportunity to execute this project, I am going to make sure the project sees completion within the time bound of the Summer of Code program.\nAlso I make sure I give it the to have a qualitative and a quantitative output</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6741911901569024/",
          "proposal_id": null,
          "short_description": "This Project is based on testing.\nThe aim of this project is to have a white box and regression test carried out on the mynewt os.\nThis is very...",
          "slug": "white-box-and-regression-testing-of-the-mynewt-os",
          "status": "completed",
          "student_name": "Nges Brian",
          "student_profile": null,
          "tags": [
            "api",
            "ai"
          ],
          "title": "White Box and Regression Testing of the Mynewt OS"
        },
        {
          "code_url": "https://gist.github.com/SanjeewaUoM/93e80f116e6fc878b31d771ecc2104d8",
          "description": "<p>Apache Mynewt OS is a rapidly developing operating system specially designed for 32-bit microcontrollers. With the development of IoT, embedded system will play a critical role. Power, memory, storage, efficiency will play some crucial role there. Currently Mynewt OS supports  ST Micro’s STM32 (BSTM32F3DISCOVERY board), Nordic nRF52 (nRF52 Development Kit), Atmel's SAMD21(Arduino Zero board). In all above MCUs are based on ARM architecture.\nIn my approach, after discussing with the community we have decided to create a port for PIC32MX270F256D MCU (PIC32 Bluetooth Starter Kit).</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5683813690638336/",
          "proposal_id": null,
          "short_description": "Apache Mynewt OS is a rapidly developing operating system specially designed for 32-bit microcontrollers. With the development of IoT, embedded...",
          "slug": "port-core-os-and-a-subset-of-the-utilities-to-a-new-32-bit-microcontroller",
          "status": "completed",
          "student_name": "Pradeep Sanjeewa",
          "student_profile": null,
          "tags": [
            "api",
            "ui"
          ],
          "title": "Port core OS and a subset of the utilities to a new 32-bit microcontroller"
        },
        {
          "code_url": "http://maanadevgsoc2016.blogspot.com/2016/08/final-evaluation.html",
          "description": "<p>The Taverna suite is consist of Taverna Engine, which handles both Taverna Workbench and\nthe Taverna Server. Taverna Server is used to execute remote workflows and workbench\nprovides GUI for create, run, import workflows.​This concept allow scientists who has limited\nknowledge in computing, limited technical resources to do complex process on Data. Also\nTaverna engine can be run on standard Windows, Linux or Mac OS.\nAt the moment Taverna workflows are constructed using SCULF2 API. So, Tavera Engine can’t\nexecute other workflows other than Taverna workflows. This is where CWL comes in ,The\nCommon Workflow Language (CWL)​. ​CWL allows one description of a workflow to be run on\nmultiple different platforms as long as they all support CWL. \" CWL builds on technologies such\nas JSON­LD and Avro for data modeling and Docker for portable runtime environments \".\nThe project mission is to bring CWL UI support in the Workbench which\nis a graphical way to build workflows and one of the steps in Add Common Workflow Language\nsupport to Taverna.</p>\n",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2016_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5397810476220416/",
          "proposal_id": null,
          "short_description": "The Taverna suite is consist of Taverna Engine, which handles both Taverna Workbench and\nthe Taverna Server. Taverna Server is used to execute remote...",
          "slug": "taverna-880-browseuse-cwl-tool-descriptions",
          "status": "completed",
          "student_name": "Thilina Manamgoda",
          "student_profile": null,
          "tags": [
            "api",
            "docker",
            "ui",
            "ux"
          ],
          "title": "TAVERNA-880 Browse+use CWL tool descriptions"
        },
        {
          "code_url": "https://gist.github.com/kdmu/55b14b7b4e1b8749fa9194bc5fa7da8c",
          "description": "<p>Apache Cassandra provides different operations which involves streaming within different nodes and data centers like bootstrap, rebuild, decommission and so on. These operation are not resumable, in case of failure we have to transfer again all data. \nSuppose in a hypothetical scenario that one user performs a operation which may take one day to be completed, if some error occurred,  he will need to restart all the process which means a waste that could be saved if such operation is resumable. Therefore in this project we aims to implement rebuild operations resumable. If time allows, we will also try to make other operation resumable.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5429448547500032/",
          "proposal_id": null,
          "short_description": "Apache Cassandra provides different operations which involves streaming within different nodes and data centers like bootstrap, rebuild, decommission...",
          "slug": "apache-cassandra-make-streaming-operations-resumable",
          "status": "completed",
          "student_name": "Kaide Mu",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Apache Cassandra: Make streaming operations resumable"
        },
        {
          "code_url": "http://blog.tusharmishra.in/?p=197",
          "description": "<p>The SYNCOPE-809 feature request points out the lack of a plugin for IDEs to allow users to create and edit mail templates and report stylesheets in the IDE itself instead of doing so using their dashboard. The feature request also provides a sample layout for the plugin where the mail and report templates are listed in a tree layout and made available for the user to view, edit and create new ones. The aim of this project will be to build a plugin that will solve the aforementioned problem and host it on the server so that end users can easily access and install the plugin on their own installation of eclipse and deployment of syncope.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5478022748569600/",
          "proposal_id": null,
          "short_description": "The SYNCOPE-809 feature request points out the lack of a plugin for IDEs to allow users to create and edit mail templates and report stylesheets in...",
          "slug": "apache-syncope-809",
          "status": "completed",
          "student_name": "Tushar",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Apache SYNCOPE-809"
        },
        {
          "code_url": "http://janakact.blogspot.com/2016/08/gsoc-2016-add-mongodb-to-tajo-storage.html",
          "description": "<p>Apache Tajo currently embeds HDFS, S3, Openstack, HBase, RDBMS storage plugins, so users can connect those data sources to Apache Tajo. The project is to add a MongoDB storage plugin to tajo-storage so users can connect MongoDB to Tajo. Implementing the new module tajo-storage-mongodb (storage plugin for MongoDB) will be the major part of the project.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_011",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5515426813444096/",
          "proposal_id": null,
          "short_description": "Apache Tajo currently embeds HDFS, S3, Openstack, HBase, RDBMS storage plugins, so users can connect those data sources to Apache Tajo. The project...",
          "slug": "add-mongodb-to-tajo-storage",
          "status": "completed",
          "student_name": "Janaka",
          "student_profile": null,
          "tags": [],
          "title": "Add MongoDB to Tajo Storage"
        },
        {
          "code_url": "https://github.com/kebertx/crimgeoprofile",
          "description": "<p>We aim to construct a probabilistic model which explains a hypothetical\ncriminal's behavior based on that criminal's actions. We will be given the\ncriminal's motions and the crimes they have committed, and from this, we will try\nto find a probabilistic model that explains their behavior. We are planning to\nconstruct a Hidden Markov Model, which is a probabilistic system describing the\ntransitions between the criminal's actions.</p>\n<p>Treating the criminal's decisions about what locations to go to, and which\ncrimes to commit, as the result of a Markov process, we can use statistical\nmethods to reconstruct a model that predicts their behavior. For this project\nwill use a simulated criminal whose actions are generated by an agent-based\nmodel (resulting from a previous GSoC project). We should be able to create a\nmodel that is nearly equivalent to the original program. With the reconstructed\nmodel, the program should be able to make predictions about the criminal's\nfuture actions.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_012",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6146525818257408/",
          "proposal_id": null,
          "short_description": "We aim to construct a probabilistic model which explains a hypothetical\ncriminal's behavior based on that criminal's actions. We will be given the...",
          "slug": "predicting-criminal-moments-with-hidden-markov-models",
          "status": "completed",
          "student_name": "kebertx",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Predicting Criminal Moments with Hidden Markov Models"
        },
        {
          "code_url": "https://github.com/davarresc/nuxeo-manifold-connector",
          "description": "<h3>Nuxeo repository and Authority connector for Apache ManifoldCF</h3>\n<p>Nowadays, there are many containers of information, each one is specialized in a different approach, such as Nuxeo. This makes many companies have their information distributed in multiple repositories, making it difficult to relate all off it and this causes that may have redundant information.</p>\n<p>Manifold native connector that support Nuxeo, will allow many companies to use this powerful framework to connect Nuxeo with others repositories and centralize their information, as I have been looking at the mailing list and CMIS connector there is problematic for some cases and certain tasks, so a native connector would be better.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_013",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5250916420681728/",
          "proposal_id": null,
          "short_description": "Nuxeo repository and Authority connector for Apache ManifoldCF\nNowadays, there are many containers of information, each one is specialized in a...",
          "slug": "nuxeo-repository-and-authority-connector-for-apache-manifoldcf",
          "status": "completed",
          "student_name": "Davarresc",
          "student_profile": null,
          "tags": [
            "ai",
            "ux"
          ],
          "title": "Nuxeo repository and Authority connector for Apache ManifoldCF"
        },
        {
          "code_url": "https://mail-archives.apache.org/mod_mbox/brooklyn-dev/201608.mbox/%3C5472759B-2FB5-4B49-ADF9-3A45DB645CD9%40lcc.uma.es%3E",
          "description": "<p>The Apache open-source-project <a href=\"https://brooklyn.apache.org/\" target=\"_blank\">Brooklyn</a> is a multi- cloud application management platform. Brooklyn can manage the provisioning and deployment of cloud applications, can monitor applications’ health and metrics, and handle the dependencies between components. It enables cross-computing features through a unified API built over <a href=\"https://jclouds.apache.org/\" target=\"_blank\">jClouds</a> to manage IaaS services offered by various providers. The tool offers a REST API and a GUI that enables a single-click deployment of applications across multiple machines, locations and clouds.</p>\n<p>As it was aforementioned, Brooklyn provides an API for the management of IaaS cloud services and ssh resources for a great number of providers and establishes a lifecycle for the management of services and applications. This project propose to extend this API with facilities for the management of PaaS offerings such as <a href=\"https://cloud.google.com/appengine/docs\" target=\"_blank\">Google App Engine</a>, <a href=\"http://aws.amazon.com/\" target=\"_blank\">AWS services</a>, <a href=\"https://www.heroku.com/\" target=\"_blank\">Heroku</a>, <a href=\"https://www.cloudfoundry.org/\" target=\"_blank\">CloudFoundry</a> (such as <a href=\"https://run.pivotal.io/\" target=\"_blank\">Pivotal</a> or <a href=\"https://console.ng.bluemix.net/\" target=\"_blank\">Bluemix</a>) , <a href=\"https://www.openshift.com/\" target=\"_blank\">Openshift</a>, etc., providing an homogeneous access to IaaS and PaaS services. Moreover, it opens up some interesting proposal such as adding new technologies support, e.g., Python, PHP and adding new management policies in order to take advantage of PaaS features.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_014",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5559741749133312/",
          "proposal_id": null,
          "short_description": "The Apache open-source-project Brooklyn is a multi- cloud application management platform. Brooklyn can manage the provisioning and deployment of...",
          "slug": "adding-paas-support-to-brooklyn",
          "status": "completed",
          "student_name": "Jose Carrasco Mora",
          "student_profile": null,
          "tags": [
            "python",
            "api",
            "cloud",
            "ui"
          ],
          "title": "Adding PaaS support to Brooklyn"
        },
        {
          "code_url": "https://github.com/meta-coder/incubator-fineract/commits/upi-sdk?author=meta-coder",
          "description": "<p>Apache Fineract is an open source system for core banking as a platform.</p>\n<p>The National Payments Corporation of India (NPCI) recently proposed an Unified Payments Interface by releasing its API and technical specification.</p>\n<p>To allow Fineract users to better integrate into India's financial landscape it is proposed that UPI be implemented as a possible connector to the Fineract platform. The solution is twofold:</p>\n<ol>\n<li>A simple Java SDK to wrap needed message and data mapping</li>\n<li>Integration into the transaction API</li>\n</ol>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_015",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5563761838522368/",
          "proposal_id": null,
          "short_description": "Apache Fineract is an open source system for core banking as a platform.\nThe National Payments Corporation of India (NPCI) recently proposed an...",
          "slug": "fineract-implement-integration-for-unified-payments-interface",
          "status": "completed",
          "student_name": "meta-coder",
          "student_profile": null,
          "tags": [
            "java",
            "api"
          ],
          "title": "Fineract: Implement integration for Unified Payments Interface"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/CLIMATE/Create+data+source+input+for+NASA+JPL+PO.DAAC",
          "description": "<p>Physical Oceanography Distributed Active Archive Center(PO.DAAC) at NASA Jet Propulsion Laboratory has a web API enabling efficient machine-to-machine communication and data transfers. This project is aimed at implementing a python API to interact with PO.DAAC and access the data by interacting with the RESTful web services provided by PO.DAAC’s API, which thereafter will be integrated with the Apache Open Climate Workbench. The Apache Open Climate Workbench(OCW) project has already got support for using RCMES and local datasets for data analysis and plotting. With ESGF data source support on its way this project will be a new milestone for OCW for Climate Model Evaluation.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_016",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6191933286252544/",
          "proposal_id": null,
          "short_description": "Physical Oceanography Distributed Active Archive Center(PO.DAAC) at NASA Jet Propulsion Laboratory has a web API enabling efficient...",
          "slug": "implementing-a-python-utility-library-for-accessing-podaac-nasa-jpl",
          "status": "completed",
          "student_name": "Omkar Reddy",
          "student_profile": null,
          "tags": [
            "python",
            "web",
            "api",
            "ai"
          ],
          "title": "Implementing a Python Utility Library for accessing PO.DAAC NASA JPL"
        },
        {
          "code_url": "https://github.com/anish18sun/Zeppelin-Notebooks",
          "description": "<p>The proposal outlines the work done in investigating about the project and the approach that will be taken to accomplish the goals laid down by the Zeppelin community. The proposal was prepared after researching about emerging data sets and the ways in which they could be analyzed to showcase the capabilities of Zeppelin with the added advantage of using a pluggable tool called Helium to provide custom visualizations and enhancements to the analysis of data in notebooks.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_017",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6203504733454336/",
          "proposal_id": null,
          "short_description": "The proposal outlines the work done in investigating about the project and the approach that will be taken to accomplish the goals laid down by the...",
          "slug": "zeppelin-notebooks",
          "status": "completed",
          "student_name": "anish18sun",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Zeppelin Notebooks"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/GORA/Apache+CouchDB+Datastore+Implementation+%28GORA-437%29+Reports",
          "description": "<p>Apache Gora open source framework provides an in-memory data model and persistence for big data. Gora supports persisting to column stores, key value stores, document stores and RDBMSs, and analyzing the data with extensive Apache Hadoop MapReduce support. \nApache CouchDB is a document-oriented NoSQL database that uses JSON to store data, JavaScript as its query language using MapReduce, and HTTP for an API.</p>\n<p>It could be nice to support CouchDB as a datastore at Gora.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_018",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/4520211218694144/",
          "proposal_id": null,
          "short_description": "Apache Gora open source framework provides an in-memory data model and persistence for big data. Gora supports persisting to column stores, key value...",
          "slug": "apache-couchdb-datastore-implementation-for-apache-gora",
          "status": "completed",
          "student_name": "cihad guzel",
          "student_profile": null,
          "tags": [
            "java",
            "javascript",
            "api",
            "database"
          ],
          "title": "Apache CouchDB datastore implementation for Apache GORA"
        },
        {
          "code_url": "http://mail-archives.apache.org/mod_mbox/vxquery-dev/201608.mbox/%3CCAOg5xaAiEV7bScgTLsYJAiGfQmxd1Ct8En9bXPiQfdaOuMxTRQ%40mail.gmail.com%3E",
          "description": "<p>The wide use of XML for document management and data exchange has created the need to query large repositories of XML data. Apache VXQuery is implemented to efficiently query such large data collections and take advantage of parallelism. The system builds upon two other open-source frameworks -- Hyracks, a parallel execution engine, and Algebricks, a language agnostic compiler toolbox. Apache VXQuery extends these two frameworks and provides an implementation of the XQuery specifics.\nThe main idea of the project is to integrate Lucene indexing to the VXQuery system. It already has some capabilities of Lucene such as,  Create a Lucene index from an XML file and execute a query by using that index. This project is to fully integrate the Lucene and extend the indexing capabilities of the system. Such as, enabling queries to dynamically select to use indexing at run time,  extend indexing for HDFS folders, allow updates to collection indexes (when Adding/Deleting/Modifying XML files).</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_019",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/4595108200579072/",
          "proposal_id": null,
          "short_description": "The wide use of XML for document management and data exchange has created the need to query large repositories of XML data. Apache VXQuery is...",
          "slug": "apache-vxquery-fully-integrate-lucene-indexing-into-vxquery",
          "status": "completed",
          "student_name": "Menaka",
          "student_profile": null,
          "tags": [
            "ml",
            "ai",
            "ui"
          ],
          "title": "Apache VXQuery - Fully integrate Lucene Indexing into VXQuery"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/OPENMEETINGS/%5BGSOC+2016%5D+webrtc+implementation",
          "description": "<p>My goal is to bring webRTC to Apache Open Meetings. These include adding features for\nSCTP protocol for signaling and change scheme for sharing video from central server to\np2p.\n<a href=\"https://issues.apache.org/jira/browse/OPENMEETINGS-1353\" target=\"_blank\">https://issues.apache.org/jira/browse/OPENMEETINGS-1353</a>\n<a href=\"https://issues.apache.org/jira/browse/OPENMEETINGS-1178\" target=\"_blank\">https://issues.apache.org/jira/browse/OPENMEETINGS-1178</a></p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_020",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/4660948707049472/",
          "proposal_id": null,
          "short_description": "My goal is to bring webRTC to Apache Open Meetings. These include adding features for\nSCTP protocol for signaling and change scheme for sharing video...",
          "slug": "proposal-for-apache-open-meetings-openmeetings-1353",
          "status": "completed",
          "student_name": "Dmitry.Bezheckov",
          "student_profile": null,
          "tags": [
            "web"
          ],
          "title": "Proposal for Apache Open Meetings: OPENMEETINGS-1353"
        },
        {
          "code_url": "https://onkarshedge.github.io/gsoc2016/",
          "description": "<p>Zeppelin has implementations for storing notebook in local filesystem, local Git repository, S3 and Azure. The idea of this project is to add storage using P2P protocols like IPFS, dat , Zeronet or Bittorrent. Hence supporting versioning and allowing users to share their notebooks easily.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_021",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/4708984158158848/",
          "proposal_id": null,
          "short_description": "Zeppelin has implementations for storing notebook in local filesystem, local Git repository, S3 and Azure. The idea of this project is to add storage...",
          "slug": "zeppelin-notebook-storage-using-p2p-protocol",
          "status": "completed",
          "student_name": "OnkarShedge",
          "student_profile": null,
          "tags": [],
          "title": "Zeppelin Notebook Storage using P2P protocol"
        },
        {
          "code_url": "https://docs.google.com/document/d/1f8IiMjrzQbCYd4oa1Tl7DUrFBwnXUn_ER6gP1aDG2aM/edit?usp=sharing",
          "description": "<p>Apache Derby is a Realational Database Management System that is implemented entirely in java. The Derby JIRA has collected the community's knowledge about known bugs in Derby. The main goal of this project, Derby bug fixing is to fix as many of the known open bugs as possible and contribute towards a more stable version of Apache Derby.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_022",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/4811187468369920/",
          "proposal_id": null,
          "short_description": "Apache Derby is a Realational Database Management System that is implemented entirely in java. The Derby JIRA has collected the community's knowledge...",
          "slug": "derby-bug-fixing",
          "status": "completed",
          "student_name": "Danoja",
          "student_profile": null,
          "tags": [
            "java",
            "ai",
            "database"
          ],
          "title": "Derby bug Fixing"
        },
        {
          "code_url": "https://github.com/apache/climate/commits/master?author=jarifibrahim",
          "description": "<p>The Open Climate Workbench (OCW) project has basic unit test coverage in the form of a test suite written using the nose framework. In order to improve test coverage, functionality and quality of tests the test framework should be updated. OCW would greatly benefit from a continuous integration (CI) infrastructure and automated test environment with a focus on large scale integration testing of climate model analysis. The current testing  makes the process of new code integration tedious and manual with potential regressions going unnoticed, this can lead to bugs and backwards incompatibility. This GSoC project proposes to build an improved test framework (smoke tests and unit tests) and set up continuous integration tools.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_023",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6547556846796800/",
          "proposal_id": null,
          "short_description": "The Open Climate Workbench (OCW) project has basic unit test coverage in the form of a test suite written using the nose framework. In order to...",
          "slug": "smoke-tests-and-continuous-integration-infrastructure-for-apache-open-climate-workbench",
          "status": "completed",
          "student_name": "Ibrahim Jarif",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "Smoke Tests and Continuous Integration Infrastructure for Apache Open Climate Workbench"
        },
        {
          "code_url": "https://wiki.apache.org/nutch/GoogleSummerOfCode/SecurityLayer",
          "description": "<p>Apache Nutch is a highly extensible and scalable open source web crawler software project. Stemming from Apache Lucene, the project has diversified and now comprises two codebases, namely: \nNutch 1.x and Nutch 2.x. \nThis proposal aims to develop a security layer for Nutch 2.x</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_024",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6555348454342656/",
          "proposal_id": null,
          "short_description": "Apache Nutch is a highly extensible and scalable open source web crawler software project. Stemming from Apache Lucene, the project has diversified...",
          "slug": "security-layer-for-nutchserver-nutch-1756",
          "status": "completed",
          "student_name": "Furkan KAMACI",
          "student_profile": null,
          "tags": [
            "web",
            "ai"
          ],
          "title": "Security Layer for NutchServer (NUTCH-1756)"
        },
        {
          "code_url": "https://github.com/apache/gora/commits/master?author=djkevincr",
          "description": "<p>JCache DataStore implementation for Apache Gora using Hazelcast JCache provider.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_025",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/4849721646514176/",
          "proposal_id": null,
          "short_description": "JCache DataStore implementation for Apache Gora using Hazelcast JCache provider.",
          "slug": "jcache-datastore-implementation-for-apache-gora",
          "status": "completed",
          "student_name": "djkevincr",
          "student_profile": null,
          "tags": [],
          "title": "JCache DataStore Implementation for Apache Gora"
        },
        {
          "code_url": "https://gist.github.com/jeffkinnison/49252125d0475ca19390abfa41d615ad",
          "description": "<p>The goal of this project is to extend Apache Airavata to allow in-situ data reporting and analysis for Molecular Dynamics (MD) workflows. The resulting gateway will allow users to create custom event listeners that monitor all simulations and report when a user-defined condition is encountered. It will also allow users to stream partial results and computational resource usage over time. As a proof of concept, the extensions created in this project will be tested using MD trajectory data collected from simulations of a small molecule and standard MD analysis techniques. While this project will be tested using a MD workflow, the result will be extensible to other scientific and big data workflows.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_026",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/4904644882989056/",
          "proposal_id": null,
          "short_description": "The goal of this project is to extend Apache Airavata to allow in-situ data reporting and analysis for Molecular Dynamics (MD) workflows. The...",
          "slug": "in-situ-simulation-management-and-analysis-using-apache-airavata",
          "status": "completed",
          "student_name": "jkinnison",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "In-Situ Simulation Management and Analysis Using Apache Airavata"
        },
        {
          "code_url": "http://mail-archives.apache.org/mod_mbox/vxquery-dev/201608.mbox/%3Ce4ac9280-cf23-3bcf-e491-2fff68671d2a%40ucr.edu%3E",
          "description": "<p>The Apache VXQUERY processor is responsible for parsing and querying large amounts of XML documents. The XML format is currently used in a variety of ways such as representation (HTML), enabling data exchange between services (SOAP, REST), etc. An alternative to XML is the JSON format which is widely considered significantly more lightweight. Thus, the goal of this project is to add support for parsing and querying JSON data based on the JSONiq language specification to the VXQUERY project. Specifically, we want to add arrays, which is one of JSON items in the VXQUERY data model.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_027",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5813866374103040/",
          "proposal_id": null,
          "short_description": "The Apache VXQUERY processor is responsible for parsing and querying large amounts of XML documents. The XML format is currently used in a variety of...",
          "slug": "jsoniq-support-to-apache-vxquery",
          "status": "completed",
          "student_name": "cricri",
          "student_profile": null,
          "tags": [
            "ml"
          ],
          "title": "JSONiq Support to Apache VXQUERY"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/OPENMEETINGS/[GSoC+2016]+Add+syncing+from+CalDAV+to+Apache+OpenMeetings+Calendar",
          "description": "<p>The project will add the ability to sync events from OpenMeetings Calendar and iCal/CalDAV Protocol. OpenMeetings is a Web-Conferencing and collaboration software which already has a Calendar, but it does not integrate with CalDAV yet. This project aims to include the ability to use the CalDAV as a front-end feature by any user or organization to allow bidirectional access to the calendar server.</p>\n<p>This task will make use of the CalDAV4j, iCal, and jackrabbit-webdav libraries to implement the CalDAV client for OpenMeetings.</p>\n<p>This will be done in 3 stages:</p>\n<ul>\n<li>Implement client for CalDAV</li>\n<li>Extend openmeetings-db to store the server credentials and calendar to the database.</li>\n<li>Extend openmeetings-web to add read and write access to the user's CalDAV server.</li>\n</ul>\n<p>CalDAV implementation to the calendar would be one major upgrade to the current OpenMeetings Calendar, which at the moment uses a local database on the OpenMeetings Server to store the calendar data, allowing groups more flexibility in setting and viewing their respective schedules.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_028",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5864271036547072/",
          "proposal_id": null,
          "short_description": "The project will add the ability to sync events from OpenMeetings Calendar and iCal/CalDAV Protocol. OpenMeetings is a Web-Conferencing and...",
          "slug": "add-the-ability-to-sync-events-from-caldav-to-apache-openmeetings-calendar",
          "status": "completed",
          "student_name": "Ankush Mishra",
          "student_profile": null,
          "tags": [
            "web",
            "ai",
            "database"
          ],
          "title": "Add the ability to sync events from CalDAV to Apache OpenMeetings Calendar"
        },
        {
          "code_url": "https://github.com/apache/spark/pulls?q=author%3Anblintao",
          "description": "<p>As more efforts have been made to Spark SQL, there are more demands on providing more information and metrics through Spark UI in an effective way. Specifically, users and developers want to (1) browse information for every individual Spark SQL sessions, (2) get continuous updates from jobs created by structured streaming, and (3) have an easy and intuitive way to debug runtime issues. In this work, we aim to make efforts to response the above three demands by adding features, improvements, and related infrastructures to Spark UI for Spark SQL and structured streaming.</p>\n",
          "difficulty": "beginner",
          "id": "proj_the-apache-software-_2016_029",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5923875250503680/",
          "proposal_id": null,
          "short_description": "As more efforts have been made to Spark SQL, there are more demands on providing more information and metrics through Spark UI in an effective way....",
          "slug": "apache-spark-build-monitoring-ui-and-related-infrastructure-for-spark-sql-and-structured-streaming",
          "status": "completed",
          "student_name": "Tao Lin",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Apache Spark: Build monitoring UI and related infrastructure for Spark SQL and structured streaming"
        },
        {
          "code_url": "http://mail-archives.apache.org/mod_mbox/vxquery-dev/201608.mbox/%3CCAMOqS%2BjR6zvZ59xSeBa-KmBmKDRQtRuh2e2wPSD%2Bw8G_ttXopg%40mail.gmail.com%3E",
          "description": "<p>Apache VXQuery will be a standard compliant Xquery processor implemented in java. JSONiq is a query and processing language specifically designed for the popular JSON data model. It is much similar to XQuery burrowing a large numbers of ideas from XQuery. The \"JSONiq extension to XQuery\" allows processing XML and JSON natively and with a single language. This project aims at adding objects to the data model of VXquery allowing it to query JSON objects.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_030",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5950762551083008/",
          "proposal_id": null,
          "short_description": "Apache VXQuery will be a standard compliant Xquery processor implemented in java. JSONiq is a query and processing language specifically designed for...",
          "slug": "vxquery-178-support-jsoniq-add-objects-to-the-data-model",
          "status": "completed",
          "student_name": "Riyafa Abdul Hameed",
          "student_profile": null,
          "tags": [
            "java",
            "ml",
            "ai"
          ],
          "title": "VXQUERY-178: Support JSONiq - add objects to the data model"
        },
        {
          "code_url": "https://gist.github.com/ivanlomba/4f4eee3a46e13f90c2ce71b2929a2250",
          "description": "<p>This project will add support for arbitrary CPU and RAM in the ComputeService on JClouds. Some providers do not have the hardware profiles concept and in the current implementation of ComputeService use workarounds to overcome that lack and provides a fixed configuration. This project will allow the user to specify CPU and RAM.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_031",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5984606893375488/",
          "proposal_id": null,
          "short_description": "This project will add support for arbitrary CPU and RAM in the ComputeService on JClouds. Some providers do not have the hardware profiles concept...",
          "slug": "add-support-for-arbitrary-cpu-and-ram-in-the-computeservice-jclouds-482",
          "status": "completed",
          "student_name": "Iván Lomba",
          "student_profile": null,
          "tags": [
            "cloud"
          ],
          "title": "Add support for arbitrary CPU and RAM in the ComputeService (jclouds-482)"
        },
        {
          "code_url": "https://github.com/bustios/zeppelin-notebooks",
          "description": "<p>Apache Zeppelin is becoming a popular web-based notebook for exploratory data analytics due to features like pluggable interpreters and custom GUIs using display systems. Although Zeppelin interacts with many frameworks and libraries to analyze data and show the results, it is needed to show them through showcasing notebooks. This proposal describes a plan to build at least 4 notebooks showing the best of Zeppelin. For that, I propose to use Flink and Spark, including MLlib and GraphX, for the back-end processing systems, Helium and Angular Display System for the front-end and choose public data sets to show a real and attractive application.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_032",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6266081870086144/",
          "proposal_id": null,
          "short_description": "Apache Zeppelin is becoming a popular web-based notebook for exploratory data analytics due to features like pluggable interpreters and custom GUIs...",
          "slug": "apache-zeppelin-notebooks",
          "status": "completed",
          "student_name": "Paul Bustios",
          "student_profile": null,
          "tags": [
            "angular",
            "web",
            "ml",
            "ui"
          ],
          "title": "Apache Zeppelin Notebooks"
        },
        {
          "code_url": "https://github.com/Xazax-hun/flink/commits/serializer_codegen?author=Xazax-hun",
          "description": "<p>The current implementation of the serializers can be a performance bottleneck in some scenarios. These performance problems were also reported on the mailing list recently. I plan to implement code generation into the serializers to improve the performance.</p>\n<p>I did some preliminary benchmarks on the Nine Men’s Morris)application being developed by Gábor Gévay and Márton Balassi using a profiler. The runtime of the application was 47 seconds with the default serializers and 35 seconds with the handwritten ones. After switching to handwritten serializers, the number of samples in java.lang.reflect, org.apache.flink.api.java.typeutils.runtime, and sun.reflect was reduced to 36% from 54%. The majority of the rest of the calls to java.lang.reflect are from the comparators. The number of garbage collections was also significantly reduced. Similarly, by adding handwritten serializer to the POJO word count example could reduce the runtime from 9.5s to 8s on a 100mb input file. Note that, these benchmarks did not measure the potential speedups from the rework of the tuple serializer and the comparators.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_033",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6292775360266240/",
          "proposal_id": null,
          "short_description": "The current implementation of the serializers can be a performance bottleneck in some scenarios. These performance problems were also reported on the...",
          "slug": "flink-3599-code-generation-in-serializers-and-comparators-of-apache-flink",
          "status": "completed",
          "student_name": "Gábor Horváth",
          "student_profile": null,
          "tags": [
            "java",
            "ios",
            "api",
            "ai"
          ],
          "title": "[FLINK-3599] Code Generation in Serializers and Comparators of Apache Flink"
        },
        {
          "code_url": "http://irds.usc.edu/SentimentAnalysisParser/blog.html",
          "description": "<p>My proposal involves developing an ideal model for sentiment analysis for OpenNLP by starting with a simple model and advancing to the desired advanced model applicable in many situations. I will be using Twitter data for my tests, and my final outcome will include the final developed advanced model specified in the article and documentation describing how it was created, how it works, how efficient and accurate it is, as well as tutorial on how to learn it. I have already started working on some parts of the project.</p>\n",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2016_034",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6317132388237312/",
          "proposal_id": null,
          "short_description": "My proposal involves developing an ideal model for sentiment analysis for OpenNLP by starting with a simple model and advancing to the desired...",
          "slug": "opennlp-840-sentiment-analysis-project-proposal",
          "status": "completed",
          "student_name": "anastasijam",
          "student_profile": null,
          "tags": [],
          "title": "OPENNLP-840 - Sentiment Analysis Project Proposal"
        },
        {
          "code_url": "https://github.com/apache/reef/commits?author=wonook",
          "description": "<p>Hi, I'm Won Wook Song, currently a final year BS student in Seoul National University in Republic of Korea. I'm interested in working on the Apache REEF project for the GSoC 2016 program for the summer.</p>\n<p>The reason why I chose this project is because I believe that technology will be able to make people’s lives better and make this globe a better place, and I believe that Big Data technologies will be able to fulfill these goals. With gigantic tides of data today, it is extremely important to process, analyze, and filter these data to make it meaningful. Apache REEF project is a project that contributes to this purpose, and I have found this opportunity to start contributing to fulfill my interests and goals.</p>\n<p>I have left comments on a few issues that I have found interesting and I have included more detail on the draft that I have attached to this application. I am highly motivated and enthusiastic about working on this project, and I hope that I could spend my summer building up experience and knowledge through this program.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2016_035",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/5207595501486080/",
          "proposal_id": null,
          "short_description": "Hi, I'm Won Wook Song, currently a final year BS student in Seoul National University in Republic of Korea. I'm interested in working on the Apache...",
          "slug": "proposal-for-the-apache-reef-project",
          "status": "completed",
          "student_name": "wonook",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Proposal for the Apache REEF project"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2016/organizations/5934639780724736/"
    },
    "year_2017": {
      "num_projects": 23,
      "projects": [
        {
          "code_url": "https://asterix-gerrit.ics.uci.edu/1974",
          "description": "<p>Apache AsterixDB is a scalable, open source Big Data Management System (BDMS). It currently supports many data types in the Asterix Data Model (ADM). This project aims to support all standard spatial object internally and to parse/format the spatial object by using either or both well-known format or/and geojson format.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/6341931260968960/",
          "proposal_id": null,
          "short_description": "Apache AsterixDB is a scalable, open source Big Data Management System (BDMS). It currently supports many data types in the Asterix Data Model (ADM)....",
          "slug": "asterixdb-1371-support-the-standard-gis-objects",
          "status": "completed",
          "student_name": "Riyafa Abdul Hameed",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "ASTERIXDB-1371 Support the standard GIS objects"
        },
        {
          "code_url": "https://github.com/GearGSoC/gsoc2017/blob/master/GSoC_2017.md",
          "description": "<p>Apache Gearpump is a real-time big data streaming engine. It is inspired by recent advances in the Akka framework and a desire to improve on existing streaming frameworks. Gearpump is event/message based and featured as low latency handling, high performance, exactly once semantics, dynamic topology update, Apache Storm compatibility, etc. This project is about building a SQL layer with Apache Calcite to help those who are unfamiliar with Scala/Java to use Gearpump.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/6359040665845760/",
          "proposal_id": null,
          "short_description": "Apache Gearpump is a real-time big data streaming engine. It is inspired by recent advances in the Akka framework and a desire to improve on existing...",
          "slug": "add-sql-support",
          "status": "completed",
          "student_name": "Buddhi Ayesha",
          "student_profile": null,
          "tags": [
            "java",
            "ui"
          ],
          "title": "Add SQL support"
        },
        {
          "code_url": "https://medium.com/@erandiganepola/gsoc-2017-apache-vxquery-180-restful-api-bcb8833f24e5",
          "description": "<p>Apache VXQuery uses Hyracks and Algebricks open-source frameworks and provides a standards compliant XML Query processor implemented in Java to evaluate queries on large amounts of XML data. At the moment a CLI tool has been implemented for command line query execution. But to use the CLI tool, the user should have some sort of an advanced knowledge on using terminals. To break this barrier, a REST API can be implemented which will be used by a web interface to make use of VXQuery effectively. Therefore, adding a REST API will add more value to VXQuery and will help VXQuery to reach more users in the future. Implementing the REST API and developing a simple web interface on top of that are the main objectives of this project. Furthermore, the existing CLI will also be modified to make use of the REST API.</p>\n",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2017_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/6592753324523520/",
          "proposal_id": null,
          "short_description": "Apache VXQuery uses Hyracks and Algebricks open-source frameworks and provides a standards compliant XML Query processor implemented in Java to...",
          "slug": "apache-vxquery-180-restful-api",
          "status": "completed",
          "student_name": "Erandi Ganepola",
          "student_profile": null,
          "tags": [
            "java",
            "web",
            "api",
            "ml",
            "ai"
          ],
          "title": "Apache -VXQUERY-180 (RESTful API)"
        },
        {
          "code_url": "https://github.com/apache/mahout/pull/334",
          "description": "<p>Clustering is an important Data Mining technique with wide applications in Medicine, Biology, Social Network Analysis, Image Segmentation just to name a few. Density-based clustering is an intuitive and efficient to group similar objects together. The DBSCAN algorithm is a state of the art density-based clustering algorithm. The DBSCAN algorithm has quadratic time complexity making it unsuitable for Big Data Applications. I propose to implement a distributed R-Tree based DBSCAN algorithm in Mahout which has a complexity of O(nlog(n)). And after due discussions, implement an optimized version of the distributed DBSCAN algorithm.</p>\n",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2017_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5706035582992384/",
          "proposal_id": null,
          "short_description": "Clustering is an important Data Mining technique with wide applications in Medicine, Biology, Social Network Analysis, Image Segmentation just to...",
          "slug": "dbscan-clustering-in-mahout",
          "status": "completed",
          "student_name": "A. S. Aditya Sarma",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "DBSCAN Clustering in Mahout"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/CLOUDSTACK/noVNC+support+for+Cloudstack",
          "description": "<p>The aim of this feature is to make it possible to connect to VM consoles using  VNC client called NoVNC in browsers.noVNC is an HTML 5-based remote desktop web client which can communicate with a remote VNC server via WebSockets. Using noVNC, you can control a remote computer in a web browser over VNC.\nnoVNC has a full VNC client implementation in JavaScript/HTML5. However, noVNC is still limited by the fact that JavaScript cannot make plain TCP connections. noVNC uses WebSockets to connect to the server. noVNC includes a generic WebSockets to TCP bridge ( WebSockify ) that you can run on the server or the client. Using noVNC would be better than the current customized VNC in ACS. However, this project aims at adding noVNC support along with the current VNC feature. They will communicate to the VM via different ports.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5708090456408064/",
          "proposal_id": null,
          "short_description": "The aim of this feature is to make it possible to connect to VM consoles using  VNC client called NoVNC in browsers.noVNC is an HTML 5-based remote...",
          "slug": "adding-a-new-novnc-console-cloudstack9778",
          "status": "completed",
          "student_name": "Sachin Patil",
          "student_profile": null,
          "tags": [
            "java",
            "javascript",
            "web",
            "ml",
            "ai"
          ],
          "title": "Adding a new NoVNC console- CloudStack9778"
        },
        {
          "code_url": "https://github.com/apache/gora/commits?author=madhawa-gunasekara",
          "description": "<p>gora cassandra module is written based on thrift connector, but new Cassandra servers don't support thrift connectors, therefore this module is needed to be rewritten to support CQL.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5727025356603392/",
          "proposal_id": null,
          "short_description": "gora cassandra module is written based on thrift connector, but new Cassandra servers don't support thrift connectors, therefore this module is...",
          "slug": "rewrite-cassandra-module-in-apache-gora-to-support-cql",
          "status": "completed",
          "student_name": "Madhawa Gunasekara",
          "student_profile": null,
          "tags": [],
          "title": "Rewrite Cassandra Module in Apache Gora to support CQL"
        },
        {
          "code_url": "https://wiki.apache.org/nutch/GoogleSummerOfCode/GraphGeneratorTool/WeeklyReports",
          "description": "<p>Currently Apache Nutch has the concept of a WebGraph which builds Web graphs, performs a stable convergent link-analysis, and updates the crawldb with those scores. The main purpose of building a new Graph Generator tool for Nutch is to create a substantiated ‘deep’ graph enabling true traversal, this could be a game changer for how Nutch Crawl data is interpreted. This will involve storage of  the crawl data as RDF datasets in the form of serialized n-quad statements. This graph can be used to execute queries on the webpages. Graph generation will be achieved using the Apache Tinkerpop ScriptInputFormat  and ScriptOutputFormat’s respectively.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5413355305041920/",
          "proposal_id": null,
          "short_description": "Currently Apache Nutch has the concept of a WebGraph which builds Web graphs, performs a stable convergent link-analysis, and updates the crawldb...",
          "slug": "nutch-2369-create-a-new-graphgenerator-tool-for-writing-nutch-records-as-a-full-web-graph",
          "status": "completed",
          "student_name": "Omkar Reddy Gojala",
          "student_profile": null,
          "tags": [
            "web",
            "ai",
            "ui"
          ],
          "title": "NUTCH-2369 Create a new GraphGenerator Tool for writing Nutch Records as a Full Web Graph."
        },
        {
          "code_url": "https://gist.github.com/dinush/5e7a331ce4aa8796a8c507dc93b2fc84",
          "description": "<p>Porting task of SIS library to Android with possible alternatives for the technologies which are not compatible with Android.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5513810026692608/",
          "proposal_id": null,
          "short_description": "Porting task of SIS library to Android with possible alternatives for the technologies which are not compatible with Android.",
          "slug": "port-apache-sis-to-android",
          "status": "completed",
          "student_name": "Sisinda Dinusha",
          "student_profile": null,
          "tags": [
            "android"
          ],
          "title": "Port Apache SIS to Android"
        },
        {
          "code_url": "https://nikpawar89.github.io/",
          "description": "<p>During Phase 1 of Credit Bureau Integration project, the focus was on Credit Bureaus from India region. Initial modifications were done in Loan and Client modules to accommodate a standalone credit bureau module. However, as Apache Fineract is Open Source core banking platform used globally, the demand is to make this module more generic to accommodate global credit bureaus. Phase 2 of credit bureau integration aims to provide flexible infrastructure which facilitates on boarding of new credit bureau in Apache Fineract Platform.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5062843560886272/",
          "proposal_id": null,
          "short_description": "During Phase 1 of Credit Bureau Integration project, the focus was on Credit Bureaus from India region. Initial modifications were done in Loan and...",
          "slug": "apache-fineract-credit-bureau-integration-phase-2",
          "status": "completed",
          "student_name": "Nikhil Pawar",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Apache Fineract Credit Bureau Integration phase 2"
        },
        {
          "code_url": "https://github.com/SiddheshRane/sis-client",
          "description": "<p>Apache SIS is a library for handling  geospatial  data. This project aims to create a JavaFX app that will expose the features of this library.  The app will allow editing metadata such as coordinate reference system, transforming coordinates and visualizing queries on a map.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5105884501901312/",
          "proposal_id": null,
          "short_description": "Apache SIS is a library for handling  geospatial  data. This project aims to create a JavaFX app that will expose the features of this library.  The...",
          "slug": "sis-javafx-front-end",
          "status": "completed",
          "student_name": "Siddhesh Rane",
          "student_profile": null,
          "tags": [
            "java",
            "ai"
          ],
          "title": "SIS JavaFX Front End"
        },
        {
          "code_url": "https://loneidealist.wordpress.com/2017/08/24/gsoc-2017-distributed-configuration-management-for-apache-oodt/",
          "description": "<p>Since OODT consists of different components like file manager, resource manager and work flow manager, all those components have their own configuration files and locations. This is complex to manage and creates problems when the platform is distributed across servers or geographically. Therefore, the objective of this project is to migrate the OODT configuration to an optional zookeeper module so that the OODT components can register themselves in the zookeeper ensemble accordingly and maintain each component’s state regardless of the scale of the cluster. The proposed zookeeper module will minimize the manual configuration required when configuring OODT components. That is, this module will make use of the inherited configuration at component level. For example consider the file manager. Almost all the configurations of file manager instances are identical. Therefore, new file managers which are coming up later will inherit the configuration of the initial file managers and will almost remove the manual configuration required when adding new nodes to the cluster.</p>\n",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2017_011",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5113122192883712/",
          "proposal_id": null,
          "short_description": "Since OODT consists of different components like file manager, resource manager and work flow manager, all those components have their own...",
          "slug": "apache-oodt-rework-oodt-configuration-to-make-use-of-zookeeper-for-distributed-configuration-management",
          "status": "completed",
          "student_name": "Imesha Sudasingha",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Apache OODT : Rework OODT configuration to make use of Zookeeper for distributed configuration management"
        },
        {
          "code_url": "https://docs.google.com/document/d/1JZsXxqlcQeD12qlWLWwyn5txCfjHUmu88TCQHMne5_Y/edit?usp=sharing",
          "description": "<p>Apache Gossip is a system which can be used to build a distributed peer-to-peer network using the gossip protocol. Currently Apache Gossip is under its initial development stage where it supports basic data replication with CRDT, fault detection and multiple datacenter support. One of the requirement for this project is to support event based model to notify whenever the per-node data or shared-data get changed. Furthermore, the system is required support distributed locking mechanism in order achieve various tasks. For example dividing a task between nodes or electing a temporary leader.  Therefore, the purpose of this project is to design and implement the above mentioned functionalities to Apache Gossip project.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_012",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5267581699096576/",
          "proposal_id": null,
          "short_description": "Apache Gossip is a system which can be used to build a distributed peer-to-peer network using the gossip protocol. Currently Apache Gossip is under...",
          "slug": "add-event-listeners-to-data-objects-and-implement-vote-based-locking",
          "status": "completed",
          "student_name": "Mirage",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "Add Event Listeners to Data Objects and Implement Vote Based Locking"
        },
        {
          "code_url": "http://mail-archives.apache.org/mod_mbox/vxquery-dev/201708.mbox/%3Cf2f453d8-f848-88a1-6718-4af00b0df1ea%40ucr.edu%3E",
          "description": "<p>This proposal aims to introduce indexing as a way to speed up XML query evaluation. In XML, due to the complexity of tree structures, a wide range of index structures exists, for which different classifications can be found in the literature. In this work, we will focus on path indexing, which facilitate the access to all unique document paths of a document. In this work, Apache VXQuery will be used as the system in which path indexing will be applied. Last year, Lucene index has been integrated in VXQuery. However, there have to be a few improvements in order for Lucene index to be fully optimized for VXQuery.</p>\n",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2017_013",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5339960219533312/",
          "proposal_id": null,
          "short_description": "This proposal aims to introduce indexing as a way to speed up XML query evaluation. In XML, due to the complexity of tree structures, a wide range of...",
          "slug": "improving-lucene-indexing-on-apache-vxquery",
          "status": "completed",
          "student_name": "Christina Pavlopoulou",
          "student_profile": null,
          "tags": [
            "ml",
            "ai"
          ],
          "title": "Improving Lucene Indexing on Apache VXQuery"
        },
        {
          "code_url": "https://github.com/apache/gora/commits/master?author=nishadi&until=2017-08-30",
          "description": "<p>Apache Gora currently supports for persisting objects to various database models such as column stores like Apache Hbase, Apache Cassandra and  key value stores. This project aims to extend its capability to provide support for Aerospike database which is a NoSQL database solution for real-time operational applications, delivering predictable performance at scale.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_014",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5583054563180544/",
          "proposal_id": null,
          "short_description": "Apache Gora currently supports for persisting objects to various database models such as column stores like Apache Hbase, Apache Cassandra and  key...",
          "slug": "implement-aerospike-datastore",
          "status": "completed",
          "student_name": "Nishadi Kirielle",
          "student_profile": null,
          "tags": [
            "ai",
            "database"
          ],
          "title": "Implement Aerospike Datastore"
        },
        {
          "code_url": "https://wiki.apache.org/marmotta/GSoC/2017/MARMOTTA-659",
          "description": "<p>Apache Marmotta has become one of the most prominent projects within the open source community of Linked Data. It brings together the standards of the Semantic Web (RDF, SPARQL) and a set of new and innovative technologies of Linked Data such as: LDP, LDCache, LDPath, etc. Currently Apache Marmotta relies on the Sesame Framework for handling data as RDF internally within its modules. However, Sesame is undergoing a deprecation process and it’s being replaced by its successor Eclipse RDF4J. In order to keep Apache Marmotta updated and insurance its compatibility with new developments, it is a fundamental need to port Apache Marmotta to the new version of this Framework.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_015",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/6223317417590784/",
          "proposal_id": null,
          "short_description": "Apache Marmotta has become one of the most prominent projects within the open source community of Linked Data. It brings together the standards of...",
          "slug": "port-marmotta-to-eclipse-rdf4j",
          "status": "completed",
          "student_name": "Gustavo Mora",
          "student_profile": null,
          "tags": [
            "web"
          ],
          "title": "Port Marmotta to Eclipse RDF4J"
        },
        {
          "code_url": "https://gist.github.com/scan3/6eddf8a20735171fd1f4ccf3b32a3180",
          "description": "<h3>Summary</h3>\n<p>This project aims to implement Node Labeling and Preemption API, which are existing feature of resource managers, on REEF. Node Labels allow users to group resources with similar characteristics or with similar ACL policies and Preemption is a way to respect elasticity and SLAs together.</p>\n<h3>The Project</h3>\n<p>Even though YARN and Mesos, the resource managers have existing features that supports Node Labeling and Preemption, REEF doesn’t have APIs that makes these features available. To make developers can exploit these features on REEF regardless of which resource manager they use, APIs that make available Node Labeling and Preemption will be implemented on REEF in this project.</p>\n<h3>Required Deliverables</h3>\n<ul>\n<li>Support for the Node Labeling API as it exists in YARN and Mesos in REEF</li>\n<li>Support for the Preemption API as it exists in YARN and Mesos in REEF</li>\n</ul>\n<h3>Benefits for REEF</h3>\n<p>When Node Labeling and Preemption has been done in REEF, developer can exploit these features without directly dealing with resource managers such as YARN or Mesos, but through the same interface on REEF. It will increase portability and simplifies development of applications for cluster resource managers.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_016",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/4630813337452544/",
          "proposal_id": null,
          "short_description": "Summary\nThis project aims to implement Node Labeling and Preemption API, which are existing feature of resource managers, on REEF. Node Labels allow...",
          "slug": "support-advanced-features-of-resource-managers",
          "status": "completed",
          "student_name": "Seokchan Ahn",
          "student_profile": null,
          "tags": [
            "api",
            "ai",
            "ui"
          ],
          "title": "Support advanced features of resource managers"
        },
        {
          "code_url": "https://github.com/therajanmaurya/android-client-2.0/pulls?q=is%3Apr+author%3Atherajanmaurya",
          "description": "<p>Fineract version 1.0 was based on the client server architecture. Now Mifos is moving one step forward and is going to releasing Gen 3/Fineract Version 2.0 which is based upon the cloud-native architecture for digital financial services.</p>\n<p>Fineract 2.0 evolved from the Fineract 1.0. Now Fineract 2.0 backend API structure is totally changed with great enhancement and is massively scalable and easily adaptable.</p>\n<p>I will design an android application on top of fineract 2.0 that will add many exciting features. \nMVP architecture with Dagger 2, Rxjava, Retrofit 2 etc. \nCode Quality plugins Findbugs, PMD, CheckStyle.\nUser Login with Multiple account (Using Basic Auth and OAuth2).\nUser Profile with Edit option.\nClient List.\nNew client onboarding (including additional user-defined data).\nViewing of client details.\nLoan and savings origination - opening, approving, and disbursing applications\nDashboard screen with advance search.\nSynchronizing client data so field officers can collect repayments, view data, and onboard new clients while offline and synchronize when the return with a connection.\nUnit testing and Instrumentation Testing. \nDocumentation etc.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_017",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/4709667863265280/",
          "proposal_id": null,
          "short_description": "Fineract version 1.0 was based on the client server architecture. Now Mifos is moving one step forward and is going to releasing Gen 3/Fineract...",
          "slug": "mobile-field-officer-app-on-apache-fineract-version-20",
          "status": "completed",
          "student_name": "Rajan Maurya",
          "student_profile": null,
          "tags": [
            "java",
            "android",
            "mobile",
            "api",
            "ai"
          ],
          "title": "Mobile Field Officer App on Apache Fineract Version 2.0"
        },
        {
          "code_url": "https://docs.google.com/document/d/1z9Lo5zUkU01uchvtJCtX454x8lUG2o05-63F6O7awdA/edit?usp=sharing",
          "description": "<p>Apache Airavata is a framework that allows users to manage and execute multiple tasks using distributed computing techniques in the cloud. A core aspect of its success depends on managing workloads in a distributed environment with a microservices based architecture. My work is to create an infrastructure to efficiently manage the workload requests and make execution of tasks much easier and faster.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_018",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/4774844797288448/",
          "proposal_id": null,
          "short_description": "Apache Airavata is a framework that allows users to manage and execute multiple tasks using distributed computing techniques in the cloud. A core...",
          "slug": "distributed-workload-management",
          "status": "completed",
          "student_name": "apalkar",
          "student_profile": null,
          "tags": [
            "ai",
            "cloud"
          ],
          "title": "Distributed Workload Management"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/AIRAVATA/A+gist+of+my+summer+with+Apache+Airavata+during+GSoC+2017",
          "description": "<p>Considering Airavata, which has multiple developers contributing to the project, there is bound to be a situation where the databases and the data stored in it are not synchronized. Even with a single instance, it takes a significant amount of time to make sure that the changes are in sync when more than one developer works on it. The goal of this project is to introduce versioning of databases (schema and data) when merging a developed branch to the master branch before deploying the revision.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_019",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/4793818889060352/",
          "proposal_id": null,
          "short_description": "Considering Airavata, which has multiple developers contributing to the project, there is bound to be a situation where the databases and the data...",
          "slug": "database-versioning-in-apache-airavata",
          "status": "completed",
          "student_name": "Sneha Tilak",
          "student_profile": null,
          "tags": [
            "ai",
            "database"
          ],
          "title": "Database Versioning in Apache Airavata"
        },
        {
          "code_url": "https://medium.com/@harshvardhangupta/apache-derby-google-summer-of-code-2017-52aa99ff77c4",
          "description": "<p>Query Optimization is an active field of research in the Database Research Community, researchers have spent significant time and resources studying the state of art in query optimization and continuously improving it through different approaches. At the 2015 VLDB conference, a team led by Dr. Viktor Leis at Munich Technical University introduced a new benchmark suite for evaluating database query optimizers. The research revisited the main components in the classic query optimizer architecture using a complex, real-world data set and realistic multi-join queries.</p>\n<p>This project aims to obtain the above benchmark suite, obtains an end to end analysis of various components of Derby Query Optimizer, isolate each component’s contribution towards Derby query optimization and improve the components. The analysis obtained will serve as the knowledge base for Derby’s current state of art in query optimization and help in directing future efforts towards improving Derby in the long term.</p>\n",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2017_020",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/6076759980113920/",
          "proposal_id": null,
          "short_description": "Query Optimization is an active field of research in the Database Research Community, researchers have spent significant time and resources studying...",
          "slug": "derby-6921-how-good-is-the-derby-query-optimizer-really",
          "status": "completed",
          "student_name": "Harshvardhan Gupta",
          "student_profile": null,
          "tags": [
            "ai",
            "database",
            "ui"
          ],
          "title": "DERBY-6921 How good is the Derby Query Optimizer, really"
        },
        {
          "code_url": "https://github.com/krishnakalyan3/krishnakalyan3.github.io/blob/master/work_product.md",
          "description": "<p>Currently the performance tests are only semi-automated and only a subset of algorithms are included, but largely the process is manual. An automatic benchmark suite can be used to detect regressions or improvements in critical components of the system. This GSoC would begin by building a benchmark infrastructure to conduct experiments that compare different choices in critical parts like Sparsity thresholds for Dense/Sparse datasets, Dataset Size, Memory Limit and Hyper parameters decisions.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_021",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/6077565689135104/",
          "proposal_id": null,
          "short_description": "Currently the performance tests are only semi-automated and only a subset of algorithms are included, but largely the process is manual. An automatic...",
          "slug": "automate-performance-testing-and-reporting",
          "status": "completed",
          "student_name": "Sai Krishna Kalyan",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "Automate performance testing and reporting"
        },
        {
          "code_url": "https://github.com/apache/fineract/pull/409",
          "description": "<p>Mifos (Fineract) has a documented REST API already. It currently has two limitations:\nIt's source is simply a HTML file that is maintained manually in parallel to the source code which actually defines the REST API, and therefore can be out of sync and it's not \"live\"\nThe goal of this project is address this by using Swagger (now Open API Initiative OAI), most probably combined with SpringFox in for Mifos (Fineract), and replace the current apiLive.htm.\nOnce the Swagger live documentation is working it would be interesting to use the Swagger descriptor to generate client libraries (e. g. Java, Angular2). \nNice to have optional add-on ideas for the end of the project is to add a paragraph to this new REST API Doc explaining how to easily import the (latest) Mifos Swagger into Postman, and perhaps add a Run in Postman button</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_022",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/4848851110330368/",
          "proposal_id": null,
          "short_description": "Mifos (Fineract) has a documented REST API already. It currently has two limitations:\nIt's source is simply a HTML file that is maintained manually...",
          "slug": "fineract-rest-api-live-swagger",
          "status": "completed",
          "student_name": "Sanyam Goel",
          "student_profile": null,
          "tags": [
            "angular",
            "java",
            "api",
            "ml",
            "ai"
          ],
          "title": "Fineract REST API \"Live\" - Swagger"
        },
        {
          "code_url": "https://wiki.apache.org/tika/GSOC/GSoC2017",
          "description": "<p>Image captions are a small piece of text, usually of one line, added to the metadata of images to provide a brief summary of the scenery in the image. It helps text based Information Retrieval(IR) systems to \"understand\" the scenery in images. It is a very useful feature, yet a challenging and interesting problem in the domain of computer vision.</p>\n<p>The objective of this project is providing Apache Tika, image captioning capabilities and a scalable architecture to deal with deep learning models in the future.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2017_023",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/4859682480979968/",
          "proposal_id": null,
          "short_description": "Image captions are a small piece of text, usually of one line, added to the metadata of images to provide a brief summary of the scenery in the...",
          "slug": "supporting-image-to-text-image-captioning-in-tika-for-image-mime-types",
          "status": "completed",
          "student_name": "Thejan Wijesinghe",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Supporting Image-to-Text (Image Captioning) in Tika for Image MIME Types"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2017/organizations/4633151007621120/"
    },
    "year_2018": {
      "num_projects": 23,
      "projects": [
        {
          "code_url": "https://github.com/apache/gora/pull/134",
          "description": "<p>This GSoC project aims to implement a new backend for Apache Gora, specifically the distributed database Apache Ignite. This proposal focuses on the native persistence of Ignite, which will be integrated in Gora as a new data store. The new backend implementation willl boost Apache Gora and open new use cases opportunities for its applications. Moreover, the approach of integration proposed will facilitate future implementations of other databases.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/6380991102844928/",
          "proposal_id": null,
          "short_description": "This GSoC project aims to implement a new backend for Apache Gora, specifically the distributed database Apache Ignite. This proposal focuses on the...",
          "slug": "gora-535-add-a-data-store-for-apache-ignite",
          "status": "completed",
          "student_name": "Carlos Muñoz",
          "student_profile": null,
          "tags": [
            "ai",
            "database",
            "backend"
          ],
          "title": "GORA-535 Add a data store for Apache Ignite"
        },
        {
          "code_url": "https://drive.google.com/drive/folders/1Vq8rYKKzl27_YGrIuKsXch0j7QMihhCW",
          "description": "<p>Apache ManifoldCF is an open source software framework which falls under the category of enterprise content management software, designed to synchronize documents and their metadata between source content repositories and target repositories where documents are indexed and can be searched for. Apache ManifoldCF is currently extending its capabilities to also support content migration.</p>\n<p>ManifoldCF uses output connectors to connect to different kinds of target repositories and uses repository connectors to connect to source content repositories. Currently, ManifoldCF only has a repository connector for GridFS which allow it to read binaries from MongoDB. But yet ManifoldCF does not have a MongoDB output connector.</p>\n<p>The proposed project is to develop a MongoDB output connector for Apache ManifoldCF, to allow ManifoldCF to migrate content against a MongoDB instance to extend it's enterprise content management capabilities as well as it's enterprise content migration capabilities.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/6680749151354880/",
          "proposal_id": null,
          "short_description": "Apache ManifoldCF is an open source software framework which falls under the category of enterprise content management software, designed to...",
          "slug": "mongodb-output-connector-for-apache-manifoldcf",
          "status": "completed",
          "student_name": "Irindu Nugawela",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "MongoDB Output Connector for Apache ManifoldCF"
        },
        {
          "code_url": "https://gist.github.com/rohanjulka19/1773172d06c289af5c7e1bb191613e27",
          "description": "<p>Apache Syncope allows customization of its behaviour using Groovy scripts this is done so that the Syncope behaviour can be customized at runtime. It has already been implemented in the Syncope console. The objective of this project is to implement this feature in the Syncope NetBeans IDE plugin . This will allow the users to manage groovy scripts using the NetBeans IDE plugin.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5726348362383360/",
          "proposal_id": null,
          "short_description": "Apache Syncope allows customization of its behaviour using Groovy scripts this is done so that the Syncope behaviour can be customized at runtime. It...",
          "slug": "support-groovy-implementations-in-the-netbeans-ide-plugin",
          "status": "completed",
          "student_name": "Rohan Julka",
          "student_profile": null,
          "tags": [],
          "title": "Support Groovy implementations in the  Netbeans IDE plugin"
        },
        {
          "code_url": "https://github.com/datjosep/airavata-sandbox/tree/master/gsoc2018",
          "description": "<p>I'm making a criminology gateway which would make data more accessible to those with the proper clearance by creating a web application that is easy to use and pick up to illustrate trends in criminal activity in areas of Indianapolis.</p>\n",
          "difficulty": "beginner",
          "id": "proj_the-apache-software-_2018_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5397332929544192/",
          "proposal_id": null,
          "short_description": "I'm making a criminology gateway which would make data more accessible to those with the proper clearance by creating a web application that is easy...",
          "slug": "mapping-criminal-activity",
          "status": "completed",
          "student_name": "Davis Joseph",
          "student_profile": null,
          "tags": [
            "web"
          ],
          "title": "Mapping Criminal Activity"
        },
        {
          "code_url": "https://github.com/karankotz/Apache-airavata-nextcloud-/wiki",
          "description": "<p>The goal of this project is to design and implement a Nextcloud module and replace the existing transfer of the files from the client applications via Hypertext Transfer Protocol (HTTP) and Secure File Transfer Protocol (SFTP) with the APIs of this module. The existing protocols to transfer the uploaded files via client application window differ from each other and run in different ways to establish the connection and transfer the files. The existing mechanisms involve the HTTP and SFTP in order to transfer the files from the client window. To effectively enable the unified mechanism and collaboration of the files with the quick and reliable way we plan to implement the file upload using Nextcloud API. The APIs of the Nextcloud will be targeted in order to transfer the files from the client window and save the files to the Nextcloud. The Nextcloud enables the developers to reliably establish and support an unified mechanism to transfer the files from different clients running on the different platforms.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5025640554168320/",
          "proposal_id": null,
          "short_description": "The goal of this project is to design and implement a Nextcloud module and replace the existing transfer of the files from the client applications...",
          "slug": "integrate-nextcloud-for-apache-airavatas-data-transfer-use-cases",
          "status": "completed",
          "student_name": "Karan Kotabagi",
          "student_profile": null,
          "tags": [
            "api",
            "ai",
            "cloud",
            "ui"
          ],
          "title": "Integrate NextCloud for Apache Airavata's Data Transfer Use Cases"
        },
        {
          "code_url": "https://medium.com/@lahiru_j/gsoc-2018-re-architect-output-data-parsing-into-airavata-core-81da4b37057e",
          "description": "<p>This provides an opportunity to re-architect the data catalog and build it on new Helix DAG based execution within Airavata.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5293136083419136/",
          "proposal_id": null,
          "short_description": "This provides an opportunity to re-architect the data catalog and build it on new Helix DAG based execution within Airavata.",
          "slug": "re-architect-output-data-parsing-into-airavata-core",
          "status": "completed",
          "student_name": "Lahiru Jayathilake",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Re-architect Output Data Parsing into Airavata core"
        },
        {
          "code_url": "https://medium.com/@yasgun/gsoc-2018-with-apache-airavata-user-defined-airavata-workflows-39f0e79234ee",
          "description": "<p>Apache Airavata used to support user-defined workflows using the XBaya interface, to drag and drop application components to a workspace and define data flow and control flow dependencies among the application nodes. Airavata has evolved significantly and currently it only supports single job submissions through Orchestrator. But the current development version is being built-over Apache Helix for DAG orchestration. This provides an opportunity to resurrect workflow capabilities in Airavata. This GSoC project consists of the following sub tasks.</p>\n<ul>\n<li>Finalizing the Airavata Workflow Language.</li>\n<li>Modifying the Orchestrator to parse user-defined workflow and translate to equivalent Helix DAGs, execute the workflow, and monitor it at runtime.</li>\n<li>Developing a simple GUI to demonstrate the capabilities.</li>\n</ul>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5636168544681984/",
          "proposal_id": null,
          "short_description": "Apache Airavata used to support user-defined workflows using the XBaya interface, to drag and drop application components to a workspace and define...",
          "slug": "airavata-2717-gsoc-resurrect-user-defined-airavata-workflows",
          "status": "completed",
          "student_name": "Yasas Gunarathne",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "[AIRAVATA-2717] [GSoC] Resurrect User-Defined Airavata Workflows"
        },
        {
          "code_url": "https://medium.com/@ahmedifhaam/the-journey-21af965c9493",
          "description": "<p>Apache DRAT is an open source Release Audit Tool. Which is distributed and parallelized (Map Reduce) wrapper around APACHE RATTM (Release Audit Tool) that goes far beyond RATTM by leveraging Apache OODTTM to dramatically speed up the process. Currently DRAT has two GUIs, the first one proteus which has the all four commands available in CLI drat tool and a summary view workflow GUI screen. The second one is Viz which is mostly a summary View. Both tools have problems showing errors from background process because most of the commands run as a process wrapper.\nThe objective of this project would be to combine both of the GUI web apps features in to one and give more productive single GUI.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/6199118498103296/",
          "proposal_id": null,
          "short_description": "Apache DRAT is an open source Release Audit Tool. Which is distributed and parallelized (Map Reduce) wrapper around APACHE RATTM (Release Audit Tool)...",
          "slug": "evolve-drat-web-interface",
          "status": "completed",
          "student_name": "Ahmed Ifhaam",
          "student_profile": null,
          "tags": [
            "web",
            "ai",
            "ui"
          ],
          "title": "Evolve DRAT web interface"
        },
        {
          "code_url": "https://github.com/haouech/incubator-taverna-language/tree/cwlparser",
          "description": "<p>The Common Workflow Language (CWL) aims to standardize workflow languages to execute command line tools on the cloud and on local servers.\nApache Taverna supports specific formats for import and export of workflows, but currently, CWL workflows are not fully supported.\nDuring the GSOC, we intend to provide structural import and export of CWL workflows.\nIn addition, we intend to provide a way to support some of CWL command line tools inside Taverna and to export Taverna activities.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/6202553398198272/",
          "proposal_id": null,
          "short_description": "The Common Workflow Language (CWL) aims to standardize workflow languages to execute command line tools on the cloud and on local servers.\nApache...",
          "slug": "apache-taverna-cwl-support-proposal",
          "status": "completed",
          "student_name": "Majdi Haouech",
          "student_profile": null,
          "tags": [
            "ai",
            "cloud"
          ],
          "title": "Apache Taverna CWL support proposal"
        },
        {
          "code_url": "https://gist.github.com/ebenezergraham/c0f085f95bf0a8c6aade2101f2a61575",
          "description": "<p>This project is a new feature request for the Apache Fineract CN. The SMS/Email Notifications service would be a microservice developed on Apache Fineract CN to enable MFI members to get notified on events occurring on their accounts. There are arrays of events occurring in other microservices therefore there is a need to streamline these events and notify MFI members of significant events. This will impact the KYC of the organisation and the user experience. This problem has led to the need for a microservice such as this one to be developed to enable MFI staff to select notifications which need to be sent or the member choose specific events during account creation.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/4548540353216512/",
          "proposal_id": null,
          "short_description": "This project is a new feature request for the Apache Fineract CN. The SMS/Email Notifications service would be a microservice developed on Apache...",
          "slug": "fineract-cn-sms-email-notifications",
          "status": "completed",
          "student_name": "Graham",
          "student_profile": null,
          "tags": [
            "ml",
            "ai"
          ],
          "title": "Fineract CN SMS & Email Notifications"
        },
        {
          "code_url": "https://gist.github.com/Hiteshgautam01/8a2367d71869b0d9bc0ef599693205bc",
          "description": "<p>Apache Taverna Mobile is an Android app for controlling an Apache Taverna Server for remotely running Apache Taverna workflows. Apache Taverna mobile app is for anyone who wants to create and run workflows, It basically shows workflow, developed by different users,this app is to give them a platform by which they can view, that is not at his desk. For instance, when visiting a conference he might hear about someone's workflow, which\nhe can quickly locate and add to starred workflows for later exploration.In this project, I will be writing the tests for this application.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_011",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/4680671263981568/",
          "proposal_id": null,
          "short_description": "Apache Taverna Mobile is an Android app for controlling an Apache Taverna Server for remotely running Apache Taverna workflows. Apache Taverna mobile...",
          "slug": "writing-tests-for-apache-taverna-mobile",
          "status": "completed",
          "student_name": "Hitesh Gautam",
          "student_profile": null,
          "tags": [
            "android",
            "mobile",
            "ui"
          ],
          "title": "Writing Tests for Apache Taverna Mobile"
        },
        {
          "code_url": "https://github.com/apache/fineract-cn-mobile/pulls?utf8=✓&q=is%3Apr+author%3Adilpreet96",
          "description": "<p>The development phase for Fineract CN Mobile 2.0 can be divided into these parts:-</p>\n<ul>\n<li>New Features like Multiple account login and maintain session, Passcode feature, Sync Adapter to sync clients, allow to edit Loan application feature if loan is not approved, adding new data views for pages like customer detail page according to API.</li>\n<li>Refactoring current features like changing the retrofit models in kotlin, improving the quality of the picture, adding review screen in every new records creation form.</li>\n</ul>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_012",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/4686743341105152/",
          "proposal_id": null,
          "short_description": "The development phase for Fineract CN Mobile 2.0 can be divided into these parts:-\n\nNew Features like Multiple account login and maintain session,...",
          "slug": "fineract-cn-mobile-20",
          "status": "completed",
          "student_name": "Dilpreet Singh",
          "student_profile": null,
          "tags": [
            "mobile",
            "api",
            "ai"
          ],
          "title": "Fineract CN Mobile 2.0"
        },
        {
          "code_url": "https://github.com/apache/incubator-nemo/pull/95",
          "description": "<p>Apache Nemo (incubating) is a data processing system that supports various deployment characteristics, by easily customizing translation of a dataflow program into a physical execution plan. Supporting RESTful API and web interface can help Apache Nemo to:</p>\n<ul>\n<li>Provide easy way to inspect compiler passes and runtime modules for developers.</li>\n<li>Provide intuitive way to introspect the behaviour of Nemo stack and to make reasonable decision on their configuration for application writers and cluster operators.</li>\n</ul>\n",
          "difficulty": "beginner",
          "id": "proj_the-apache-software-_2018_013",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/4758094961704960/",
          "proposal_id": null,
          "short_description": "Apache Nemo (incubating) is a data processing system that supports various deployment characteristics, by easily customizing translation of a...",
          "slug": "implement-restful-api-and-web-ui-interface-in-nemo",
          "status": "completed",
          "student_name": "Jae Hyeon Park",
          "student_profile": null,
          "tags": [
            "web",
            "api",
            "ui"
          ],
          "title": "Implement RESTful API and web ui interface in Nemo"
        },
        {
          "code_url": "https://gist.github.com/sesteves/9c37e23f7e0b79cfb6be1f7ee6a31acc",
          "description": "<p>This proposal aims at designing, implementing and evaluating plugins that integrate RocketMQ with both the HBase data store and the Beam data processing model. These integration plugins will improve RocketMQ offline storage capabilities and benefit users with stringent large-scale and data-intensive processing needs. End results of this proposal include HBase and Beam plugin implementations, as well as exhaustive unit tests, application examples and documentation.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_014",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/4822558528503808/",
          "proposal_id": null,
          "short_description": "This proposal aims at designing, implementing and evaluating plugins that integrate RocketMQ with both the HBase data store and the Beam data...",
          "slug": "implementing-integration-plugins-in-rocketmq-for-hbase-and-beam",
          "status": "completed",
          "student_name": "Sergio Esteves",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Implementing integration plugins in RocketMQ for HBase and Beam"
        },
        {
          "code_url": "https://phuonghaonguyen.blogspot.com/2018/08/i.html",
          "description": "<p>This project focus on building about the server side of the Catalog Service for the Web(CSW) is base on OGC Catalogue interface standards use the Apache CXF framework, CXF enables the development of RESTful services via annotations using the HTTP Binding. Using URI templates and annotations that can bind a service operation to arbitrary URL/verb combinations. \nFor each new metadata added to the CSW, relevant metadata will been server read only once and stored in a PostgreSQL database. This database would be used by the CSW engine for performing the search. About the client side, I will creat a client application simple, from there, the user can search for metadata they are interested in CSW.\nImplementing OGC CSW is not only applicable for VNSC but also for other space agencies in searching images by criteria since the metadata used in this project (provided by VNSC) is largely used by other space agencies. This project aims the web server application would be developed in the Apache SIS application/sis-webapp module.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_015",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/6480593474813952/",
          "proposal_id": null,
          "short_description": "This project focus on building about the server side of the Catalog Service for the Web(CSW) is base on OGC Catalogue interface standards use the...",
          "slug": "implement-ogc-catalog-service-for-the-webcsw",
          "status": "completed",
          "student_name": "PHUONG HAO NGUYEN THI",
          "student_profile": null,
          "tags": [
            "web",
            "ai",
            "database",
            "ui"
          ],
          "title": "Implement OGC Catalog Service for the Web(CSW)"
        },
        {
          "code_url": "https://medium.com/@deshanigeethika/gsoc-2018-apache-allura-personal-dashboard-631b4bc23ec5",
          "description": "<p>A nice improvement to Allura project/code hosting would be a personal dashboard when a user is logged in. It would provide quick access to the projects that the user is part of, tickets that created by the user, tickets assigned to the user, pull requests of the user, activity stream of people that the user follows, etc.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_016",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/6563917719404544/",
          "proposal_id": null,
          "short_description": "A nice improvement to Allura project/code hosting would be a personal dashboard when a user is logged in. It would provide quick access to the...",
          "slug": "comdev-254-allura-personal-dashboard",
          "status": "completed",
          "student_name": "Deshani Geethika",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "[COMDEV-254] Allura - Personal Dashboard"
        },
        {
          "code_url": "https://gist.github.com/pembemiriam/f588107c092b686e394ed3866730b489",
          "description": "<p>This project is about designing a new web user interface for institutions with Group lending facilities using Apache Fineract CN which will be similar to the one of Mifos X and Gen 1 web app. This design will have a completely different user interface from the the existing fims-web-app. It will not only have the functionalities of the existing fims-web-app but will include functionalities to support microfinance institutions with group and center-based operations. Mindful of what is needed to execute this project, i will put in all my time ( during weekdays and week-ends ) except for the 22 hours of classes that i have every week to make this project idea into a reality.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_017",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/4911608904024064/",
          "proposal_id": null,
          "short_description": "This project is about designing a new web user interface for institutions with Group lending facilities using Apache Fineract CN which will be...",
          "slug": "new-web-ui-for-apache-fineract-cn",
          "status": "completed",
          "student_name": "Pembe Motia",
          "student_profile": null,
          "tags": [
            "web",
            "ui"
          ],
          "title": "New Web UI For Apache Fineract CN"
        },
        {
          "code_url": "https://gist.github.com/kengneruphine/1b9ec42cae46e62c637729f0505cdfc5",
          "description": "<p>This project is about building a Group Loan Management Service web UI within the fims-web-app to consume the existing APIs of the Group microservice on Apache Fineract CN and then extending the microservice to include more features needed for full Joint Group Loan Management. The latter phase requires full understanding of how Groups and Loans functions on Mifos X and detailed knowledge of the Apache Fineract CN to replicate some of the Group features such as Joint Group Loan Management and Joint Liability Group within the context of Apache Fineract CN which I am committed to do. Beside the 21 hours of school classes every week, i will dedicate the rest of my time and my weekends to learning and implementing this project and will continue contributing to the community after this summer period.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_018",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5836324221222912/",
          "proposal_id": null,
          "short_description": "This project is about building a Group Loan Management Service web UI within the fims-web-app to consume the existing APIs of the Group microservice...",
          "slug": "group-loan-management-service",
          "status": "completed",
          "student_name": "Ruphine Kengne",
          "student_profile": null,
          "tags": [
            "web",
            "api",
            "ai",
            "ui"
          ],
          "title": "Group Loan Management Service"
        },
        {
          "code_url": "https://gist.github.com/vectorijk/4372aa5e69b465138f29eb9083952590",
          "description": "<p>Beam has a number of classic streaming SQL benchmarks known as \"Nexmark\" coded up in both raw Java and also Beam SQL.\nSo far, expanding functionality has been the focus of Beam SQL so there is little known about performance - we know only that it is a pretty straightforward mapping from SQL to Beam that should work OK a lot of the time. It would be interesting to see where the bottlenecks are when these SQL benchmarks are translated via Beam SQL into a Beam pipeline and then again translated to the native capabilities of e.g. Spark. Flink and Dataflow.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_019",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/6321528153047040/",
          "proposal_id": null,
          "short_description": "Beam has a number of classic streaming SQL benchmarks known as \"Nexmark\" coded up in both raw Java and also Beam SQL.\nSo far, expanding functionality...",
          "slug": "apache-beam-tpc-h-benchmark-on-beam-sql",
          "status": "completed",
          "student_name": "Kai Jiang",
          "student_profile": null,
          "tags": [
            "java",
            "ai"
          ],
          "title": "Apache Beam: TPC-H Benchmark on Beam SQL"
        },
        {
          "code_url": "https://medium.com/@hasiniwitharana/gsoc-2018-openid-connect-relying-party-implementation-for-apache-sling-635ea1e9b45e",
          "description": "<p>This project is about creating an OpenID Connect Relying Party Authentication Handler for Apache Sling.  OpenID Connect(OIDC) is an authentication protocol based on OAuth2.0 authorization protocol. The purpose of this project is to build an OIDC authentication handler that has the capability of sending an authorization request to an OpenID Provider, getting an access token and an id token for a particular user and storing  the required user claims.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_020",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5129417365913600/",
          "proposal_id": null,
          "short_description": "This project is about creating an OpenID Connect Relying Party Authentication Handler for Apache Sling.  OpenID Connect(OIDC) is an authentication...",
          "slug": "openid-connect-authentication-handler-for-apache-sling",
          "status": "completed",
          "student_name": "Hasini Witharana",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "OpenID Connect Authentication Handler for Apache Sling"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/ANY23/GSoC+2018",
          "description": "<p>This project will implement a new RDFa parser for Apache Any23 through a wrapper of the native C/C++ library Librdfa. The implementation aims to evaluate the level of compatibility between both projects and quantify the performance improvement that a native parser could achieve in Any23. In addition, it is proposed to test the integration  results against the rdfa.info test-suit in order to validate the approach. The benefits of implementing a more efficient parser are extremely relevant taking into account that RDFa processing takes place in the web where the amount of data is huge.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_021",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5137473516601344/",
          "proposal_id": null,
          "short_description": "This project will implement a new RDFa parser for Apache Any23 through a wrapper of the native C/C++ library Librdfa. The implementation aims to...",
          "slug": "any23-295-implement-ability-to-use-librdfa",
          "status": "completed",
          "student_name": "Julio Caguano",
          "student_profile": null,
          "tags": [
            "web",
            "ai",
            "ui"
          ],
          "title": "ANY23-295  Implement ability to use librdfa"
        },
        {
          "code_url": "http://edgarlgb.github.io/Gsoc-project/",
          "description": "<p>The project aims to provide a compiler extension and runtime for a new \"paramserv\" built-in function. In the context of large-scale machine learning, it will bring more performance when training a model with a data-parallel and model-parallel parameter server. SystemML already supports the data-parallel and task-parallel operator. Hence, we can focus on designing the parameter server primitive and implementing the parameter update strategies.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_022",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5148916517437440/",
          "proposal_id": null,
          "short_description": "The project aims to provide a compiler extension and runtime for a new \"paramserv\" built-in function. In the context of large-scale machine learning,...",
          "slug": "systemml-2083-language-and-runtime-for-parameter-servers",
          "status": "completed",
          "student_name": "Guobao LI",
          "student_profile": null,
          "tags": [
            "ml",
            "ai",
            "ui"
          ],
          "title": "[SYSTEMML-2083] Language and runtime for parameter servers"
        },
        {
          "code_url": "https://tz70s.github.io/posts/gsoc-2018/",
          "description": "<p>The emergence of serverless computing moves cloud/edge to the next generation of resource sharing: function as a service. The innovation makes developer released from provisioning, updating, and managing servers under flexible scalability and fault tolerance. Also, the most influential outcome is no computing cost when idle, which is also known as pay as you go model.</p>\n<p>However, the performance is under critical to be improved, i.e., more servers required in existed serverless platform, high and not predictable round-trip latency, especially under high concurrency and keeping dependable.</p>\n<p>Here come some places to improvement, including shortened path, performance improvement on invoker, serialization elimination, and scheduling. In the first step, the picked-up topic: <strong><em>work-stealing and priority-based scheduling and direct connection for streaming capabilities</em></strong> will be a great and valuable choice.</p>\n<p>Goal on this project</p>\n<ol>\n<li>Work-stealing scheduling on load balancer.</li>\n<li>Direct connection for stream support.</li>\n<li>Priority-based work-stealing scheduling.</li>\n<li>Comprehensive tests to avoid bugs on concurrency and distributed failure.</li>\n<li>Performance tests and optimization.</li>\n</ol>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2018_023",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5211013825691648/",
          "proposal_id": null,
          "short_description": "The emergence of serverless computing moves cloud/edge to the next generation of resource sharing: function as a service. The innovation makes...",
          "slug": "openwhisk-performance-improvement-work-stealing-priority-based-scheduling-on-load-balancer-and-direct-connection-for-streaming-capabilities",
          "status": "completed",
          "student_name": "Tzu-Chiao Yeh",
          "student_profile": null,
          "tags": [
            "ai",
            "cloud",
            "ui"
          ],
          "title": "OpenWhisk performance improvement - work stealing, priority-based scheduling on load balancer and direct connection for streaming capabilities."
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2018/organizations/5175246747336704/"
    },
    "year_2019": {
      "num_projects": 17,
      "projects": [
        {
          "code_url": "https://medium.com/@shreyansh25.shrivastava/gsoc19-work-submission-4699662d99f5",
          "description": "<p>The goal of the project is to implement a plugin with various statistical models implemented underneath from which the user can choose the best one which works for them for the classification of their mails into ham and spam. Documentation regarding the merged patch and a tutorial to use the plugin will also be created.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/6477076280901632/",
          "proposal_id": null,
          "short_description": "The goal of the project is to implement a plugin with various statistical models implemented underneath from which the user can choose the best one...",
          "slug": "spamassassin-statistical-classifier-plugin",
          "status": "completed",
          "student_name": "Shreyansh Shrivastava",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "SpamAssassin : Statistical Classifier Plugin"
        },
        {
          "code_url": "https://medium.com/@nayanangamuhandiram/final-submission-in-gsoc-2019-a99b117a64b3",
          "description": "<p>New Camel website is a major migration of <a href=\"http://camel.apache.org/\" target=\"_blank\">http://camel.apache.org/</a> website. This work is focused on Camel 3 final release in September.</p>\n<p>Tools used to generate the website:</p>\n<ol>\n<li>Git :- a source code management tool used to fetch document sources from different GitHub repositories.</li>\n<li>Node.js :- a JavaScript runtime used to build the website. You will need to use Node.js version 10.</li>\n<li>yarn :-  a blazing fast dependency and package manager tool used to download and manage required libraries.</li>\n<li>Gulp :- a task automation tool. Used to build the Camel Antora UI theme.</li>\n<li>Hugo :- a static site generator. Simplified, it takes the documentation from the content folder and applies templates from the layouts folder and together with any resources in static folder generates output in the public folder.</li>\n<li>Antora :- a documentation site generator. It uses Asciidoc documents from different sources in the Camel and Camel K repositories where user manual and component reference documentation resides and renders them for inclusion in this website.</li>\n<li>Maven (optional) :- a build tool used to run the complete website generating process</li>\n</ol>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/6707838833917952/",
          "proposal_id": null,
          "short_description": "New Camel website is a major migration of http://camel.apache.org/ website. This work is focused on Camel 3 final release in September.\nTools used to...",
          "slug": "camel-11492-new-camel-website",
          "status": "completed",
          "student_name": "Nayananga Muhandiram",
          "student_profile": null,
          "tags": [
            "java",
            "javascript",
            "web",
            "ui"
          ],
          "title": "CAMEL-11492 New Camel website"
        },
        {
          "code_url": "https://gist.github.com/ttanay/80f84b7b852e0867d5a00d3b345e1dad",
          "description": "<p>This project aims to add support for File Loads method of inserting data into BigQuery for streaming pipelines. The PR - <a href=\"https://github.com/apache/beam/pull/7655\" target=\"_blank\">#7655</a> for <a href=\"https://issues.apache.org/jira/browse/BEAM-6553\" target=\"_blank\">[BEAM-6553]</a> added support in the Python SDK for writing to BigQuery using File Loads method for Batch pipelines. However, support still needs to be added for Streaming pipelines.</p>\n<p>Streaming pipelines with non-default Windowing, Triggering and Accumulation mode should be able to write data to BigQuery using file loads method. In case of failure, the pipeline should fail atomically. This means that each record should be loaded into BigQuery at-most-once.</p>\n<p>The JIRA issue for this project is <a href=\"https://issues.apache.org/jira/browse/BEAM-6611\" target=\"_blank\">[BEAM-6611]</a>.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/6754999034445824/",
          "proposal_id": null,
          "short_description": "This project aims to add support for File Loads method of inserting data into BigQuery for streaming pipelines. The PR - #7655 for [BEAM-6553] added...",
          "slug": "beam-6611-a-python-sink-for-bigquery-with-file-loads-in-streaming",
          "status": "completed",
          "student_name": "Tanay Tummalapalli",
          "student_profile": null,
          "tags": [
            "python",
            "ai"
          ],
          "title": "[BEAM-6611] A Python Sink for BigQuery with File Loads in Streaming"
        },
        {
          "code_url": "https://github.com/apache/camel/pull/3022",
          "description": "<p>This project will implement a new dataformat within Apache Camel. Concretely, the dataformat will cover the microformats standard through the well-known library Apache Any23. This project will open up a new spectrum of possibilities for Apache Camel users in the context of Semantic Web technologies. Moreover, the implementation of this module will pave the way for other standards such RDF, Linked Data, RDFa, etc.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5670732191760384/",
          "proposal_id": null,
          "short_description": "This project will implement a new dataformat within Apache Camel. Concretely, the dataformat will cover the microformats standard through the...",
          "slug": "camel-9260-dataformat-apache-any23",
          "status": "completed",
          "student_name": "Roberto Flores",
          "student_profile": null,
          "tags": [
            "web"
          ],
          "title": "CAMEL-9260 Dataformat Apache Any23"
        },
        {
          "code_url": "https://medium.com/@shalithasuranga/gsoc-2019-implementing-user-mentions-feature-for-apache-allura-4e5e4df8b2db",
          "description": "<p>This proposal suggests a full-featured modern user mentions feature with additional improvements for Apache Allura. User will be able to mention other users in a comment with the help of an autocomplete list. Thereafter, notification emails will be sent to related users. Furthermore, there will be an option for users to turn on/off notifications as they wish.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5430086918995968/",
          "proposal_id": null,
          "short_description": "This proposal suggests a full-featured modern user mentions feature with additional improvements for Apache Allura. User will be able to mention...",
          "slug": "implementing-an-user-mentions-feature-for-discussions-with-additional-improvements",
          "status": "completed",
          "student_name": "Shalitha Suranga",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Implementing an user mentions feature for discussions with additional improvements"
        },
        {
          "code_url": "https://medium.com/@gimhanadesilva.15/gsoc-2019-apache-oodt-react-based-opsui-dashboard-d93a9083981c",
          "description": "<p>At the present stage, Apache OODT provides a web app to monitor the status of each component and ingested files, metadata and workflows. This main dashboard is known as OPS UI which is based on Apache wicket java web framework. Though it provides basic monitoring functionalities like retrieval of product status, metadata,workflow and platform health information etc. still it lacks of few important features like querying over products, product removal and workflow termination etc. Further the existing UI is not so user friendly and  prints stack traces when backend errors occurred. Moreover users have to deploy the complete OPS UI, even whether they are embedding components individually in their applications. The intention of this proposed project idea is to address all those loop holes  by implementing a new component based React UI with enhanced REST APIs. Moreover the implementation of the idea discussed here, is decided to be released with Apache OODT 2.0.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5432463780741120/",
          "proposal_id": null,
          "short_description": "At the present stage, Apache OODT provides a web app to monitor the status of each component and ingested files, metadata and workflows. This main...",
          "slug": "oodt-986-a-react-based-new-ui-for-opsui",
          "status": "completed",
          "student_name": "Nadeeshan Gimhana",
          "student_profile": null,
          "tags": [
            "react",
            "java",
            "web",
            "api",
            "ai"
          ],
          "title": "[OODT-986] A React based new UI for OPSUI"
        },
        {
          "code_url": "https://github.com/apache/gora/pull/175",
          "description": "<p>The Apache Gora™ an in-memory data model and persistence for big data. Gora provides a generic API to work with different datastores. Data storing, data persisting and querying can be done via Gora APIs on these data stores. Apart from data stores gora provides support for mapReduce, Apache Spark, Apache Pig and Apache Flink. On the other hand, Hazelcast jet is an emerging distributed computing engine which competes shoulder to shoulder with Apache spark and others. \nSo this project is to add Hazelcast Jet execution engine support for Apache Gora.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5499434064936960/",
          "proposal_id": null,
          "short_description": "The Apache Gora™ an in-memory data model and persistence for big data. Gora provides a generic API to work with different datastores. Data storing,...",
          "slug": "hazelcast-jet-execution-engine-support-for-apache-gora",
          "status": "completed",
          "student_name": "Lahiru Jayasekara",
          "student_profile": null,
          "tags": [
            "api"
          ],
          "title": "Hazelcast Jet execution engine support for Apache Gora"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/GORA/GORA-527%3A+Implement+a+data+store+for+REDIS",
          "description": "<p>Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. So, It is better if Apache Gora can use redis DB as well. Then this proposal is mainly dedicated to providing Redis compatibility for Gora. For such, there is a need to implement a new datastore, and Apache Gora gives a great facility for this.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/6142988273582080/",
          "proposal_id": null,
          "short_description": "Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. So, It is better if Apache Gora...",
          "slug": "gora-527-implement-a-data-store-for-redis",
          "status": "completed",
          "student_name": "Xavier Sumba",
          "student_profile": null,
          "tags": [
            "ai",
            "database"
          ],
          "title": "GORA-527: Implement a data store for REDIS"
        },
        {
          "code_url": "https://lists.apache.org/thread.html/aac14e34a217daf2a95e9cec774114ad33324ce6918878146f38f7d8@<dev.asterixdb.apache.org>",
          "description": "<p>AsterixDB currently attempts to perform an efficient join using a hybrid-hash-join and uses a nested-loop-join when hybrid-hash-join is not appropriate. If the data is already sorted, there may be cases where a merge join would be more efficient. This project will migrate an existing merge join from an outdated AsterixDB repository and will build a new query plan off of that to implement a parallel sort merge join for data across many partitions.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5611242465525760/",
          "proposal_id": null,
          "short_description": "AsterixDB currently attempts to perform an efficient join using a hybrid-hash-join and uses a nested-loop-join when hybrid-hash-join is not...",
          "slug": "implementing-parallel-sort-merge-join-in-asterixdb",
          "status": "completed",
          "student_name": "Stephen Ermshar",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "Implementing Parallel Sort Merge Join in AsterixDB"
        },
        {
          "code_url": "https://github.com/hy00nc/GSoC2019/blob/master/FinalReport.md",
          "description": "<p>This project aims to optimize Apache Nemo I/O with two main approaches:</p>\n<ul>\n<li>Providing I/O using high-performance networking and storage hardware such as RDMA and NVMe by integrating <strong>Apache Crail</strong> to Nemo and</li>\n<li>Utilizing <strong>off-heap memory</strong> for storing serialized data (e.g. intermediate data) to alleviate JVM garbage collection overhead and use <strong>zero-copy</strong> for transferring these off-heap data between workers to reduce unnecessary data copies.</li>\n</ul>\n",
          "difficulty": "medium",
          "id": "proj_the-apache-software-_2019_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/4554188468518912/",
          "proposal_id": null,
          "short_description": "This project aims to optimize Apache Nemo I/O with two main approaches:\n\nProviding I/O using high-performance networking and storage hardware such as...",
          "slug": "empower-apache-nemo-io-with-new-hardware-and-off-heap-memory",
          "status": "completed",
          "student_name": "Haeyoon Cho",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Empower Apache Nemo I/O with new hardware and off-heap memory"
        },
        {
          "code_url": "https://github.com/apache/mnemonic/pull/118",
          "description": "<p>Apache Mnemonic is a non-volatile hybrid memory storage oriented library and it proposes a non-volatile/durable Java object model and durable computing service that bring several advantages to significantly improve the performance of massive real-time data processing/analytics and helps to build cache-less and SerDe-less high performance applications. Mnemonic has two memory service based on “NVML”. On december 2017 NVML has changed it’s name into PMDK and has also started growing its libraries and tools. So, we need to upgrade Mnemonic volatile and nonvolatile memory service according to PMDK libraries. PMDK is tuned and validated on both Linux and Windows, the libraries build on the DAX feature of those operating systems which allows applications to access persistent memory as memory-mapped files, as described in the SNIA NVM Programming Model.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_011",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/4737513996943360/",
          "proposal_id": null,
          "short_description": "Apache Mnemonic is a non-volatile hybrid memory storage oriented library and it proposes a non-volatile/durable Java object model and durable...",
          "slug": "pmdk-based-persistent-memory-service-for-mnemonic",
          "status": "completed",
          "student_name": "Afrin Jaman",
          "student_profile": null,
          "tags": [
            "java",
            "ml",
            "ui",
            "ux"
          ],
          "title": "PMDK based Persistent Memory Service for Mnemonic"
        },
        {
          "code_url": "https://gist.github.com/kangbreder/034f47e2e8015cee10b48b7c5f1b8df1",
          "description": "<p>In the previous documentation of fineract API, the source was simply an HTML  file which was maintained manually in parallel to the source code which defines REST API and therefore out of sync. To overcome the problem, Swagger documentation which is an automated tool to document REST API was introduced during GSoC. The majority of conversion of the API doc was completed and finalized during GCI 2017. However since 2017, new APIs have been added. This project aims at adding swagger document for new APIs, updating swagger document for the current APIs, improving the Swagger UI and automating the Swagger Documentation.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_012",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/6515157121892352/",
          "proposal_id": null,
          "short_description": "In the previous documentation of fineract API, the source was simply an HTML  file which was maintained manually in parallel to the source code which...",
          "slug": "swagger-documentation-for-fineract-apis",
          "status": "completed",
          "student_name": "Kang Breder Mbulle",
          "student_profile": null,
          "tags": [
            "api",
            "ml",
            "ai",
            "ui"
          ],
          "title": "Swagger Documentation for Fineract APIs"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/GORA/Final+Report%3A+%5BGORA-532%5D+Benchmark+Module+For+Apache+Gora",
          "description": "<p>Apache Gora is an opensource framework which aims to give users an easy-to-use in-memory data model and persistence for big data frameworks with data store specific mappings. The overall goal for Apache Gora is to become the standard data representation and persistence framework for big data by providing easy to use Java API for accessing data agnostic of where the data is stored. It uses Apache Avro for data serialisation and depends on mapping files specific to each datastore.</p>\n<p>In this project, we will develop a Benchmark module that will help to identify and understand the various performance characteristics of Apache Gora. It will also help to identify the overhead incurred by Gora compared to the use of native NoSQL systems. This will help in fixing bug and aid performance improvement. The performance characteristics may range from execution time to resource utilisation. The proposed module could be used to benchmark and compare native implementation vs Apache Gora implementation.</p>\n",
          "difficulty": "beginner",
          "id": "proj_the-apache-software-_2019_013",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/4872731915452416/",
          "proposal_id": null,
          "short_description": "Apache Gora is an opensource framework which aims to give users an easy-to-use in-memory data model and persistence for big data frameworks with data...",
          "slug": "benchmark-module-for-apache-gora",
          "status": "completed",
          "student_name": "Sheriffo Ceesay",
          "student_profile": null,
          "tags": [
            "java",
            "api",
            "ai"
          ],
          "title": "Benchmark Module for Apache Gora"
        },
        {
          "code_url": "https://issues.apache.org/jira/browse/NEMO-352",
          "description": "<h6>This project aims at improving the flexibility and resource management of Apache Nemo by dispatching Nemo executor to AWS Lambda Function.</h6>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_014",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/4878490845839360/",
          "proposal_id": null,
          "short_description": "This project aims at improving the flexibility and resource management of Apache Nemo by dispatching Nemo executor to AWS Lambda Function.",
          "slug": "support-nemo-executor-on-aws-lambda",
          "status": "completed",
          "student_name": "Zhiyuan Gao",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Support Nemo Executor on AWS Lambda"
        },
        {
          "code_url": "https://about.yasithmilinda.me/open-source.html",
          "description": "<p>This project aims to make OODT deployment and configuration management simple through implementation of a docker-based deployment tool that integrates with the existing distributed configuration management tool in OODT. The target is to first containerize the major components in OODT (file manager, resource manager and workflow manager) using Docker. Each component will then have its own Dockerfile and Maven build execution using the dockerfile-maven plugin. Next, the initial OODT deployment tool will be created using Kubernetes. Once this is done, the existing OODT Distributed Configuration Management feature will be integrated with this tool to handle dynamic configuration management. As a later step, the deployment could be upgraded to work with Helm or KNative.</p>\n<p>Through this project, OODT will gain the ability to seamlessly manage OODT components regardless of the deployment environment. Technologies including Docker, Kubernetes and Maven will be required to carry out this project.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_015",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5817813699133440/",
          "proposal_id": null,
          "short_description": "This project aims to make OODT deployment and configuration management simple through implementation of a docker-based deployment tool that...",
          "slug": "make-oodt-deployment-simple-using-docker-and-distributed-configuration-management",
          "status": "completed",
          "student_name": "Yasith Jayawardana",
          "student_profile": null,
          "tags": [
            "ml",
            "ai",
            "docker",
            "kubernetes",
            "ui"
          ],
          "title": "Make OODT Deployment Simple Using Docker and Distributed Configuration Management"
        },
        {
          "code_url": "https://gist.github.com/ebenezergraham/b0f46714b4821650db62cb68b03f50f2",
          "description": "<p>Apache Fineract CN is currently using HIbernate as it Object-Relational Mapping. However, Hibernate's license is not compliant with the Apache license. Therefore this project seeks to remove all Hibernate specific code and dependencies and replace them with core Java and EclipseLink equivalents to make Fineract CN fully Apache compliant.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_016",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5906535694204928/",
          "proposal_id": null,
          "short_description": "Apache Fineract CN is currently using HIbernate as it Object-Relational Mapping. However, Hibernate's license is not compliant with the Apache...",
          "slug": "object-relational-mapping-migration",
          "status": "completed",
          "student_name": "Graham",
          "student_profile": null,
          "tags": [
            "java",
            "ui"
          ],
          "title": "Object-relational Mapping Migration"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/GORA/GORA-485+Apache+Kudu+datastore+for+Gora+Reports",
          "description": "<p>This project aims to integrate Kudu (a columnar storage manager developed for the Apache Hadoop platform) into the Apache Gora project as a DataStore Backend. This project will pursuit one of the main objectives of Gora which is to support as many NoSQL databases as possible into its environment through the Object-to-Datastore Mapping concept.  Moreover, the inclusion of Apache Kudu will open new opportunities and flexibility for Gora's users that need more specialized solutions and variety in development alternatives.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2019_017",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5979318746873856/",
          "proposal_id": null,
          "short_description": "This project aims to integrate Kudu (a columnar storage manager developed for the Apache Hadoop platform) into the Apache Gora project as a DataStore...",
          "slug": "gora-485-apache-kudu-datastore-for-gora",
          "status": "completed",
          "student_name": "John Javier Mora Vivar",
          "student_profile": null,
          "tags": [
            "ai",
            "database",
            "ui",
            "backend"
          ],
          "title": "GORA-485 Apache Kudu datastore for Gora"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2019/organizations/5617445421711360/"
    },
    "year_2020": {
      "num_projects": 17,
      "projects": [
        {
          "code_url": "https://gist.github.com/thesmallstar/265d4f75a3a91bedb6acbf54b3e67cf9",
          "description": "<p>The project aims to make Fineract more robust by fixing Issues/feature Requests in Backlog. The major part of this project include work on making swagger-UI usable, adding checkstyle modules, removing SQL statement string concatenation, and fixing planned issues.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/6593169975672832/",
          "proposal_id": null,
          "short_description": "The project aims to make Fineract more robust by fixing Issues/feature Requests in Backlog. The major part of this project include work on making...",
          "slug": "making-fineract-more-robust",
          "status": "completed",
          "student_name": "Manthan Raju Surkar",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Making Fineract More Robust"
        },
        {
          "code_url": "https://github.com/apache/gora/pull/219",
          "description": "<p>RethinkDB is a popular implementation for document store which is being used extensively in modern real time applications. Detailed technical comparison between RethinkDB and MongoDB as a document persistent store solution is available on reference. [1] There are a number of benefits of RethinkDB as it developed focusing on developer oriented and operations oriented mindset. [2] Apache Gora currently supports MongoDB and CouchDB as document stores, this project is aimed to further extend the datastore support for RethinkDB.\n[1] <a href=\"https://rethinkdb.com/docs/comparison-tables/\" target=\"_blank\">https://rethinkdb.com/docs/comparison-tables/</a>\n[2] <a href=\"https://rethinkdb.com/blog/mongodb-biased-comparison/\" target=\"_blank\">https://rethinkdb.com/blog/mongodb-biased-comparison/</a></p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5720601970343936/",
          "proposal_id": null,
          "short_description": "RethinkDB is a popular implementation for document store which is being used extensively in modern real time applications. Detailed technical...",
          "slug": "apache-gora-implement-rethinkdb-datastore-module",
          "status": "completed",
          "student_name": "Rumesh Perera",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Apache Gora - Implement RethinkDB datastore module"
        },
        {
          "code_url": "https://medium.com/@nayanangamuhandiram/my-final-submission-of-gsoc-2020-camel-minio-component-for-apache-camel-d2318e2eaa4f?sk=7bc78b4689cf4eef88a713f3e1a6ccdf",
          "description": "<p>I have decided to select the project,\ncamel-minio - Component to store/load files from blob store(<a href=\"https://issues.apache.org/jira/browse/CAMEL-13934\" target=\"_blank\">https://issues.apache.org/jira/browse/CAMEL-13934</a>)</p>\n<p>Camel simplifies service integrations with an easy-to-use DSL to create routes that clearly identify the integration intentions and endpoints. Camel's out-of-the-box integration components are modeled after the Enterprise Integration Patterns cataloged in Gregor Hohpe and Bobby Wolf's book (<a href=\"http://www.eaipatterns.com\" target=\"_blank\">http://www.eaipatterns.com</a>). Camel allows you to integrate with quite a few protocols and systems out of the box using Camel components. Each component is highly flexible and can be easily configured using Camel's consistent URI syntax. In this project I`m going to add one more component to the camel components collection hopefully it will be a popular and widely used component.</p>\n",
          "difficulty": "beginner",
          "id": "proj_the-apache-software-_2020_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/6158627733241856/",
          "proposal_id": null,
          "short_description": "I have decided to select the project,\ncamel-minio - Component to store/load files from blob store(https://issues.apache.org/jira/browse/CAMEL-13934)...",
          "slug": "camel-13934-camel-minio-component-to-storeload-files-from-blob-store",
          "status": "completed",
          "student_name": "Nayananga Muhandiram",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "CAMEL-13934 camel-minio - Component to store/load files from blob store"
        },
        {
          "code_url": "https://gist.github.com/cherbel/6eccbc5fa33d78bcef1cca6f56175a18",
          "description": "<p>AsterixDB currently performs interval joins but it is not optimized; the database uses a nested loop when an interval join is required. In the process of learning more about Asterix I was shown an out-of-date, never merged branch that implemented an optimized version of interval join. The goal of my project is to update and migrate that interval join code into the active repository. The first part of my project will be to merge the interval join code into my own branch, update it, and update the interval optimization rules. The second part of the project is to update the query parser so that Asterix will run an interval join using the new query plan. The last stage of my plan is to update/create any tests that need to be modified, and perform full scale testing.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5007141632475136/",
          "proposal_id": null,
          "short_description": "AsterixDB currently performs interval joins but it is not optimized; the database uses a nested loop when an interval join is required. In the...",
          "slug": "interval-join-in-asterixdb",
          "status": "completed",
          "student_name": "Caleb Herbel",
          "student_profile": null,
          "tags": [
            "database",
            "ui"
          ],
          "title": "Interval Join in AsterixDB"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/AIRAVATA/User+Storage+Quotas+and+MFT+Dashboard",
          "description": "<p>Airavata based science gateways store data in the gateway storage which is typically mounted in the portal's hosting server. Each user's data is organized within user directories on these storage devices. As storage reaches its limits, it often creates an issue in rationing the disks. So, a single user running a finite number of experiments can adversely cause issues for other users in the gateway.</p>\n<p>This is similar to modern memory attacks. A hacker can write a script that continuously creates new experiments causing the storage space in the gateway to be depleted.</p>\n<p>The goal of this project is to mitigate such scenarios by implementing a storage limit for each user in a gateway. This way, one user can never adversely affect other users.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5046913029636096/",
          "proposal_id": null,
          "short_description": "Airavata based science gateways store data in the gateway storage which is typically mounted in the portal's hosting server. Each user's data is...",
          "slug": "implementing-storage-limits-for-multiple-types-of-storages",
          "status": "completed",
          "student_name": "vivek",
          "student_profile": null,
          "tags": [
            "ios",
            "ai"
          ],
          "title": "Implementing Storage limits for multiple types of storages"
        },
        {
          "code_url": "https://gist.github.com/xurror/9fc6a93e2234dcd546b9d92ba44be28e",
          "description": "<p>In line with the rationale for choosing EclipseLink as the ORM replacement for Hibernate in FineractCN, we have broad consensus across the community to swap out OpenJPA with EclipseLink.\nOpenJPA seems to have reached its end of life with community activity withering and the trade-offs between Hibernate and EclipseLink are much lower. We also have community members who are migrating Fineract 1.x to PostGreSQL and would benefit from the increased performance with EclipseLink.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5087537648893952/",
          "proposal_id": null,
          "short_description": "In line with the rationale for choosing EclipseLink as the ORM replacement for Hibernate in FineractCN, we have broad consensus across the community...",
          "slug": "migrate-fineract-orm-from-openjpa-to-eclipselink",
          "status": "completed",
          "student_name": "Yemdjih Kaze Nasser",
          "student_profile": null,
          "tags": [],
          "title": "Migrate Fineract ORM from OpenJPA to EclipseLink"
        },
        {
          "code_url": "https://gist.github.com/percyashu/98b0f7cc7f475b1515a5cae8a22320f4",
          "description": "<p>Strengthen/Harden Fineract 1.x  by integration static analysis tool  Error Prone and enforce code checks; Migrate from Joda time to new Java 8 Date/Time API and  Improving Code Coverage of Tests so as to improved functionality and increased stability of the core Fineract platform.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5102710392619008/",
          "proposal_id": null,
          "short_description": "Strengthen/Harden Fineract 1.x  by integration static analysis tool  Error Prone and enforce code checks; Migrate from Joda time to new Java 8...",
          "slug": "strengthenharden-fineract-1x",
          "status": "completed",
          "student_name": "Percy Enoabane",
          "student_profile": null,
          "tags": [
            "java",
            "api"
          ],
          "title": "Strengthen/Harden Fineract 1.x"
        },
        {
          "code_url": "https://gist.github.com/AldairCoronel/a0e0987fd5f386ed9a402ebd70a30bdd",
          "description": "<p>Currently, Apache Beam Python SDK has already got support for Google Cloud Storage and Amazon Web Services S3. This project aims to add support for the Azure Blobstore filesystem to the Python SDK.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5112694748741632/",
          "proposal_id": null,
          "short_description": "Currently, Apache Beam Python SDK has already got support for Google Cloud Storage and Amazon Web Services S3. This project aims to add support for...",
          "slug": "implement-an-azure-blobstore-filesystem-for-python-sdk",
          "status": "completed",
          "student_name": "Aldair Coronel Ruiz",
          "student_profile": null,
          "tags": [
            "python",
            "web",
            "ai",
            "cloud"
          ],
          "title": "Implement an Azure blobstore filesystem for Python SDK"
        },
        {
          "code_url": "https://beta.geogateway.scigap.org/geogateway_django_app/",
          "description": "<p>This proposal focuses on developing a prototype in Electron.js of the SEAGrid native application, currently implemented in JavaFX. Once prototyped, translation from Django based web applications to native Electron applications can be generalized to an Electron based Airvata Framework. An Electron based Airvata Framework will allow for quick translation from Django based web-apps for specific Science Gateway applications and provide a more stable platform with larger community support.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/4663367148503040/",
          "proposal_id": null,
          "short_description": "This proposal focuses on developing a prototype in Electron.js of the SEAGrid native application, currently implemented in JavaFX. Once prototyped,...",
          "slug": "electronjs-for-native-airvata-applications",
          "status": "completed",
          "student_name": "Nicholas Mowery",
          "student_profile": null,
          "tags": [
            "java",
            "web",
            "ai",
            "ui"
          ],
          "title": "Electron.js for Native Airvata Applications"
        },
        {
          "code_url": "https://gist.github.com/a-rekkusu/b98ecd201d25102ca3e118a2fa38fbb4",
          "description": "<p>CDI (Contexts and Dependency Injection) is an IoC (Inversion of Control) container, that is implemented in Apache OWB (OpenWebBeans). Even though there is an existing micro HTTP server that supports CDI capabilities in the Apache world (Meecrowave), it is not IoC centric and it has a lot more features than the basics. Furthermore, it is not runnable as a native executable – there’s always the big JVM necessary. \nThe proposal is to build a much slimmer HTTP API and implement it in a project with CDI (OpenWebBeans) as the starting point and webserver components (Netty) on top. This can then be injected as a managed bean in the web application. It would be an even more minimalistic microserver and IoC centric.\nMaking this then natively runnable as a native executable for Windows is delivering important work for future JakartaEE projects within Apache, that need to be turned into a native image (via GraalVM). At the moment, there is little to none such experience in the project.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/4751252849688576/",
          "proposal_id": null,
          "short_description": "CDI (Contexts and Dependency Injection) is an IoC (Inversion of Control) container, that is implemented in Apache OWB (OpenWebBeans). Even though...",
          "slug": "building-an-injectable-ioc-centric-small-and-lightweight-http-server-and-making-it-runnable-as-a-native-executable-jira-owb-1319",
          "status": "completed",
          "student_name": "Alexander Fischer",
          "student_profile": null,
          "tags": [
            "web",
            "api",
            "ai",
            "ui"
          ],
          "title": "Building an injectable IoC centric, small and lightweight HTTP server  and making it runnable as a native executable [Jira: OWB-1319]"
        },
        {
          "code_url": "https://github.com/apache/gora/pull/222",
          "description": "<p>Apache Gora currently has support for JCache datastore which can be used with any JCache provider like Hazelcast. However JCache API does not expose details on data locality on how keys of data is distributed across the cluster. However Hazelcast IMap native api does expose these details and can be used to leverage data locality which is heavily useful to achieve performance gains in distributed processing. Hazelcast IMap datastore support is introduced to overcome these limitations in Apache Gora JCache datastore.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_011",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/4794290636587008/",
          "proposal_id": null,
          "short_description": "Apache Gora currently has support for JCache datastore which can be used with any JCache provider like Hazelcast. However JCache API does not expose...",
          "slug": "hazelcast-imap-backed-datastore-for-apache-gora",
          "status": "completed",
          "student_name": "Saviyo Perera",
          "student_profile": null,
          "tags": [
            "api",
            "ai"
          ],
          "title": "Hazelcast IMap backed datastore for Apache Gora"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/AIRAVATA/User+Interface+for+Airavata+Managed+File+Transfer+Service",
          "description": "<p>Airavata Managed File Transfer (MFT) (<a href=\"https://github.com/apache/airavata-mft\" target=\"_blank\">https://github.com/apache/airavata-mft</a>) is the Apache Airavata’s own Data Movement Implementation Framework to avoid traffic flowing through the Airavata Server when moving the data from one cloud storage to another cloud storage as the moving out the cloud storage to another network seem’s costly with external cloud providers like Azure, AWS, etc due to the increase of the egress traffic.</p>\n<p>The Goal of the project is to design a user interface using Django for the recently developed new feature MFT ( Managed File Transfer ) of Airavata as per the Mock UX Graphical version developed and available in the Jira EPIC mentioned below.</p>\n<p>(<a href=\"https://issues.apache.org/jira/browse/AIRAVATA-3314\" target=\"_blank\">https://issues.apache.org/jira/browse/AIRAVATA-3314</a>)</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_012",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/4904320115408896/",
          "proposal_id": null,
          "short_description": "Airavata Managed File Transfer (MFT) (https://github.com/apache/airavata-mft) is the Apache Airavata’s own Data Movement Implementation Framework to...",
          "slug": "user-interface-for-airavata-managed-file-transfer-service",
          "status": "completed",
          "student_name": "Akhil nagulavancha",
          "student_profile": null,
          "tags": [
            "ai",
            "cloud",
            "ux"
          ],
          "title": "User Interface for Airavata Managed File Transfer Service"
        },
        {
          "code_url": "https://github.com/apache/camel/pull/3934",
          "description": "<p>This proposal aims to implement an OAI-PMH component for Apache Camel. OAI-PMH is a protocol widely used in libraries and digital repositories across the world. This implementation will be extremely useful for final users working on data integration this domain.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_013",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5843083465326592/",
          "proposal_id": null,
          "short_description": "This proposal aims to implement an OAI-PMH component for Apache Camel. OAI-PMH is a protocol widely used in libraries and digital repositories across...",
          "slug": "apache-camel-oai-pmh-component",
          "status": "completed",
          "student_name": "Juan Segarra",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Apache Camel - OAI-PMH Component"
        },
        {
          "code_url": "https://docs.google.com/document/d/1jzQN4KuV92C2FtJ3pIP3HuGeDa_8GeBrts8Bp68mv3k/edit?usp=sharing",
          "description": "<p><code>Match_Recogniztion</code> syntax was introduced in SQL in 2016. It turned out to be very useful in data analysis. Currently, Beam SQL does not support this syntax. The goal of this project is to implement this feature for Beam SQL.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_014",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5936301435518976/",
          "proposal_id": null,
          "short_description": "Match_Recogniztion syntax was introduced in SQL in 2016. It turned out to be very useful in data analysis. Currently, Beam SQL does not support this...",
          "slug": "implementing-pattern-recognition-function-in-beam-sql",
          "status": "completed",
          "student_name": "Qihang Zeng",
          "student_profile": null,
          "tags": [],
          "title": "Implementing Pattern Recognition Function in Beam SQL"
        },
        {
          "code_url": "https://github.com/apache/beam/pull/11975",
          "description": "<p>This project aims to add support for aggregation analytics functions (a.k.a window functions) to the SQLBeam module of the Apache Beam project. The implementation of these function will ease the creation of pipelines that need aggregation procedures described in SQL.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_015",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/6286692517937152/",
          "proposal_id": null,
          "short_description": "This project aims to add support for aggregation analytics functions (a.k.a window functions) to the SQLBeam module of the Apache Beam project. The...",
          "slug": "beamsql-aggregation-analytics-functionality",
          "status": "completed",
          "student_name": "John Mora",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "BeamSQL aggregation analytics functionality"
        },
        {
          "code_url": "https://github.com/apache/gora/pull/221",
          "description": "<p>Scylla is an open-source distributed NoSQL data store. It was designed to achieve significantly higher throughputs and lower latencies. Apache Gora is a Object to datastore mapping data persistence framework. This proposal is about to support Scylla DB in Apache Gora</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2020_016",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5176655267495936/",
          "proposal_id": null,
          "short_description": "Scylla is an open-source distributed NoSQL data store. It was designed to achieve significantly higher throughputs and lower latencies. Apache Gora...",
          "slug": "implement-scylla-db-datastore-for-apache-gora",
          "status": "completed",
          "student_name": "Arne",
          "student_profile": null,
          "tags": [],
          "title": "Implement Scylla DB Datastore for Apache Gora"
        },
        {
          "code_url": "https://github.com/apache/gora/pull/218",
          "description": "<p>Multi model databases are becoming more popular due its native support for polyglot persistence. Polyglot Persistence is a term to mean that when storing data, it is best to use multiple physical data models, chosen based upon the way data is being used by individual applications or components of a single application. Multi model databases acknowledge the need for multiple data models, combining them to reduce operational complexity, operational costs, extensibility and  maintain data consistency. Apache Gora currently supports OrientDB datastore as a multi model database, the project proposes further extending multi model database support with ArangoDB</p>\n",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2020_017",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5187038518706176/",
          "proposal_id": null,
          "short_description": "Multi model databases are becoming more popular due its native support for polyglot persistence. Polyglot Persistence is a term to mean that when...",
          "slug": "implement-arangodb-multi-model-data-store-for-apache-gora",
          "status": "completed",
          "student_name": "Dinuka Perera",
          "student_profile": null,
          "tags": [
            "ai",
            "database"
          ],
          "title": "Implement ArangoDB multi-model data store for Apache Gora"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2020/organizations/6679967372410880/"
    },
    "year_2021": {
      "num_projects": 28,
      "projects": [
        {
          "code_url": "https://gist.github.com/BLasan/9c624bf4e5230b17c1dc4711301097f6",
          "description": "<p>Proposal is about improving the robustness of MifosX and Apache Fineract by fixing issues/feature requests from the backlog. There're currently 5 issues attached to this idea. Some of them contain UI improvements as well as the server side implementations. A new feature  \"Collateral Module\" which is an enhancement of collateral management will also be implemented during this summer.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/6385348753489920/",
          "proposal_id": null,
          "short_description": "Proposal is about improving the robustness of MifosX and Apache Fineract by fixing issues/feature requests from the backlog. There're currently 5...",
          "slug": "improve-robustness-by-fixing-issues-feature-requests-from-the-backlog",
          "status": "completed",
          "student_name": "Benura Abeywardena",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Improve Robustness by fixing Issues / Feature Requests from the backlog"
        },
        {
          "code_url": "https://gist.github.com/fgksgf/27d7d8d90fc688bdfb686c4387240e14",
          "description": "<p>Currently, the basic structural verification of CRD has been completed in APISIX Ingress Controller, but more verification is still needed. For example, plug-in schema verification, dependency verification between APISIX objects, rule conflict verification, etc. In this project, I will enhance the verification for APISIX Ingress Controller by implementing validating admission webhooks, which can avoid some errors caused by YAML when the user defines the CRD.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/6468310341779456/",
          "proposal_id": null,
          "short_description": "Currently, the basic structural verification of CRD has been completed in APISIX Ingress Controller, but more verification is still needed. For...",
          "slug": "enhance-verification-for-apisix-ingress-controller",
          "status": "completed",
          "student_name": "Huaxi Jiang",
          "student_profile": null,
          "tags": [
            "web",
            "api",
            "ml"
          ],
          "title": "Enhance verification for APISIX ingress controller"
        },
        {
          "code_url": "https://github.com/miador/clerezza-signal",
          "description": "<p>The purpose of this task is to define an ontology for conversations and to create a Java library based on Apache Clerezza to store them. Signal (<a href=\"https://signal.org/docs/\" target=\"_blank\">https://signal.org/docs/</a>) is one of many messaging apps which is open source. This task recommends to integrate the library to be developed into Signal (<a href=\"https://github.com/signalapp\" target=\"_blank\">https://github.com/signalapp</a>) for testing.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5668477070737408/",
          "proposal_id": null,
          "short_description": "The purpose of this task is to define an ontology for conversations and to create a Java library based on Apache Clerezza to store them. Signal...",
          "slug": "application-proposal-for-apache-clerezza",
          "status": "completed",
          "student_name": "Yusuf Karadag",
          "student_profile": null,
          "tags": [
            "java"
          ],
          "title": "Application Proposal for Apache Clerezza"
        },
        {
          "code_url": "https://github.com/apache/cloudstack/pull/5216",
          "description": "<p>Currently, cloudstack does not have an option for the user to clone a VM. In order to achieve a full clone, we have to manually handle it by using snapshots, new disk and then new attachment. The manual way of creating a VM causes extra overhead for the user like the temporary snapshots should also be manually cleaned up after the steps. This may influence the reliability of the system since issues may increase for a missing step.\nThis proposal aims to integrate all these steps into one API and one UI interface and the whole project focus consists of mainly three parts:</p>\n<ul>\n<li>An independent integrated full clone API (adapt to different hypervisors, ones support clone and ones doesn’t)</li>\n<li>An UI interface providing the clone option</li>\n<li>Implementation steps for updating the related db information table</li>\n</ul>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5669923870736384/",
          "proposal_id": null,
          "short_description": "Currently, cloudstack does not have an option for the user to clone a VM. In order to achieve a full clone, we have to manually handle it by using...",
          "slug": "proposal-for-cloudstack-cloning-a-vm",
          "status": "completed",
          "student_name": "Junxuan Wu",
          "student_profile": null,
          "tags": [
            "api",
            "ai",
            "cloud",
            "ui"
          ],
          "title": "Proposal for cloudstack: cloning a VM"
        },
        {
          "code_url": "https://github.com/apache/dolphinscheduler/pull/6027",
          "description": "<p>Currently parameter configuration of DolphinScheduler is mainly based on configuration files. However there’s no way to override parameters when the same parameter is passed as JVM parameter at server startup. This project is about introducing parameter injection from java JVM arguments to server runtime,  so that one can override a particular parameter which is externalised to a configuration file.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5696192259817472/",
          "proposal_id": null,
          "short_description": "Currently parameter configuration of DolphinScheduler is mainly based on configuration files. However there’s no way to override parameters when the...",
          "slug": "comdev-412-apache-dolphinscheduler-parameter-coverage",
          "status": "completed",
          "student_name": "nrumeshp",
          "student_profile": null,
          "tags": [
            "java",
            "ai"
          ],
          "title": "COMDEV-412 Apache DolphinScheduler Parameter coverage"
        },
        {
          "code_url": "https://docs.google.com/document/d/1uRSKex-8fNoYdj4skx2UXtciRDj5Hf7kQiXqPA4Jqso",
          "description": "<p>Project proposal on issue#4813 about holding multiple SSH keys.\nAs of now, ACS supports only a single SSH key to be added / reset on a VM. Here I propose a project on support of multiple SSH Keys.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5728925379985408/",
          "proposal_id": null,
          "short_description": "Project proposal on issue#4813 about holding multiple SSH keys.\nAs of now, ACS supports only a single SSH key to be added / reset on a VM. Here I...",
          "slug": "multiple-ssh-key-holding-on-cloudstack",
          "status": "completed",
          "student_name": "Bikram Biswas-1",
          "student_profile": null,
          "tags": [
            "cloud"
          ],
          "title": "Multiple SSH key holding on CloudStack"
        },
        {
          "code_url": "https://gist.github.com/varsvat/be08d5234770b1c22d809177564a6276",
          "description": "<p>The <strong>Fineract-cn-mobile</strong> application is the Android client of Apache Fineract CN, built on top of the FIneract CN Platform. It provides banking solutions for people around the world who are unbacked. This app is for field officers who go to their customers and provide them with financial services.</p>\n<p><strong>Achieved Goals:</strong></p>\n<p>-&gt; Added support for all the Teller functionalities such as creating, editing, Viewing Tellers.</p>\n<p>-&gt; Improved offline functionality in the application via Couchbase Implementation.</p>\n<p>-&gt; Added support for viewing, creating and editing products.</p>\n<p>-&gt; Added support for various Account-related functionalities, including viewing, creating and editing accounts. Also added support to lock, close, and reopen Accounts.</p>\n<p>-&gt; Added Task management features for the Tellers, Account and products section.</p>\n<p>-&gt;  Extended the Kotlin support in App and replaced the already implemented MVP architecture with the Google recommended Model-View-View-Model (MVVM) architecture. Also extended.</p>\n<p>-&gt; Added UI/Integration tests.</p>\n<p><strong>Work in progress:</strong></p>\n<p>-&gt; UI for payment-hub integration is almost complete; APIs would be integrated once ready.</p>\n<p>-&gt; Improve GIS features once the Endpoints are made.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5754030134919168/",
          "proposal_id": null,
          "short_description": "The Fineract-cn-mobile application is the Android client of Apache Fineract CN, built on top of the FIneract CN Platform. It provides banking...",
          "slug": "functional-enhancements-to-fineract-cn-mobile-application",
          "status": "completed",
          "student_name": "Varun Jain",
          "student_profile": null,
          "tags": [
            "android",
            "mobile",
            "api",
            "ui"
          ],
          "title": "Functional Enhancements To Fineract CN Mobile Application"
        },
        {
          "code_url": "https://github.com/n-jay/gsoc-2021/tree/feature1",
          "description": "<p>The Apache Synapse ESB currently exists as a standard server runtime, the same state it’s been since inception. However cloud native technologies have in the meantime advanced significantly and concepts such as containerisation have been introduced.\nContainerisation brings with it several benefits such as portability, scalability, faster deployment &amp; increased security.</p>\n<p>This project aims to containerise Apache Synapse while not being detrimental to its current features and capabilities.</p>\n",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2021_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5088417175568384/",
          "proposal_id": null,
          "short_description": "The Apache Synapse ESB currently exists as a standard server runtime, the same state it’s been since inception. However cloud native technologies...",
          "slug": "containerisation-of-apache-synapse-esb",
          "status": "completed",
          "student_name": "Nuwan Jayawardene",
          "student_profile": null,
          "tags": [
            "ai",
            "cloud"
          ],
          "title": "Containerisation of Apache Synapse ESB"
        },
        {
          "code_url": "https://github.com/apache/cassandra/pull/1046",
          "description": "<p>Currently Cassandra can create snapshots of SSTables containing all data of concrete Column Family (Analogue of the table into RDBMS).Snapshot is a copy of original data, represented by the hard link.They can be created before each compaction or before keyspace truncation.User also can manually create snapshot via nodetool snapshot command. After snapshot creation it is not managed by Cassandra.The goal of the task is to make it possible to set TTL to snapshot and automatically delete it after it’s expiration.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5128135825162240/",
          "proposal_id": null,
          "short_description": "Currently Cassandra can create snapshots of SSTables containing all data of concrete Column Family (Analogue of the table into RDBMS).Snapshot is a...",
          "slug": "add-ttl-for-cassandra-snapshots",
          "status": "completed",
          "student_name": "fibersel",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Add ttl for cassandra snapshots"
        },
        {
          "code_url": "https://gist.github.com/danishjamal104/ddb099d5f7985dc08537db658c178a81",
          "description": "<p>A Java and Retrofit2 based library, which mainly focuses on building an abstraction layer over the fineract API. Currently, all the MIFOS application uses fineract API and has a lot of repeated code for API integration hence the main motive of this project was to eliminate the boilerplate API integration code and provide an SDK with proper and comprehensive documentation so that it can be easily integrated with all the MIFOS's front end application. \nThis summer I will be spending most of my time automating the steps that are currently used for generating API. Some of them are creating templates, publishing documents, improving CI/CD, etc. Apart from that this year's end goal is to release the SDK for <a href=\"https://github.com/apache/fineract/releases\" target=\"_blank\">fineract 1.4.0 or 1.5.0</a> whichever the latest is until then.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5246508378619904/",
          "proposal_id": null,
          "short_description": "A Java and Retrofit2 based library, which mainly focuses on building an abstraction layer over the fineract API. Currently, all the MIFOS application...",
          "slug": "fineract-client",
          "status": "completed",
          "student_name": "Danish Jamal",
          "student_profile": null,
          "tags": [
            "java",
            "api",
            "ai",
            "ui"
          ],
          "title": "Fineract Client"
        },
        {
          "code_url": "https://github.com/apache/incubator-nemo/pull/312,",
          "description": "<p>This project aims to optimize the performance of Nemo by dynamically splitting skewed tasks of a job based on the information collected from runtime metrics, executing them in parallel, and merging them afterwards. The goal is achieved through the following four steps: First, gather relevant metrics during execution. Second, using the gathered statistics, determine which task is skew(i.e. needs a longer time to finish) periodically. Third, Split the skewed tasks in half and allocate the latter splitted half to the new task. And lastly, execute the new task and check its performance.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_011",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5555996843311104/",
          "proposal_id": null,
          "short_description": "This project aims to optimize the performance of Nemo by dynamically splitting skewed tasks of a job based on the information collected from runtime...",
          "slug": "implementing-work-stealing-on-nemo",
          "status": "completed",
          "student_name": "Hwarim Hyun",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Implementing Work Stealing on Nemo"
        },
        {
          "code_url": "https://gist.github.com/fhuzero/a913eb2ae3cddb04b0019dc95c0daebe",
          "description": "<p>Knative is an extension of Kubernetes and is specifically designed for serverless workloads. Knative Serving, as one of the core components of Knative, runs scalable containers based on ingress gateway as its network layer to route traffic and control the flow of API calls. Currently, Istio is the default ingress gateway of Knative Serving. Other community-based gateway implementations such as Kong and Gloo are also supported.</p>\n<p>APISIX, a dynamic, real-time, and high-performance API gateway, comes with an ingress controller which can be used in Kubernetes. The ingress controller of APISIX, however, has no support for Knative. This limits its use scenarios. This project aims at providing support for APISIX for Knative. Main tasks include</p>\n<ol>\n<li>understanding the mechanism of Knative Serving and APISIX ingress controller.</li>\n<li>Implement support for APISIX as Knative ingress gateway</li>\n<li>Writing tests documentation, or articles for the newly added feature</li>\n</ol>\n<p>As a result, APISIX ingress controller will be an alternative Knative network layer to manage ingress traffic.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_012",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/6199699496763392/",
          "proposal_id": null,
          "short_description": "Knative is an extension of Kubernetes and is specifically designed for serverless workloads. Knative Serving, as one of the core components of...",
          "slug": "apisix-ingress-controller-integration-with-knative-serving",
          "status": "completed",
          "student_name": "Fang Hu",
          "student_profile": null,
          "tags": [
            "ios",
            "api",
            "ai",
            "kubernetes"
          ],
          "title": "APISIX ingress controller integration with Knative Serving"
        },
        {
          "code_url": "https://lemarais.github.io/gsoc/2021/08/24/GSoC-final-evaluation.html",
          "description": "<p>This is a project that develops a simulator consisting of an executor model abstracted based on statistics and a scheduler model that are executed like actual running with manually managed timeline. Directly, this project can increase the reliability of nemo. Indirectly it can contribute to speed up future projects and be a springboard to future projects.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_013",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/6209738378838016/",
          "proposal_id": null,
          "short_description": "This is a project that develops a simulator consisting of an executor model abstracted based on statistics and a scheduler model that are executed...",
          "slug": "incubator-nemo-accurate-task-execution-simulator-for-distributed-data-processing",
          "status": "completed",
          "student_name": "Hae Dong Lee",
          "student_profile": null,
          "tags": [],
          "title": "[Incubator-Nemo] Accurate Task Execution Simulator for Distributed Data Processing"
        },
        {
          "code_url": "https://gist.github.com/1502shivam-singh/08dfa68024c4503f12cc22df81c4ff96",
          "description": "<p>I propose my project idea relating to Apache APISIX growth, titled <strong>\"Redesign, develop and refactor Apache APISIX landing page and documentation website\"</strong>.\nMain reasons for me to propose this project are -</p>\n<ul>\n<li>Website doesn’t show the most important features of APISIX</li>\n<li>Website lacks a secondary call-to-action (After download) to the docs for which the website is made for.</li>\n<li>Website lacks the amount of information needed to explain the usefulness of APISIX and why it is better.</li>\n<li>The copywriting in certain sections of the website is too long (description section)</li>\n<li>Website lacks accessibility in images. For instance, the APISIX architecture image is not clear on desktop.</li>\n<li>Website lacks visual design as a whole, when compared to other SaaS product websites.</li>\n</ul>\n<p>Considering the above issues, it is essential that a redesign is needed to solve this, because to solve them would require a rework of the design and copywriting in the website.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_014",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/4768141195870208/",
          "proposal_id": null,
          "short_description": "I propose my project idea relating to Apache APISIX growth, titled \"Redesign, develop and refactor Apache APISIX landing page and documentation...",
          "slug": "redesign-develop-and-refactor-apisix-landing-page",
          "status": "completed",
          "student_name": "ShivamSingh",
          "student_profile": null,
          "tags": [
            "web",
            "api",
            "ai",
            "ui"
          ],
          "title": "Redesign, develop and refactor APISIX landing page"
        },
        {
          "code_url": "https://gist.github.com/xurror/bba79ecbf063dd8eae8ee9c24732701e",
          "description": "<p>Financial Organizations using Mifos/Fineract are depending on external agencies or their past experiences for evaluating credit scoring and identification of potential NPAs. Though information from external agencies is required, financial organizations can have an internal scorecard for evaluating loans so that preventive/proactive actions can be done along with external agencies reports. In industry, organizations are using rule based, Statistical and Machine learning methods for credit scoring, predicting potential NPAs, fraud detection and other activities. This project aims to implement a scorecard based on statistical and ML methods for credit scoring and identification of potential NPAs.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_015",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/6114688672202752/",
          "proposal_id": null,
          "short_description": "Financial Organizations using Mifos/Fineract are depending on external agencies or their past experiences for evaluating credit scoring and...",
          "slug": "machine-learning-credit-scorecard-phase-4",
          "status": "completed",
          "student_name": "Nasser Yemdjih Kaze",
          "student_profile": null,
          "tags": [
            "ml",
            "ai",
            "ui"
          ],
          "title": "Machine Learning Credit Scorecard PHASE 4"
        },
        {
          "code_url": "https://kangji.github.io/nemo-wan-hierarchical-aggregation/",
          "description": "<p>This GSOC project aims to optimize Nemo execution by performing hierarchical aggregation and controlling its fidelity based on the distance of a geo-distributed data processing environment. The project consists of four main tasks: First, implement and check the correctness of the hierarchical aggregation. Second, evaluate the performance improvement in the point of throughput. Third, add the layer of fidelity control which varies on the different levels of hierarchy. And last, implement a learning-based model which automatically adjusts the hierarchy and fidelity level.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_016",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/4904415944769536/",
          "proposal_id": null,
          "short_description": "This GSOC project aims to optimize Nemo execution by performing hierarchical aggregation and controlling its fidelity based on the distance of a...",
          "slug": "nemo-optimization-by-wan-hierarchical-aggregation-and-fidelity-control",
          "status": "completed",
          "student_name": "Ji Ho Kang",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Nemo Optimization by WAN Hierarchical Aggregation and Fidelity Control"
        },
        {
          "code_url": "https://gist.github.com/quantranhong1999/8147f52a1b17f0461a9f1f27fc8b5303",
          "description": "<p>JMAP is an email application protocol to modernise IMAP, on top of HTTP using a JSON format. JMAP is designed to make efficient use of limited network resources and to be horizontally scalable to a very large number of users. Apache James is one of the first implementations of this new standard.</p>\n<p>Mail user agents generally allow displaying emails grouped by conversations (replies, forward, etc...). As a part of JMAP RFC-8621 implementation (<a href=\"https://tools.ietf.org/html/rfc8621#page-20\" target=\"_blank\">https://tools.ietf.org/html/rfc8621#page-20</a>), there are dedicated concepts: threads.  JMAP Threads is already implemented In Apache James in a rather naive way: each email is a thread of its own. This naive implementation is specification compliant but defeats the overall purposes of threads: emails which related to a topic should belong to a thread.</p>\n<p>James’s data models, storage APIs, and some JMAP methods at HTTP level need to be changed to make sure the purpose of the thread is reached.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_017",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/4918420021182464/",
          "proposal_id": null,
          "short_description": "JMAP is an email application protocol to modernise IMAP, on top of HTTP using a JSON format. JMAP is designed to make efficient use of limited...",
          "slug": "apache-james-implement-thread-support-for-jmap",
          "status": "completed",
          "student_name": "Hồng Quân Trần",
          "student_profile": null,
          "tags": [
            "api",
            "ml",
            "ai"
          ],
          "title": "Apache James - Implement Thread support for JMAP"
        },
        {
          "code_url": "https://github.com/apache/gora/pull/246",
          "description": "<p>Currently the gora-sql module is outdated and only supports mysql database scheme. This module can be rewritten in JOOQ in such a way that it can support any Relationshional database store [2]. JOOQ is a widely used Java framework which helps to build applications where persistence requires and is highly regarded by industry specialists over Hibernate &amp; JDBC [2]. Hibernate itself is very distant from normal sql queries and JDBC has security concerns and also too much hassle when it comes to transaction handling. JOOQ will be a very good addition to the Apache Gora project as it creates a path for Relational databases to work with apache gora seamlessly.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_018",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5762844951314432/",
          "proposal_id": null,
          "short_description": "Currently the gora-sql module is outdated and only supports mysql database scheme. This module can be rewritten in JOOQ in such a way that it can...",
          "slug": "support-jooq-api-within-gora-sql-module",
          "status": "completed",
          "student_name": "infaz",
          "student_profile": null,
          "tags": [
            "java",
            "api",
            "ml",
            "database",
            "ui"
          ],
          "title": "Support JOOQ API within gora-sql module"
        },
        {
          "code_url": "https://pavindulakshan.medium.com/gsoc-2021-improving-apache-oodt-opsui-react-js-ui-with-advanced-functionalities-8d1a8b080c8a",
          "description": "<p>This project aims to improve the functionalities of the Apache OODT OPSUI React.js User Interface and implement a REST API for the resource manager component of Apache OODT. The current OPSUI React.js dashboard which has been developed in the Apache Wicket framework will be replaced with the React.js UI on the completion of this project.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_019",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5863359534071808/",
          "proposal_id": null,
          "short_description": "This project aims to improve the functionalities of the Apache OODT OPSUI React.js User Interface and implement a REST API for the resource manager...",
          "slug": "apache-oodt-improving-opsui-reactjs-ui-with-advanced-functionalities",
          "status": "completed",
          "student_name": "Pavindu Lakshan",
          "student_profile": null,
          "tags": [
            "react",
            "api",
            "ai",
            "ui"
          ],
          "title": "Apache OODT - Improving OPSUI React.js UI with Advanced Functionalities"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/NUTTX/%5B2021%5D+NuttX+Support+for+Rapid+Control+Applications+Development+with+pysimCoder",
          "description": "<p>NuttX is a real time operating system which provides wide support for smaller and cheaper microcontrollers and development boards. PysimCoder is an open source Rapid Control Application Design tool which is able to transfer block diagrams into C code. Main goal of the project is to integrate and test pysimCoder support for various kinds of drivers supported by NuttX. The main target platform is iMXRT1060 MCU, but some other platforms like STM32 or RISC-V ESP32-C3 can also be considered for testing and demonstration.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_020",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5866655485263872/",
          "proposal_id": null,
          "short_description": "NuttX is a real time operating system which provides wide support for smaller and cheaper microcontrollers and development boards. PysimCoder is an...",
          "slug": "nuttx-support-for-rapid-control-applications-development-with-pysimcoder",
          "status": "completed",
          "student_name": "Michal Lenc",
          "student_profile": null,
          "tags": [
            "api",
            "ai"
          ],
          "title": "NuttX Support for Rapid Control Applications Development with pysimCoder"
        },
        {
          "code_url": "https://apurv-1.github.io/gsoc2021-final-report/",
          "description": "<h4>There are 3 sub-projects in the UX improvements, they are :</h4>\n<ul>\n<li>Implementation of shortcut navigation using the keyboard on CloudStack client. </li>\n<li>Adding the confirmation dialogues with keyboards shortcuts, like for press enter/space to confirm and ESC to cancel.</li>\n<li>Autoscroll to error field in form submissions.<br>\nApart from these some bug fixes for UI like translation doesn’t work completely for few languages, and some more UI improvements.</li>\n</ul>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_021",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5909142476161024/",
          "proposal_id": null,
          "short_description": "There are 3 sub-projects in the UX improvements, they are :\n\nImplementation of shortcut navigation using the keyboard on CloudStack client. \nAdding...",
          "slug": "ux-enhancements",
          "status": "completed",
          "student_name": "Apurv Gupta",
          "student_profile": null,
          "tags": [
            "cloud",
            "ui",
            "ux"
          ],
          "title": "UX Enhancements"
        },
        {
          "code_url": "https://github.com/apache/apisix-dashboard/pull/2010",
          "description": "<h3>Current problem</h3>\n<p>A simple identity authentication module has been implemented in the current panel, which supports the user name/password authentication mode, but its implementation faces some problems.</p>\n<p>First of all, in the currently implemented authentication mode, the user name and password are stored in a configuration file in plain text. It does not support hot updates, nor does it support dynamic addition by programs, and it is also difficult to ensure security.</p>\n<p>Also, the back-end part currently does not implement an abstract authentication framework specification, and can only implement a single authentication mode, which cannot be extended.</p>\n<h3>Project Summary</h3>\n<p>This proposal aims to implement an extensible abstract framework for the front-end and back-end so that it can be extended to other authentication methods while retaining the existing username/password mode and improving it.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_022",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5928497645617152/",
          "proposal_id": null,
          "short_description": "Current problem\nA simple identity authentication module has been implemented in the current panel, which supports the user name/password...",
          "slug": "enhanced-authentication-for-apisix-dashboard",
          "status": "completed",
          "student_name": "Zeping Bai",
          "student_profile": null,
          "tags": [
            "api",
            "ai"
          ],
          "title": "Enhanced authentication for APISIX Dashboard"
        },
        {
          "code_url": "https://gist.github.com/EGOR-IND/e13db2d9bcbb221d46741ec3644e800c",
          "description": "<p>As we know FIneract CN Mobile is a mobile field operations app built upon the brand new Apache Fineract CN micro-services architecture, with an MVP architecture and material design. So this year the focus of this project will be on providing very necessary and some UI-specific functional enhancements to the app. This project will cover the following tasks, integration of Payment Hub to enable disbursement via Mobile Money API, Adding UI and functionalities for remaining operations that are accounts, tellers, and products management, Adding FAQ section and multiple theme support, extending the offline mode via Couchbase, writing unit, integration, and UI tests for better testing, and last but not least converting existing Java code to Kotlin for KMM support.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_023",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5985136419536896/",
          "proposal_id": null,
          "short_description": "As we know FIneract CN Mobile is a mobile field operations app built upon the brand new Apache Fineract CN micro-services architecture, with an MVP...",
          "slug": "functional-enhancements-to-fineract-cn-mobile",
          "status": "completed",
          "student_name": "Kinar Sharma",
          "student_profile": null,
          "tags": [
            "java",
            "mobile",
            "api",
            "ai",
            "ui"
          ],
          "title": "Functional Enhancements to Fineract CN Mobile"
        },
        {
          "code_url": "https://mvthanoshan.medium.com/apache-shardingsphere-proofread-oracle-dml-sql-definitions-gsoc-2021-fcf6fdcbf34a",
          "description": "<p>Apache ShardingSphere uses ANTLR (ANother Tool for Language Recognition) as a generator for the SQL parser engine and obtains SQL statements from AST (Abstract Syntax Tree). Currently, the ShardingSphere parser engine has basic Oracle DML SQL definitions but does not align with Oracle documentation.</p>\n<p>This proposal suggests proofreading Oracle DML SQL definitions and corrects them according to Oracle documentation. This will be achieved by:</p>\n<ul>\n<li>Proofread and change the target ANTLR files which contain Oracle DML SQL definitions. </li>\n<li>Add unit tests to ensure newly proofread and modified SQL definitions work properly.</li>\n</ul>\n<p>Once the ShardingSphere parser engine is aligned with Oracle's DML documentation, the users and developers of Apache ShardingSphere can parse a complete set of Oracle DML SQL statements.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_024",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/6296096749387776/",
          "proposal_id": null,
          "short_description": "Apache ShardingSphere uses ANTLR (ANother Tool for Language Recognition) as a generator for the SQL parser engine and obtains SQL statements from AST...",
          "slug": "proofread-oracle-dml-sql-definitions-for-the-shardingsphere-parser",
          "status": "completed",
          "student_name": "Thanoshan M.V.",
          "student_profile": null,
          "tags": [
            "ml",
            "ai"
          ],
          "title": "Proofread Oracle DML SQL Definitions for the ShardingSphere Parser"
        },
        {
          "code_url": "https://gist.github.com/cherbel/44c0f2ab58ee455bd7921ef5554c575d",
          "description": "<p>Asterix currently requires a static range hint in the query when performing interval joins. The range hint supplies split points for input data, then data is partitioned and sent to separate nodes based on those split points. A static query hint is nice because it gives the user more control over the split points and data partitioning, but it would be nice to have the option to run a query without having to process the data and its split points in advance. Within the last year, code was added to Asterix that implemented a spatial join with a dynamic range hint. This code can pick split points (or tiles) before the join. For my project, I am going to take that code, learn how it works, and then refactor and write code to make it work with interval data and interval joins.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_025",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5147213700792320/",
          "proposal_id": null,
          "short_description": "Asterix currently requires a static range hint in the query when performing interval joins. The range hint supplies split points for input data, then...",
          "slug": "dynamic-partitioning-for-interval-joins-in-asterix-database",
          "status": "completed",
          "student_name": "Caleb Herbel",
          "student_profile": null,
          "tags": [
            "database",
            "ui"
          ],
          "title": "Dynamic Partitioning for Interval Joins in Asterix Database"
        },
        {
          "code_url": "https://github.com/apache/cloudstack/pull/5195",
          "description": "<p>Apache CloudStack’s persistent networks have been a solution for system administrators, that abstracts away the micromanaging of resources like virtual machines and physical devices (like routers and switches) and avoids the inconvenience of setting up the network for every individual host. \nEven though the persistent network is quite powerful, it lacks a dynamic to simply add a new host to a cluster and have it automatically configured for the persistent networks resources of the zone. \nThe project idea aims to introduce a feature to CloudStack, with which detecting newly added hosts and creating the persistent network’s resources will be automated to further reduce the management of a cluster during its lifecycle.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_026",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5165975426564096/",
          "proposal_id": null,
          "short_description": "Apache CloudStack’s persistent networks have been a solution for system administrators, that abstracts away the micromanaging of resources like...",
          "slug": "apache-cloudstack-synchronization-of-network-devices-on-newly-added-hosts-for-persistent-networks",
          "status": "completed",
          "student_name": "Sang Woo Bae",
          "student_profile": null,
          "tags": [
            "ai",
            "cloud",
            "ui"
          ],
          "title": "Apache CloudStack - Synchronization of network devices on newly added hosts for Persistent Networks"
        },
        {
          "code_url": "https://github.com/apache/shardingsphere/issues/10513",
          "description": "<p>ShardingSphere parser engine helps users parse a SQL to get the AST (Abstract Syntax Tree) and visit this tree to get SQLStatement (Java Object). At present, this parser engine can handle SQLs for MySQL, PostgreSQL, SQLServer and <code>Oracle</code>, which means we have to understand different database dialect SQLs. This project is focused on proofreading all the TCL (Transaction Control Language) SQL definitions and all the Oracle DDL (Data Definition Language) SQL definitions except for ALTER, DROP, CREATE and TRUNCATE.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_027",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5176643219357696/",
          "proposal_id": null,
          "short_description": "ShardingSphere parser engine helps users parse a SQL to get the AST (Abstract Syntax Tree) and visit this tree to get SQLStatement (Java Object). At...",
          "slug": "apache-shardingsphere-proofread-the-oracle-ddltcl-sql-definitions",
          "status": "completed",
          "student_name": "Liangda Wang",
          "student_profile": null,
          "tags": [
            "java",
            "database"
          ],
          "title": "Apache ShardingSphere - Proofread the Oracle DDL/TCL SQL Definitions"
        },
        {
          "code_url": "https://github.com/Humbertzhang/GSOC2021FinalReport",
          "description": "<p>Apache SkyWalking already has a Python Agent with relatively complete functions, but it still has some functional deficiencies compared with Java Agent. One of these is the ability to profile running projects.  In this project, I will implement the profiling function for the Python Agent of SkyWalking. \nBecause the Java Agent already implements this functionality, so the code in the oapserver and the report protocol can be reused, but the Python Agent needs to implement the code that accepts the profiling task command and the code associated with the profiling sample.</p>\n",
          "difficulty": null,
          "id": "proj_the-apache-software-_2021_028",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5224136162410496/",
          "proposal_id": null,
          "short_description": "Apache SkyWalking already has a Python Agent with relatively complete functions, but it still has some functional deficiencies compared with Java...",
          "slug": "proposal-for-apache-skywalking-python-agent-supports-profiling",
          "status": "completed",
          "student_name": "Ke Zhang",
          "student_profile": null,
          "tags": [
            "python",
            "java"
          ],
          "title": "Proposal for Apache SkyWalking: Python agent supports profiling"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2021/organizations/5149287498907648/"
    },
    "year_2022": {
      "num_projects": 33,
      "projects": [
        {
          "code_url": "https://pchengma.github.io/2022/09/06/gsoc22.html",
          "description": "By finishing this project, we could provide an event-driven application that connects EventMesh to Knative. Apache EventMesh community could obtain the ability of Knative, including publishing/subscribing event messages. It also provide convenience to users who want to use Knative, and as we provide a mature SDK, users can directly use our SDK in EventMesh to build their applications.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/YxBHSLin/",
          "proposal_id": null,
          "short_description": "By finishing this project, we could provide an event-driven application that connects EventMesh to Knative. Apache EventMesh community could obtain...",
          "slug": "apache-eventmesh-support-knative-as-eventing-infra",
          "status": "completed",
          "student_name": "Pengcheng Ma",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Apache EventMesh Support Knative as Eventing Infra"
        },
        {
          "code_url": "https://github.com/erdengk/GSoC2022/blob/main/GSoC2022.md",
          "description": "The main tasks of this project are adding plugin integration tests and adding new test workflows. There are already integration tests for some plugins in ShenYu, but there are still some plugins without integration tests, such as the cache plugin, metrics plugin, logging-rocketmq plugin, etc. Adding integration tests can help developers find problems in the system as early as possible so that they can be solved as soon as possible.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/wWJCM4HI/",
          "proposal_id": null,
          "short_description": "The main tasks of this project are adding plugin integration tests and adding new test workflows. There are already integration tests for some...",
          "slug": "apache-shenyu-integration-tests-cover-more-scenarios",
          "status": "completed",
          "student_name": "erdengk",
          "student_profile": null,
          "tags": [
            "ios",
            "ai"
          ],
          "title": "Apache ShenYu: Integration tests cover more scenarios"
        },
        {
          "code_url": "https://github.com/MaverickJune/snuspl_intern",
          "description": "In this project, I will focus on building a concrete baseline for stream processing system scaling on a serverless framework. First, choose an adequate system for scaling based on the purpose of a scaling, dealing with events with high input rate. Second, examine the dataflow reshaping mechanism on stream query DAG and evaluate it though some experiment, since it is often helpful for efficient scaling on serverless framework. Finally, elaborate scaling policy to reasonably determine when to scale up on a serverless framework. This process mainly focuses on input rate on the stream that can cause high latency spike toward the system.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/hNZOOc0x/",
          "proposal_id": null,
          "short_description": "In this project, I will focus on building a concrete baseline for stream processing system scaling on a serverless framework. First, choose an...",
          "slug": "elaborating-the-new-stream-processing-system-utilizes-serverless-framework-with-fast-scaling-policy",
          "status": "completed",
          "student_name": "maverick_June",
          "student_profile": null,
          "tags": [
            "api",
            "ai",
            "ui"
          ],
          "title": "Elaborating the new stream processing system utilizes serverless framework with fast scaling policy"
        },
        {
          "code_url": "https://gist.github.com/yang20150702/87ac709f5895c17a1b8079532def2189",
          "description": "dubbo-rust provides basic RPC communication and service governance capability in microservice scenarios.\ndeliverables:\n+ protoc-gen-rust-triple: protoc plugin\n+ service governance capability: server discovery, server registry, config server, metadata server\n+ dubbo-rust code",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/7b6vmFqS/",
          "proposal_id": null,
          "short_description": "dubbo-rust provides basic RPC communication and service governance capability in microservice scenarios. deliverables: + protoc-gen-rust-triple:...",
          "slug": "gsoc2022-rust-language-implementation",
          "status": "completed",
          "student_name": "杨阳",
          "student_profile": null,
          "tags": [
            "ios"
          ],
          "title": "GSoC2022 Rust language implementation"
        },
        {
          "code_url": "https://gist.github.com/ericluoliu/defa835dccf44a6c11db7bd72f88f10c",
          "description": "This project's aim was to improve upon the current apisix-java-plugin-runner design. APISIX is an API Gateway that provides traffic management (load balancing, authorization, security, etc). Users can develop their own custom plugins, however, the current development process for Java plugins is inconvenient and unreliable. This project streamlines and improves the Java plugin development and shipment process.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/cLq6dMbf/",
          "proposal_id": null,
          "short_description": "This project's aim was to improve upon the current apisix-java-plugin-runner design. APISIX is an API Gateway that provides traffic management (load...",
          "slug": "apache-apisix-java-plugin-runner-improvement",
          "status": "completed",
          "student_name": "erikiceliu",
          "student_profile": null,
          "tags": [
            "java",
            "api",
            "ml",
            "ai"
          ],
          "title": "Apache APISIX Java Plugin Runner Improvement"
        },
        {
          "code_url": "https://github.com/Liangshumin/GSoC-Log--Outlier--Detection",
          "description": "Currently Apache SkyWalking can collect logs from various sources like user agents and Envoy access logs, it also provides a log analysis language to analyze the logs and produce some metrics, with those metrics, users can configure rules to trigger alerts and react to those abnormal/exceptional logs. But in reality, production environment exceptional logs are not known in advance and users can't enumerate all possible exceptional logs. This task aims to add an algorithm that can identify outlier log(s) from the massive logs, and draw the users attention to see whether there is error in the system. Log acquisition, log analysis, feature extraction, and anomaly detection are the four aspects of this algorithm. To extract the relevant features in log events, the feature extraction technique divides the log data set into finite blocks using a window. A representative approach of supervised learning is used to execute the final anomaly detection process (SVM). The algorithm should be able to learn from bot the history logs and streaming logs, and adjust itself to increase the accuracy.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/REBhXTku/",
          "proposal_id": null,
          "short_description": "Currently Apache SkyWalking can collect logs from various sources like user agents and Envoy access logs, it also provides a log analysis language to...",
          "slug": "log-outlier-detection",
          "status": "completed",
          "student_name": "Liangshumin",
          "student_profile": null,
          "tags": [
            "react",
            "ai",
            "ui"
          ],
          "title": "Log Outlier Detection"
        },
        {
          "code_url": "https://github.com/apache/dubbo/pull/10331",
          "description": "This project has three main modules: indicator collection, local aggregation and indicator push.\n\n1.indicator collection : Define MetricsCollector under the common package to collect various internal indicators of Dubbo, and count the basic indicators (total number of requests, total number of successes, total number of failures, number of requests being processed, number of threads, request response time) when the service is invoked. \n\n2.local aggregation : The result of index collection is used as the basic index, and the sliding window algorithm is used to calculate some quantile indexes. This function is controlled by XML label and is disabled by default. \n\n3.indicator push : Encapsulate collected and aggregated indicators and push them to a third-party server in a specific way.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/88DMMT0I/",
          "proposal_id": null,
          "short_description": "This project has three main modules: indicator collection, local aggregation and indicator push. 1.indicator collection : Define MetricsCollector...",
          "slug": "dubbo-metrics-and-observability",
          "status": "completed",
          "student_name": "henrik",
          "student_profile": null,
          "tags": [
            "ml",
            "ai"
          ],
          "title": "Dubbo Metrics and Observability"
        },
        {
          "code_url": "https://github.com/apache/dubbo-go/issues/1834",
          "description": "Based on traffic scheduling, traffic limiting and circuit breaking in service mesh, enhancing the feedback capability of the server side (downstream service) in a distributed client-side(upstream  service) load balancing architecture and making the client and server work together to improve the load balancing effect.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/jAxP1ZpV/",
          "proposal_id": null,
          "short_description": "Based on traffic scheduling, traffic limiting and circuit breaking in service mesh, enhancing the feedback capability of the server side (downstream...",
          "slug": "dubbo-92-explore-a-new-generation-of-flexible-loadbalance-algorithms-for-dubbo-go",
          "status": "completed",
          "student_name": "Yepeng Zhang",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "DUBBO-92: Explore a new generation of flexible loadbalance algorithms for Dubbo-go"
        },
        {
          "code_url": "https://github.com/pulls?user=apache&q=is%3Apr+author%3Alyleshaw+archived%3Afalse&user=apache",
          "description": "The Python API CLI is a component of PyDolphinScheduler, but it currently only has two commands, `version` and `config`. This proposal refines its functionality and outlines the timelines and milestones required for refinement and follow-up plans.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/JTAjayLz/",
          "proposal_id": null,
          "short_description": "The Python API CLI is a component of PyDolphinScheduler, but it currently only has two commands, `version` and `config`. This proposal refines its...",
          "slug": "proposal-for-python-api-cli-enhancement",
          "status": "completed",
          "student_name": "lyle",
          "student_profile": null,
          "tags": [
            "python",
            "api",
            "ui"
          ],
          "title": "Proposal For Python API CLI Enhancement"
        },
        {
          "code_url": "https://gist.github.com/chenyanlann/dd833db1a723ffc4500dc63f4941ae33",
          "description": "Details\nxDS 官方说明\nhttps://www.envoyproxy.io/docs/envoy/latest/api-docs/xds_protocol\n\n● Listener Discovery Service (LDS): Returns Listener resources. Used basically as a convenient root for the gRPC client's configuration. Points to the RouteConfiguration. ● Route Discovery Service (RDS): Returns RouteConfiguration resources. Provides data used to populate the gRPC service config. Points to the Cluster. ● Cluster Discovery Service (CDS): Returns Cluster resources. Configures things like load balancing policy and load reporting. Points to the ClusterLoadAssignment. ● Endpoint Discovery Service (EDS): Returns ClusterLoadAssignment resources. Configures the set of endpoints (backend servers) to load balance across and may tell the client to drop requests.\n\n协议基础：protobuf + gRPC\n实现方案 1：使用 io.grpc 的依赖手动创建原生 gRPC 服务 实现方案 2：使用 Dubbo 3.0 的新协议\n\n测试环境控制平面 mock\nEnvoy 提供的 Java 实例控制平面 https://github.com/envoyproxy/java-control-plane\n\nJava 版协议支持\nEnvoy 提供的 Java 版控制平面 API https://search.maven.org/search?q=g:io.envoyproxy.controlplane",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/de4zCj2s/",
          "proposal_id": null,
          "short_description": "Details xDS 官方说明 https://www.envoyproxy.io/docs/envoy/latest/api-docs/xds_protocol ● Listener Discovery Service (LDS): Returns Listener resources....",
          "slug": "apache-dubbo-gsoc2022-proxyless-mesh-support",
          "status": "completed",
          "student_name": "Cyl",
          "student_profile": null,
          "tags": [
            "java",
            "api",
            "ai",
            "backend"
          ],
          "title": "Apache Dubbo GSoC2022 Proxyless Mesh support"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/AIRAVATA/Final+Report+%3A+AdminDashboard",
          "description": "Apache Airavata is a software framework for executing and managing computational jobs on distributed computing resources including local clusters, supercomputers, national grids, academic and commercial clouds. Gateway admins needs periodical reports of number of users, experiments running , resources in use etc for various reporting and planning purposes. The goal is to use the existing experimental and user data that is already present in apache Airavata’s databases and take the advantage of apache superset and visualize these statistics on webpage using VueJS as well as ability to download the report in Csv or pdf format.\n\n\nDeliverables:\n1. Study the Apache Airavata’s User and Experiment Database\n2. Creation of the feature API’s to fetch relevant data.\n3. Creation of the dashboard to visualize the the data\n4. End to End Testing",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_011",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/QmSIkjhD/",
          "proposal_id": null,
          "short_description": "Apache Airavata is a software framework for executing and managing computational jobs on distributed computing resources including local clusters,...",
          "slug": "dashboards-to-get-quick-statistics",
          "status": "completed",
          "student_name": "Shubham Bipin Kumar",
          "student_profile": null,
          "tags": [
            "vue",
            "web",
            "api",
            "ai",
            "database"
          ],
          "title": "Dashboards to get quick statistics"
        },
        {
          "code_url": "https://github.com/apache/shardingsphere/issues/17844",
          "description": "The ShardingSphere parser engine can handle various SQL dialects such as MySQL, PostgreSQL, SQLServer, openGauss, and Oracle. Although the parser engine supports numerous PostgreSQL statements, some important PostgreSQL statements that start with ‘c’ require assistance in parsing and getting the SQLStatement (Java object). Therefore, this proposal aims to support those PostgreSQL statements for the parser engine.\n\nThis will be achieved by:\n1. Review the PostgreSQL SQL commands documentation and modify the target ANTLR g4 files (essential).\n2. Implement the visit method (essential).\n3. Add SQL cases and expected parse results (essential).\n4. Run the associated tests to ensure no failures and exceptions (essential).\n\nOnce the parser engine gets support for the target PostgreSQL statements, the users and developers of Apache ShardingSphere can be benefitted by working on these SQL statements.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_012",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/LJFxxqPR/",
          "proposal_id": null,
          "short_description": "The ShardingSphere parser engine can handle various SQL dialects such as MySQL, PostgreSQL, SQLServer, openGauss, and Oracle. Although the parser...",
          "slug": "solve-unsupported-postgresql-statements-that-start-with-c-for-shardingsphere-parser",
          "status": "completed",
          "student_name": "Thanoshan M.V.",
          "student_profile": null,
          "tags": [
            "java",
            "ai",
            "ui"
          ],
          "title": "Solve Unsupported PostgreSQL Statements That Start With 'c' for Shardingsphere Parser"
        },
        {
          "code_url": "https://github.com/HaiqiQin/GSoC2022/blob/master/GSoC2022-Summary.md",
          "description": "Apache Shenyu supports the use of elasticsearch, Kafka and rocketmq middleware to obtain gateway log information, but at present, it can only support the use of rocketmq.  In this project,I will use reactor Java technology and elasticsearch related technology to complete the preparation of logging-elasticsearch plugin, so that Shenyu can store the log into the elasticsearch database and view and change the data through visualization technology.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_013",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/wjs0bHYB/",
          "proposal_id": null,
          "short_description": "Apache Shenyu supports the use of elasticsearch, Kafka and rocketmq middleware to obtain gateway log information, but at present, it can only support...",
          "slug": "proposal-for-apache-shenyu-about-logging-elasticsearch-plugin",
          "status": "completed",
          "student_name": "QinHaiqi",
          "student_profile": null,
          "tags": [
            "react",
            "java",
            "ai",
            "database"
          ],
          "title": "Proposal for Apache Shenyu about logging-elasticsearch plugin"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/AIRAVATA/Airavata+Jupyter+Platform+Services+%3A-+Final+Report",
          "description": "There is a need to develop a UI application integrated with Apache Custos as the authentication service to host jupyter notebooks platform on Jetstream that can cater to handle multiple concurrent users at the same time with proper resource isolation, persist user states, and integrated to allow for uploading files from the local and add to the existing services of Apache Airavata as a scientific gateway.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_014",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/mRaKJNOZ/",
          "proposal_id": null,
          "short_description": "There is a need to develop a UI application integrated with Apache Custos as the authentication service to host jupyter notebooks platform on...",
          "slug": "airavata-jupyter-platform-services",
          "status": "completed",
          "student_name": "Himanshu Hansaria",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Airavata Jupyter Platform Services"
        },
        {
          "code_url": "https://shenyu.apache.org/docs/next/plugin-center/observability/logging-kafka",
          "description": "ShenYu is a widely used program for limiting, fusing, forwarding, routing, monitoring, and so on. Since ShenYu clusters are able to support a large volume of internet business, it is crucial to decouple the systems and data streams. The Kafka plugins as a high-throughput distributed messaging system will enable ShenYu to have excellent horizontal scalability, scaling to millions of messages per second. It enables the data stream to communicate with less than 10 ms latency, almost real-time message transmission. In this feature, the logging-Kafka plugin will be able to store ShenYu’s logs and take the ShenYu gateway log information, write it to Kafka and display it. The module could be activated as a “Shenyu-plugin”.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_015",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/HOZgtVXq/",
          "proposal_id": null,
          "short_description": "ShenYu is a widely used program for limiting, fusing, forwarding, routing, monitoring, and so on. Since ShenYu clusters are able to support a large...",
          "slug": "shenyu-logging-kafka-plugin",
          "status": "completed",
          "student_name": "Qifan Yu",
          "student_profile": null,
          "tags": [],
          "title": "ShenYu: logging-kafka plugin"
        },
        {
          "code_url": "https://github.com/isHuangXin/GSoC-2022-DistSQL-Convert-Tool",
          "description": "Since version 5.0.0, ShrdingSphere provides its own management language: DistSQL, which greatly facilitates users to manage distributed databases.\n\nThere are now many users who want to convert from legacy YAML configuration to DistSQL, and we want to design and implement a command-line tool that allows the user to enter a path to a YAML configuration file and output a DistSQL script file. The tool should convert both datasources and rule configuration in YAML to corresponding DistSQL RDL",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_016",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/4PnSweAf/",
          "proposal_id": null,
          "short_description": "Since version 5.0.0, ShrdingSphere provides its own management language: DistSQL, which greatly facilitates users to manage distributed databases....",
          "slug": "apache-shardingsphere-develop-an-external-tool-to-convert-yaml-configuration-into-distsql-scripts",
          "status": "completed",
          "student_name": "Xin Huang",
          "student_profile": null,
          "tags": [
            "ml",
            "database"
          ],
          "title": "Apache ShardingSphere Develop an external tool to convert YAML configuration into DistSQL scripts"
        },
        {
          "code_url": "https://github.com/apache/skywalking-banyandb/pull/175",
          "description": "Apache skywalking: Add the webapp of Banyandb has determined the support for \nHTTP client requests, and the data structure has been designed. We only need to \ndesign a Web UI to support querying data from Banyandb's data nodes, monitoring \nthe performance of the back-end and presenting the topology of the server nodes. Therefore, I divide the webui into Home, Database, Structure and About Us pages to display performance, data, topology and community information respectively.The Home page shows the performance of the database itself, using visualization technologies such as ECharts.The Database page is used for database management, which is divided into definition part and data browsing part.The Structure page is used to display the topology of Banyandb.The About Us page is used to display community information, including but not limited to community, development team and contact information.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_017",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/FKBuRb8U/",
          "proposal_id": null,
          "short_description": "Apache skywalking: Add the webapp of Banyandb has determined the support for HTTP client requests, and the data structure has been designed. We only...",
          "slug": "apache-skywalking-add-the-webapp-of-banyandb",
          "status": "completed",
          "student_name": "Chusheng Wu",
          "student_profile": null,
          "tags": [
            "web",
            "database",
            "ui"
          ],
          "title": "Apache skywalking: Add the webapp of Banyandb"
        },
        {
          "code_url": "https://gist.github.com/wjf222/3096c65bae2b4e9073f484b3dc090de6",
          "description": "The dolphinscheduler-registry-api defines the standard for implementing plugins. This project aims to support Etcd as a new registrar plugin and help user who only familiar with Etcd to use DolphinScheduler.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_018",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/O8ZokNAN/",
          "proposal_id": null,
          "short_description": "The dolphinscheduler-registry-api defines the standard for implementing plugins. This project aims to support Etcd as a new registrar plugin and help...",
          "slug": "dolphinscheduler-support-etcd-as-registry",
          "status": "completed",
          "student_name": "wjf",
          "student_profile": null,
          "tags": [
            "api",
            "ai"
          ],
          "title": "DolphinScheduler: Support etcd as registry"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/AIRAVATA/SMILES+Data+Models",
          "description": "The goal is to design and implement the solution to the Airavata Data Catalog to record the metadata extracted from the Literature, Experimental and Computational data in support of Small Molecule Iconic Isolation Lattices (SMILES) Data. More precisely, this includes the data synchronization with the end-users.\n\nCurrently, Airavata is extending an open-source project called “open-inventory” with additional features. Airavata uses three individual and unrelated databases to save the Literature data, Experimental data, and Computational data. Having these in usage, the chemical compounds are represented with ambiguous keys and missing data.\n\nTherefore, the scientific representation of the compounds with a specific structure; scientific data model (SDM), and related ontology (SDMO) is much better to analyze the behavior of a compound. In particular, a common data model should be used to synchronize the data efficiently.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_019",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/LAzoIUP3/",
          "proposal_id": null,
          "short_description": "The goal is to design and implement the solution to the Airavata Data Catalog to record the metadata extracted from the Literature, Experimental and...",
          "slug": "smiles-data-models",
          "status": "completed",
          "student_name": "Bhavesh Asanabada",
          "student_profile": null,
          "tags": [
            "ai",
            "database"
          ],
          "title": "SMILES Data Models"
        },
        {
          "code_url": "https://gist.github.com/everly-gif/b2df9b5b2133afc671c38c43c08f2569",
          "description": "Apache ShardingSphere is positioned as a Database Plus, and aims at building a standard layer and ecosystem above heterogeneous databases. It focuses on how to reuse existing databases and their respective upper layer, rather than creating a new database. The goal is to minimize or eliminate the challenges caused by underlying database fragmentation.\n\nShardingSphere parser engine is the core of ShardingSphere, It helps users parse a SQL to get the AST (Abstract Syntax Tree) and visit this tree to get SQLStatement (Java Object). At present, this parser engine can handle SQLs for MySQL, PostgreSQL, SQLServer, openGauss and Oracle. However, there are still many statements that are not supported yet.\n\nTherefore this project proposes to Solve unsupported Postgres sql about alter statements for ShardingSphere parser and also proofread and optimize the grammar wherever needed.\n\nThis project would require to proofread through DDLStatement.g4 to analyze existing grammars and optimize them (essential), write grammar for unsupported alter statements referring to the official PostgreSQL documentation (essential), implement visit methods for the statements (essential), add new corresponding SQL cases  and expected parsed results (essential), Run SQLParserParameterizedTest and UnsupportedSQLParserParameterizedTest to make sure there are no exceptions (essential).\n\nSuccessful Implementation of the project will add proper support for PostgreSQL Alter Statements ensuring there are no exceptions for the following statements,  ALTER OPERATOR, ALTER POLICY, ALTER PUBLICATION, ALTER ROUTINE, ALTER RULE, ALTER SCHEMA, ALTER SEQUENCE, ALTER SERVER, ALTER STATISTICS, ALTER SUBSCRIPTION, ALTER TABLE, ALTER TEXT SEARCH,ALTER TRIGGER, ALTER TYPE, ALTER VIEW.\n\nThis project will significantly improve the ShardingSphere parser engine.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_020",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/ajDT1hjj/",
          "proposal_id": null,
          "short_description": "Apache ShardingSphere is positioned as a Database Plus, and aims at building a standard layer and ecosystem above heterogeneous databases. It focuses...",
          "slug": "solve-unsupported-postgres-sql-about-alter-statement-for-shardingsphere-parser",
          "status": "completed",
          "student_name": "Everly Precia Suresh",
          "student_profile": null,
          "tags": [
            "java",
            "ai",
            "database",
            "ui"
          ],
          "title": "Solve unsupported Postgres sql about alter statement for ShardingSphere Parser"
        },
        {
          "code_url": "https://github.com/apache/dubbo-go-pixiu/pull/474",
          "description": "Pixiu is an open source Dubbo ecosystem API gateway and language solution for accessing dubbo clusters. When Pixiu is closed, there may be some traffic loss at the end of mandatory. We need to ensure that Pixiu can be shut down normally and try our best to reduce traffic consumption.\nIn summary, We need to realize the  gracefully shut down function of Pixiu in several directions to reduce the traffic loss when Pixiu is closed.\nWe need to add some  related options in the configuration file to control graceful shut down, then we need Implement a graceful policy for each protocol listener.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_021",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/cbmFNiQj/",
          "proposal_id": null,
          "short_description": "Pixiu is an open source Dubbo ecosystem API gateway and language solution for accessing dubbo clusters. When Pixiu is closed, there may be some...",
          "slug": "gracefully-shuts-down-for-dubbo-go-pixiu",
          "status": "completed",
          "student_name": "Shibo Chen",
          "student_profile": null,
          "tags": [
            "api"
          ],
          "title": "Gracefully shuts down for dubbo-go-pixiu"
        },
        {
          "code_url": "https://github.com/apache/dubbo-go/pull/1945",
          "description": "Service mesh has brought new vitality to the rpc field, but the complexity and performance loss of the sidecar deployment discourages users. Proxyless is to put the related functions of sidecar directly into the rpc sdk, so that users can not only enjoy the advantages of mesh, but also avoid the loss of sidecar.\n\nNow dubbo proxyless mesh already supports some mesh functions, such as service registration and service discovery of XDS protocol. Dubbo needs to support more service mesh functions, such as service routing, service rate limiting, etc.",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2022_022",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/lZ90KM9Z/",
          "proposal_id": null,
          "short_description": "Service mesh has brought new vitality to the rpc field, but the complexity and performance loss of the sidecar deployment discourages users....",
          "slug": "dubbo-go-proxyless-mesh",
          "status": "completed",
          "student_name": "zlber",
          "student_profile": null,
          "tags": [],
          "title": "dubbo-go Proxyless Mesh"
        },
        {
          "code_url": "https://github.com/dubbogo/dubbo-go-boot/pull/9",
          "description": "Dubo-go-boot project enriches other middleware adaptations \nSimilar to the Spring Boot project, which makes it easier for users to use dubo-Go projects, importing related packages provides middleware capabilities",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_023",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/CVodKm18/",
          "proposal_id": null,
          "short_description": "Dubo-go-boot project enriches other middleware adaptations Similar to the Spring Boot project, which makes it easier for users to use dubo-Go...",
          "slug": "gsoc-2022-dubo-go-boot-project-enriches-other-middleware-adaptations",
          "status": "completed",
          "student_name": "jay li",
          "student_profile": null,
          "tags": [],
          "title": "GSoC 2022: Dubo-go-boot project enriches other middleware adaptations"
        },
        {
          "code_url": "https://medium.com/@abhinav7.sinha/gsoc-2022-apache-airavata-final-report-db4e79043c67",
          "description": "Although Apache Custos is currently deployed on a Kubernetes cluster - its size and complexity may not be ideal for a relatively small application like Custos. This project aims to develop an alternative deployment architecture for Custos that aims to simplify its deployment and backup process.",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2022_024",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/2OPKNrzB/",
          "proposal_id": null,
          "short_description": "Although Apache Custos is currently deployed on a Kubernetes cluster - its size and complexity may not be ideal for a relatively small application...",
          "slug": "apache-custos-baremetal-deployment",
          "status": "completed",
          "student_name": "Abhinav Sinha",
          "student_profile": null,
          "tags": [
            "ai",
            "kubernetes"
          ],
          "title": "Apache Custos Baremetal Deployment"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/AIRAVATA/Report",
          "description": "The SeaGrid web portal is created for interested science communities for conducting experiments. Desktop applications have better performance for complex computations than web applications. The existing javaFX client is not actively maintained and does not work with the latest version of apache airavata. The proposed solution will be built with electronJS. As electronJS makes use of pre-existing business logic, user interface/user experience, and overall web app structure. Apache Airavata is a middleware that makes computation and data analysis easier in a variety of computing environments. The existing SeaGrid desktop application uses Apache Airavata API as a middleware for accessing resources and performing experiments provided by users. The implied SeaGrid desktop application will also use apache airavata for computing complex experiments.",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2022_025",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/1cNhg9b3/",
          "proposal_id": null,
          "short_description": "The SeaGrid web portal is created for interested science communities for conducting experiments. Desktop applications have better performance for...",
          "slug": "airavata-rich-client-based-on-electronjs",
          "status": "completed",
          "student_name": "Aishwarya Sinhasane",
          "student_profile": null,
          "tags": [
            "java",
            "web",
            "api",
            "ai",
            "ui"
          ],
          "title": "Airavata Rich Client Based on ElectronJS"
        },
        {
          "code_url": "https://github.com/apache/incubator-eventmesh/tree/dashboard",
          "description": "Currently, there is no front end user interface for the control plane of EventMesh. For this project, we're building a front end user interface for eventmesh-admin which will enhance topic and subscription management experience by leveraging front-end frameworks to abstract away the complexity of dealing with back-end APIs. We will also implement additional APIs for the eventmesh-admin module that will extend the module's functionality.",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2022_026",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/fPgGP9W7/",
          "proposal_id": null,
          "short_description": "Currently, there is no front end user interface for the control plane of EventMesh. For this project, we're building a front end user interface for...",
          "slug": "eventmesh-admin-dashboard",
          "status": "completed",
          "student_name": "Kaifeng Liu",
          "student_profile": null,
          "tags": [
            "api",
            "ui"
          ],
          "title": "EventMesh Admin Dashboard"
        },
        {
          "code_url": "https://github.com/apache/gora/pull/273",
          "description": "The goal is to add Apache Geode support for the Apache Gora project. Apache Gora currently supports a wide range of data stores.  But, Apache Geode is a data management platform that provides real-time, consistent access to data-intensive applications throughout widely distributed cloud architectures.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_027",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/3P25m4BT/",
          "proposal_id": null,
          "short_description": "The goal is to add Apache Geode support for the Apache Gora project. Apache Gora currently supports a wide range of data stores. But, Apache Geode is...",
          "slug": "apache-geode-data-store-support-for-apache-goragora-698",
          "status": "completed",
          "student_name": "Himanshu Acharya",
          "student_profile": null,
          "tags": [
            "cloud"
          ],
          "title": "Apache Geode Data store support for Apache Gora(GORA-698)"
        },
        {
          "code_url": "https://github.com/conghuhu/conghuhu/blob/main/GSoC%202022%20Work%20Product%20Doc.md",
          "description": "The overall goal is to modify the Dubbo SDK to work in mesh mode and streamline unnecessary processes.\n\n1. For service invocation, add the meshEnable configuration in ConsumerConfig to enable the mesh mode and add the providerPort in ReferenceConfig to specify the provider's service port. Modify the SDK, read the providerBy and providerPort in the configuration to determine the address of sending RPC. In the mesh environment, providerBy should be the ServiceName of the Provider. In Mesh mode, Invoker should remove clusters.\n\n2. For health checks, Istio comes with probes that align the life cycle of Dubbo and even the entire application with the life cycle of Pod. An active health check provided by Envoy removes unhealthy instances immediately and then joins the service route when the instance is healthy again. However, the readinessProbe implementation provided by Dubbo does not apply to mesh. If the registry is not configured in mesh mode, Dubbo's readinessProbe returns false, which needs to be modified here.\n\n3.  For traffic governance, you can use retry configuration, routing, load balancing and other traffic governance functions to find the methods to interact with Envoy (for example, the number of retries can be achieved by configuring the header).",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_028",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/JCf3vuRf/",
          "proposal_id": null,
          "short_description": "The overall goal is to modify the Dubbo SDK to work in mesh mode and streamline unnecessary processes. 1. For service invocation, add the meshEnable...",
          "slug": "thin-sdk-for-proxy-mesh",
          "status": "completed",
          "student_name": "conghuhu",
          "student_profile": null,
          "tags": [
            "ml",
            "ai"
          ],
          "title": "Thin SDK for Proxy Mesh"
        },
        {
          "code_url": "https://gist.github.com/sumanth-rajkumar/705e0247c1b48f78bfded8fa58a98aa0",
          "description": "The existing Commons Numbers library for complex types uses collections of complex object instances that incur Java object allocation overhead and is inefficient for iteration and operations on large complex data sets. \n\nThere are several third party Java libraries for complex math that each have their advantages and disadvantages, but Java developers currently have no single API for Complex operations that can use these libraries at runtime without rewriting their applications\n\nThis project would provide Java developers with a single Complex API with abstractions that allow for efficient data structures (such as primitive arrays and value types - as proposed by Java Project Valhalla), use of Java 8 language features (Lambdas/Streams) and a Service Provider Interface (SPI) to integrate with existing (JTransforms, JBLAS, EJML) and future third party libraries (Java 17 Vector API, jcuda, aparapi)\n\n\nThe project deliverables would include interfaces to represent complex scalar, vector, matrix types and functional interfaces for complex unary and binary operators & functions. The existing methods in Commons Numbers would be refactored as static functions for use as Lambdas with the new API. The JTransforms library will be integrated for supporting operations such as fast Fourier and Discrete Cosine transforms. Optionally, an implementation using Java 17 vector API would be provided for basic operations on complex vectors and matrices. Performance benchmarks comparing different implementations would be published. The deliverables will include complete Pull Requests meeting all Apache Commons Numbers project requirements",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2022_029",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/m9ScOEh7/",
          "proposal_id": null,
          "short_description": "The existing Commons Numbers library for complex types uses collections of complex object instances that incur Java object allocation overhead and is...",
          "slug": "commons-numbers-library-for-complex-linear-algebra",
          "status": "completed",
          "student_name": "Sumanth Sulur Rajkumar",
          "student_profile": null,
          "tags": [
            "java",
            "api",
            "ml",
            "ui"
          ],
          "title": "Commons Numbers Library for Complex Linear Algebra"
        },
        {
          "code_url": "https://gist.github.com/Trydamere/3cea03844dcdd9b7e10a5bcf58773d63",
          "description": "服务治理（Service-Oriented Architecture (SOA) governance）是指在面向服务架构中对服务执行控制相关的活动，主要作用是改变运行时服务的行为和选址逻辑，达到限流，权重配置等目的。Dubbo 拥有丰富的治理规则，如服务发现、负载均衡、路由策略（标签路由、条件路由）等，但是这些治理规则的使用具有一定的难度，用户也很难直观的了解到其对应的使用场景。因此 Dubbo 期望有这样的一些场景化的用例能够体现 Dubbo 的治理能力，帮助用户将治理规则迁移到真实业务场景中使用。",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_030",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/0h06IrAA/",
          "proposal_id": null,
          "short_description": "服务治理（Service-Oriented Architecture (SOA) governance）是指在面向服务架构中对服务执行控制相关的活动，主要作用是改变运行时服务的行为和选址逻辑，达到限流，权重配置等目的。Dubbo...",
          "slug": "task-demo-demonstrating-the-usage-of-dubbo3",
          "status": "completed",
          "student_name": "Huang Yilong",
          "student_profile": null,
          "tags": [],
          "title": "Task demo demonstrating the usage of Dubbo3"
        },
        {
          "code_url": "https://gist.github.com/Damans227/f235d8a6a4e609a28be37ce0b2cb4143",
          "description": "CloudStack has recently made the first release of its own terraform provider, called CloudStack-Terraform Provider v0.4.0 and as of today it supports 25 resource types, and 1 Data Source type. I would like to extend the list of data sources supported by the CloudStack Terraform provider and implement data sources for the existing cloudstack resources. To solve this issue, I will implement data sources for all the resources already supported via the Terraform CloudStack provider and possibly extend that list of supported resources and data sources to other major CloudStack resources which are not available yet.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_031",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/ZVraist1/",
          "proposal_id": null,
          "short_description": "CloudStack has recently made the first release of its own terraform provider, called CloudStack-Terraform Provider v0.4.0 and as of today it supports...",
          "slug": "cloudstack-terraform-provider-add-datasources-for-the-existing-resources",
          "status": "completed",
          "student_name": "Daman Arora",
          "student_profile": null,
          "tags": [
            "ai",
            "cloud"
          ],
          "title": "CloudStack Terraform Provider - Add datasources for the existing resources"
        },
        {
          "code_url": "https://gist.github.com/alive2020/b7c63851c30c1bb739994a8132aa1fc7",
          "description": "Currently, Apache Beam maintains a static capability matrix to track which Beam features are supported by which set of language SDKs + Runners. This Runners/Beam Capability Matrix Page needs to be updated.\n\nThe goal of this Project: Tighter coupling of the matrix portion of the comparison with tags on ValidatesRunner tests\nAction: Create a completely new Capability Matrix that is based on the ValidatesRunner tests that run on the various Apache Beam runners. Improve UI/UX of Matrix Table. \nUse the test in ./test-infra/validates-runner/ to generate a JSON file that contains the capabilities supported by various runners and tested by each individual test.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_032",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/bcrkfuzU/",
          "proposal_id": null,
          "short_description": "Currently, Apache Beam maintains a static capability matrix to track which Beam features are supported by which set of language SDKs + Runners. This...",
          "slug": "runner-comparison-capability-matrix-revamp",
          "status": "completed",
          "student_name": "Aisulu Karimbaeva",
          "student_profile": null,
          "tags": [
            "ai",
            "ui",
            "ux"
          ],
          "title": "Runner Comparison / Capability Matrix revamp"
        },
        {
          "code_url": "https://github.com/apache/apisix-dashboard/pull/2538",
          "description": "​\tA simple route import and export module has been implemented in the current APISIX dashboard. But its implementation faces several problems.\n​\tFirst of all, in the currently implemented route data handler, the code is very complicated and does not follow the OAS 3.0. It also makes extensive use of custom variables and other non-standard formats.\n​\tAlso the APISIX Dashboard V3 refactoring plan already had a detailed roadmap with some changes that will affect the operation of the current data export and import module.       \n​\tThis proposal aims to implement a general data loader and exporter for APISIX, so that it can be extended to support a wider range of data formats while adhering to open standards and also improves compatibility and extensibility.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2022_033",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/QADLl2VF/",
          "proposal_id": null,
          "short_description": "​ A simple route import and export module has been implemented in the current APISIX dashboard. But its implementation faces several problems. ​...",
          "slug": "multi-source-data-import-and-export-extension-for-apisix-dashboard",
          "status": "completed",
          "student_name": "Feng Han",
          "student_profile": null,
          "tags": [
            "api",
            "ai"
          ],
          "title": "Multi-source data import and export extension for APISIX Dashboard"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2022/organizations/apache-software-foundation/"
    },
    "year_2023": {
      "num_projects": 25,
      "projects": [
        {
          "code_url": "https://abdelrahmanelawady.github.io/GSoC-2023/",
          "description": "Apache Traffic Control is a Content Delivery Network that that requires Apache Traffic Server as the underlying cache. The goal is to extend the caching configuration to support Varnish cache and update Traffic Monitor to monitor Varnish state.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/Y9YXNhle",
          "proposal_id": "fievIQpu",
          "short_description": "Apache Traffic Control is a Content Delivery Network that that requires Apache Traffic Server as the underlying cache. The goal is to extend the...",
          "slug": "varnish-cache-support-in-apache-traffic-control",
          "status": "completed",
          "student_name": "AbdulrahmanElawady",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "Varnish Cache support in Apache Traffic Control"
        },
        {
          "code_url": "https://github.com/AibekYrysbekov/airflow/tree/main/community/pmc-tool",
          "description": "Overview\nThis project aims to create a tool for Apache PMCs that will automate analysis of contributor activity in any given Apache repository.\nProject Goal\nThe project goal is to make it easy for PMCs to manage their communities. We will try to achieve this by developing a tool that automatically finds and tracks first (or 3rd, or 10th) pull requests in a specified repository on Github that belongs to a specific community. The idea is that the PMC can take this data and send “Thank you” notes or emails to new people that joined the community and made their first contribution. If these automatic reports show that there are contributors with consistent commits to the project, PMC can send them encouragement emails to keep up the good work and become committers, etc. \nProject Description \nThe tool will be based on using Github API to retrieve a list of all pull requests in the specified repository. Users will be able to set search parameters such as repository name and filters by pull request status.\nUsers can use this tool to:\nTrack pull requests in their own repositories \nTrack issues opened in their own repositories\nTrack the activity of individual contributors to encourage them to improve\nThe tool will provide a user-friendly interface for searching and filtering valuable community information, such as pull requests, issues, questions in StackOverflow and others. Users will also be able to configure notifications to receive alerts about new pull requests.\nTechnical Details\nThe tool will be developed in Python and will use the Github API directly to fetch data (another possibility is using the  PyGithub library to interact with Github API, however this may not be necessary). For the user interface, we can use the Flask or Django framework. The tool will be deployed on a web server and will be accessible through a browser.",
          "difficulty": "beginner",
          "id": "proj_the-apache-software-_2023_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/h1cLBx3O",
          "proposal_id": "sqgLGXS6",
          "short_description": "Overview This project aims to create a tool for Apache PMCs that will automate analysis of contributor activity in any given Apache repository....",
          "slug": "gsoc-242-project-proposal-for-airflow",
          "status": "completed",
          "student_name": "Aibek",
          "student_profile": null,
          "tags": [
            "python",
            "web",
            "api",
            "ai"
          ],
          "title": "[GSOC-242] Project proposal for Airflow"
        },
        {
          "code_url": "https://gist.github.com/ani5rudh/4d82f3498f20c9c1a6d6e429cffaab3b",
          "description": "My goal is to design an updated summary statistics API for use with Java 8 streams based on the summary statistic implementations in the Commons Math stat.descriptive package. The project aims to be a library of commons statistics functions in line with the latest developments in the Java language, in particular Java's functional programming syntax. At the end of the project I  plan to provide a lightweight and reusable API that utilizes Java streams to offer commonly used statistical functions, with an emphasis on minimizing external dependencies and avoiding redundancy.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/lEdvtw7o",
          "proposal_id": "8JN59XfI",
          "short_description": "My goal is to design an updated summary statistics API for use with Java 8 streams based on the summary statistic implementations in the Commons Math...",
          "slug": "new-summary-statistics-api-for-java-8-streams",
          "status": "completed",
          "student_name": "ani5rudh",
          "student_profile": null,
          "tags": [
            "java",
            "api",
            "ai"
          ],
          "title": "New Summary Statistics API for Java 8 streams"
        },
        {
          "code_url": "https://github.com/moomman/GSOC-Reporter2023-ShardingSphere-on-cloud",
          "description": "Problem:\nIntroduce New CRD ShardingSphereChaos to ShardingSphere.\nPlan:\n1. Design chaos based on ShardingSphere in a production environment\n2.Implement it to out environment by operator.define the status and spec of the corresponding crd based on the actual chaos implemented (considering its duration, running state). The chaos can be managed by writing corresponding logic code in reconcile.\n3.make it automatic and do a lot chaos experiments to improve system availability.\nResult: \n1.chaos CRD and controller. \n2.chaosEngineer theory about ShardingSphere\n3.automatic chaos engineer",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/dRt47Swt",
          "proposal_id": "bGtR94IT",
          "short_description": "Problem: Introduce New CRD ShardingSphereChaos to ShardingSphere. Plan: 1. Design chaos based on ShardingSphere in a production environment...",
          "slug": "introduce-new-crd-shardingspherechaos",
          "status": "completed",
          "student_name": "aroura",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Introduce New CRD ShardingSphereChaos"
        },
        {
          "code_url": "https://gist.github.com/chaminda-neluka/e2b96506cfdee6256a577f14aa21665b",
          "description": "The project proposes further extending multi model database support in Apache Gora with ArangoDB datastore and upgrade Hive and HBase datastore dependencies to become fully compatible with latest available API versions.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/iSEHsdtP",
          "proposal_id": "Z3ZODGVE",
          "short_description": "The project proposes further extending multi model database support in Apache Gora with ArangoDB datastore and upgrade Hive and HBase datastore...",
          "slug": "gora-708-improve-arangodb-datastore-and-upgrade-hive-and-hbase-dependencies",
          "status": "completed",
          "student_name": "chaminda-neluka",
          "student_profile": null,
          "tags": [
            "api",
            "ai",
            "database"
          ],
          "title": "GORA-708 Improve ArangoDB datastore and upgrade Hive and HBase dependencies"
        },
        {
          "code_url": "https://github.com/yanchaomei/GSOC2023/blob/main/README.md",
          "description": "RocketMQ 5.0 has released various language clients including Java, CPP, and Golang, to cover all major programming languages, a Python client needs to be implemented.\n\nReferring to the API design of the Java client, the Python client is also composed of several main modules: Consumer, Producer, Message, Metrics, and Client. The general process for implementing a python client is as follows:\n\n* Build a test environment\n* Automatically generate protocol layer code through the grpc protoc tool\n* Implementing Producer/SimpleConsumer\n* Implementing PushConsumer\n* Implement client metrics architecture based on OpenTelemetry/Open Focus",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/XEJasFhe",
          "proposal_id": "o7HWt6Xm",
          "short_description": "RocketMQ 5.0 has released various language clients including Java, CPP, and Golang, to cover all major programming languages, a Python client needs...",
          "slug": "gsoc-implement-python-client-for-rocketmq-50",
          "status": "completed",
          "student_name": "Chaomei Yan",
          "student_profile": null,
          "tags": [
            "python",
            "java",
            "api",
            "ai",
            "ui"
          ],
          "title": "GSoC Implement python client for RocketMQ 5.0"
        },
        {
          "code_url": "https://gist.github.com/ev1lQuark/7cb8c9fb32bc36fd73b70f0a2037656b",
          "description": "I am proposing an improvement to the observability capabilities of Apache Dubbo-go, a Dubbo implementation written in Golang used to solve communication and governance problems under the microservice architecture. The current implementation of the observability feature is not comprehensive enough and not aligned with Dubbo-java's implementation. My proposal consists of two major improvements, one for metrics and another for tracing. For metrics, the proposed improvements include adding metric instrumentation for the consumer side of RPC calls, as well as for the registry, configuration, metadata centers, and RPC exception handling. For tracing, the proposed improvements include enhancing the configuration loading and component initialization for tracing, adding support for the B3 standard, aligning the configuration with Dubbo-java, and adding support for other observability backends. The deliverables include feature implementation, tests, samples, and documentation.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/FC5ucrIH",
          "proposal_id": "QqbgLHvB",
          "short_description": "I am proposing an improvement to the observability capabilities of Apache Dubbo-go, a Dubbo implementation written in Golang used to solve...",
          "slug": "dubbo-gsoc-2023-go-observability-improvement",
          "status": "completed",
          "student_name": "Guan Wang",
          "student_profile": null,
          "tags": [
            "java",
            "backend"
          ],
          "title": "Dubbo GSoC 2023 - Go Observability Improvement"
        },
        {
          "code_url": "https://github.com/apache/skywalking-python/pull/316",
          "description": "Currently, SkyWalking Python agent is implemented with the Threading module to provide data reporters. Yet with the growth of the Python agent, it is now fully capable and requires more resources than when only tracing was supported. \n\nThe goal of this proposal is to refactor both the data reporters and communication protocol client parts using Python asyncio to improve performance and provide reliable test results and documentation.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/M7qsJ2mB",
          "proposal_id": "kUgZZKhu",
          "short_description": "Currently, SkyWalking Python agent is implemented with the Threading module to provide data reporters. Yet with the growth of the Python agent, it is...",
          "slug": "apache-skywalking-python-agent-performance-enhancement-plan",
          "status": "completed",
          "student_name": "Guohan Ling",
          "student_profile": null,
          "tags": [
            "python",
            "ui"
          ],
          "title": "Apache SkyWalking - Python Agent Performance Enhancement Plan"
        },
        {
          "code_url": "https://github.com/apache/incubator-teaclave",
          "description": "Teaclave currently lacks a mechanism for data providers to enforce policies on the data they upload, and also it cannot verify that the behavior of the uploaded function conforms to the expected rules. These two gaps leave the system vulnerable to exploitation by malicious actors.\n\nTo solve the problem, verification should be exerted on the uploaded function so that its behavior that it strictly conforms to a prescribed policy. The standard formal verifier can be adopted (e.g., Prusti, Creusot) to formally verify the function's behavior.\n\nA set of deliverables as follows can be anticipated in the coming future.\n\nMilestones: Basic policies (e.g., addition, subtraction) of the data can be verified by Teaclave; Complex policies can be verified.\n\nComponents: Verifier for the function code; Policy language adapters (adapt policy language to verifier); Policy language parser; Function source code converter (append policies to the functions).\n\nDocumentation: The internal working mechanism of the verification; How to write policies for the data.",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2023_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/jnoHeq00",
          "proposal_id": "y2NQOZ9P",
          "short_description": "Teaclave currently lacks a mechanism for data providers to enforce policies on the data they upload, and also it cannot verify that the behavior of...",
          "slug": "data-privacy-policy-definition-and-function-verification-for-teaclave",
          "status": "completed",
          "student_name": "Hiroki Chen",
          "student_profile": null,
          "tags": [],
          "title": "Data Privacy Policy Definition and Function Verification for Teaclave"
        },
        {
          "code_url": "https://github.com/apache/skywalking-terraform",
          "description": "Goal:\n○ To add a Terraform module for SkyWalking deployment to facilitate users in\nconveniently spinning up a cluster for demonstration or testing.\n○ To allow users to customize the Terraform provider according to their needs,\nmaking it feasible for them to use it in their production environment.\n○ To mainly focus on the support for AWS in the Terraform module for SkyWalking\ndeployment.\n○ To provide a hassle-free solution to users where they only need to provide their\naccess key/secret key, and the Terraform provider does the rest of the work,\nwhich includes creating VMs, creating database/OpenSearch or RDS,\ndownloading SkyWalking tars, configuring the SkyWalking, and starting the\nSkyWalking components (OAP/UI), creating public IPs/domain name, etc.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/ZR71GtF1",
          "proposal_id": "tSozsdhD",
          "short_description": "Goal: ○ To add a Terraform module for SkyWalking deployment to facilitate users in conveniently spinning up a cluster for demonstration or testing. ○...",
          "slug": "add-apache-skywalking-terraform-module",
          "status": "completed",
          "student_name": "infracop",
          "student_profile": null,
          "tags": [
            "ai",
            "database",
            "ui"
          ],
          "title": "Add Apache Skywalking Terraform Module"
        },
        {
          "code_url": "https://github.com/itsayushpandey/GSoC2023",
          "description": "The project adds support for importing and exporting virtual machines (VMs) from KVM Hypervisor into the CloudStack. It helps administrators better manage resources and transfer VMs if needed. The CloudStack currently supports this functionality only on VMWare and support on KVM (as one of the most popular open source hypervisor) can tremendously help many other users of CloudStack.\n\nIn terms of deliverables the following can be expected at the minimum:\n\n1. Implement/extend listUnmanagedInstances API: Lists unmanaged virtual machines (not existing in CloudStack but existing on the hypervisor side)\n2. Implement/extend importUnmanagedInstance: Import an unmanaged VM into CloudStack (this implies populating the database with the corresponding data)\n3. Implement/extend unmanageVirtualMachine: Make CloudStack forget a VM but do not remove it on the hypervisor side\n4. UI Changes to facilitate above API use through the web portal\n5. Integration tests and documentations for ease of use",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_011",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/f0gpheQM",
          "proposal_id": "CSmn1rsa",
          "short_description": "The project adds support for importing and exporting virtual machines (VMs) from KVM Hypervisor into the CloudStack. It helps administrators better...",
          "slug": "import-export-instances-on-kvm",
          "status": "completed",
          "student_name": "itsayushpandey",
          "student_profile": null,
          "tags": [
            "web",
            "api",
            "database",
            "cloud",
            "ui"
          ],
          "title": "Import-Export Instances on KVM"
        },
        {
          "code_url": "https://gist.github.com/kanha-gupta/c62ef45c0e427a682c1e3c2801dd211a",
          "description": "Shardingsphere federated query engine provides support for SQL statements. In the GSoc period, I have to add support for more MySQL SELECT statements so that more SQL statements can be converted into SQLNode. This can be achieved by: \n1- Analysing the SQL statement I have to add support of, 2-Figure out components & logic required , 3- Make changes in SQL federation engine optimizer files , 4- Optimize parser files , 5- Make changes in TEST files to ensure test is passing successfully.\nAfter the support for More SELECT statements queries is added, The users & developers will be benefitted by utilising more SELECT queries for MySQL .",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_012",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/UIxa8sz7",
          "proposal_id": "BnuDW01I",
          "short_description": "Shardingsphere federated query engine provides support for SQL statements. In the GSoc period, I have to add support for more MySQL SELECT statements...",
          "slug": "shardingsphere-enhance-sqlnodeconverterengine-to-support-more-mysql-sql-statements",
          "status": "completed",
          "student_name": "kanha-gupta",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "ShardingSphere Enhance SQLNodeConverterEngine to support more MySQL SQL statements"
        },
        {
          "code_url": "https://gist.github.com/JooKS-me/387ed3d2edba5bf427282df84125b2a0",
          "description": "shenyu-ingress-controller is an important step for Apache ShenYu to integrate into the cloud native ecosystem. This time gsoc roughly needs to complete the following steps:\n\n1. Implement the divide plugin to support host;\n\n2. Implement the divide plugin to dynamically configure the tls certificate;\n\n3. Develop a controller to implement the native API specification of ingress;\n\n4. Write unit tests and integration tests;\n\n5. Write deployment and usage documentation.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_013",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/RiNlevG8",
          "proposal_id": "PnwDE9W6",
          "short_description": "shenyu-ingress-controller is an important step for Apache ShenYu to integrate into the cloud native ecosystem. This time gsoc roughly needs to...",
          "slug": "shenyu-gsoc2023-shenyu-ingress-controller",
          "status": "completed",
          "student_name": "Kunshuai Zhu",
          "student_profile": null,
          "tags": [
            "api",
            "cloud"
          ],
          "title": "ShenYu Gsoc2023 - shenyu-ingress-controller"
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/AIRAVATA/Design+and+implementation+of+lifecycle+management+of+the+CyberShuttle+agents",
          "description": "Apache Airavata MFT is a distributed high-performance, multi-protocol data transfer engine to orchestrate data movement and operations across most cloud and on-premises storages. Agent is the core of this distributed system which does the heavy lifting of transfer jobs. Right now, agents have to be manually deploy and configure to start the transfer. This is a problem for researchers and people who need to transfer data without having much technical skills or time.\n\nUpdated Proposal Summary:\nUpdated proposal includes creating a desktop application and cybershuttle server to orchestrate the lifecycle management. This will guide cybershuttle agent and MFT agent from cybershuttle server to perform execution of jobs and data transfer, this would also maintain the lifecycle of cybershuttle agent and mft agents. This would help deploy any software and not limited to MFT agents.\n\nThe proposed solution is to automate the process of deploying and lifecycle management of the agents when a transfer job is submitted from an edge machine. This will help various researchers and people who needs to transfer data from a source to a destination without having much technical skills or time.\n\nThe deliverables are a piece of code to deploy the agent on various virtual machines, a piece of code to maintain the agent's lifecycle, an automated process for deployment and management, onboarding users and evaluating edge cases, and automated agent placement.\n\nThe benefits of the proposed solution are that it will make it easy and on the go solution for people even with less technical ability to use the vast speeds and advantages MFT offers. It will save time and effort for researchers and people who need to transfer data from a source to destination. It will make the MFT more user-friendly and accessible to a wider range of people. It not just stops at MFT, in fact users can deploy any containerizable applications using this solution.",
          "difficulty": "beginner",
          "id": "proj_the-apache-software-_2023_014",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/wjchXCVK",
          "proposal_id": "dVt4P79l",
          "short_description": "Apache Airavata MFT is a distributed high-performance, multi-protocol data transfer engine to orchestrate data movement and operations across most...",
          "slug": "design-and-implementation-of-lifecycle-management-of-the-cybershuttle-agents",
          "status": "completed",
          "student_name": "Praneeth Chityala",
          "student_profile": null,
          "tags": [
            "ai",
            "cloud",
            "ui"
          ],
          "title": "Design and implementation of lifecycle management of the CyberShuttle agents"
        },
        {
          "code_url": "https://gist.github.com/HaiqiQin/1825af8245210185d3d6f25b1fa52306",
          "description": "E2e (End to End), also known as end-to-end testing, is a method used to test whether the application flow is executed as designed from beginning to end, which can simulate the integrity and accuracy of a software system under real user scenarios. Currently, Shenyu only supports e2e test cases for the divide plugin, so this task requires adding test cases for the spring cloud plugin.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_015",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/OeKmTy4J",
          "proposal_id": "6uVSeyjm",
          "short_description": "E2e (End to End), also known as end-to-end testing, is a method used to test whether the application flow is executed as designed from beginning to...",
          "slug": "shenyu-springcloud-plugin-e2e-testcase-proposal",
          "status": "completed",
          "student_name": "QinHaiqi",
          "student_profile": null,
          "tags": [
            "ios",
            "cloud",
            "ui"
          ],
          "title": "shenyu-springcloud-plugin-e2e-testcase-proposal"
        },
        {
          "code_url": "https://medium.com/@reebaq2/real-world-ml-use-cases-apache-beam-gsoc-2023-report-edeb313d43ba",
          "description": "In this project, I want to create Jupyter notebooks for a real-world machine learning use case, especially image processing using publicly accessible datasets. The goal is to create a reference guide that others can use to build ML pipelines for image processing or computer vision problems. I already have experience working with image processing to detect breast cancer cells in histopathological images and want to leverage that to build a similar pipeline using Apache Beam for image processing use cases. This can also be expanded to other computer vision problems like object detection, facial recognition, optical character recognition, and hand gesture recognition for disabled people.\n\nFollowing are some ideas on notebooks that I can build and contribute to :\n\n1. Image Data Preprocessing: Apache Beam can be used to create a pipeline for different image pre-processing tasks like resizing, cropping, normalizing and filtering for different image file formats like TIFF, PNG and converting it into a more standardized format like JSON.\n\n2. Model Inference: We can showcase how trained models can be used to make real time inferences in a Beam pipeline.\n\n3. Model Evaluation: We can evaluate the model using Apache Beam, utilizing various metrics such as accuracy, precision, recall, and F1 score.\n\n4. Stretch Goal: If time permits, we can do a similar process for video datasets and show how to preprocess videos using Beam.\n\nDeliverables \n\nApache Beam notebook with working code to deploy a pipeline for image processing/video processing use case and supporting documentation.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_016",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/tCKZoqmv",
          "proposal_id": "L9IPqKPz",
          "short_description": "In this project, I want to create Jupyter notebooks for a real-world machine learning use case, especially image processing using publicly accessible...",
          "slug": "building-apache-beam-notebooks-for-real-world-ml-use-cases",
          "status": "completed",
          "student_name": "Reeba Qureshi",
          "student_profile": null,
          "tags": [
            "ml",
            "ai",
            "ui"
          ],
          "title": "Building Apache Beam Notebooks for Real-World ML Use Cases"
        },
        {
          "code_url": "https://docs.google.com/document/d/e/2PACX-1vThb7Ig7i7SbjLNGSVpqeyYNiWf93E37U7PiX2dyYBiQfr5iyxaFJ88_TJXXpEpycjZC7REaIi5BNju/pub",
          "description": "Currently, Beam has code completion plugins for Python and Golang SDKs in JetBrains IDEs. For example, Pycharm has a plugin called Alabaster that suggests beam transforms after typing a pipe character. However, IntelliJ IDEA does not have code completion for the Beam Java SDK. In this project, I will implement an IntelliJ Plugin to auto-complete beam transforms for Java SDK users using a Starcoder Language Model.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_017",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/rXHePT06",
          "proposal_id": "5kxfGyPa",
          "short_description": "Currently, Beam has code completion plugins for Python and Golang SDKs in JetBrains IDEs. For example, Pycharm has a plugin called Alabaster that...",
          "slug": "ai-code-completion-for-apache-beam-java-sdk",
          "status": "completed",
          "student_name": "Saadat",
          "student_profile": null,
          "tags": [
            "python",
            "java",
            "ai"
          ],
          "title": "AI Code Completion for Apache Beam Java SDK."
        },
        {
          "code_url": "https://cwiki.apache.org/confluence/display/AIRAVATA/Dashboards+to+get+quick+statistics",
          "description": "The Airavata Django Portal is a web interface to the Apache \nAiravata API implemented using the Django web framework.\nGateway admins need period reports on user count, running experiments, resource \nusage, and other relevant information to aid in their reporting and planning \nactivities. The primary task is development of dashboards where admins can get \nquick statistics. Data to be displayed on the dashboard is to be taken from Airavata \ndatabases making use of Airavata APIs. Apache Superset along with other libraries \ncan be employed to create the required dashboards using Vue.js.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_018",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/ZptJgBGs",
          "proposal_id": "D9ilOWEo",
          "short_description": "The Airavata Django Portal is a web interface to the Apache Airavata API implemented using the Django web framework. Gateway admins need period...",
          "slug": "dashboards-to-get-quick-statistics",
          "status": "completed",
          "student_name": "Saurav Kumar Jha",
          "student_profile": null,
          "tags": [
            "vue",
            "web",
            "api",
            "ai",
            "database"
          ],
          "title": "Dashboards to get quick statistics"
        },
        {
          "code_url": "https://github.com/apache/eventmesh-site/pull/126",
          "description": "Improve and maintain EventMesh documentation, including archiving Chinese and English content for different release versions, enhancing project quick start documents, providing feature introductions and display videos, etc.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_019",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/00W2TfS9",
          "proposal_id": "hinDTfpl",
          "short_description": "Improve and maintain EventMesh documentation, including archiving Chinese and English content for different release versions, enhancing project quick...",
          "slug": "apache-eventmesh-eventmesh-official-website-docs-by-version-and-demo-show",
          "status": "completed",
          "student_name": "Shukun Zhang",
          "student_profile": null,
          "tags": [
            "web",
            "ai",
            "ui"
          ],
          "title": "Apache EventMesh EventMesh official website docs by version and demo show"
        },
        {
          "code_url": "https://github.com/apache/doris/pull/23546",
          "description": "In the process of this task, a more comprehensive page cache system will be completed progressively for Apache Doris, aiming at better cache performance in large queries and more flexible cache GC. More reasonable cache eviction policy, more flexible GC trigger policy and more user-friendly configuration ways will be supported for better adaptation to OLAP scenarios.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_020",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/mfXgmxdQ",
          "proposal_id": "eL4XZLIl",
          "short_description": "In the process of this task, a more comprehensive page cache system will be completed progressively for Apache Doris, aiming at better cache...",
          "slug": "progressive-page-cache-improvement-for-apache-doris",
          "status": "completed",
          "student_name": "Siyang Tang",
          "student_profile": null,
          "tags": [
            "ios",
            "ai"
          ],
          "title": "Progressive Page Cache Improvement for Apache Doris"
        },
        {
          "code_url": "https://github.com/TheR1sing3un/GSoC",
          "description": "Based on the performance bottleneck issues in the current mode of RocketMQ, implement a high-performance, highly maintainable new version of the Controller module that provides low-latency master-slave switching capabilities, improves the upper limit of the number of brokers that a Controller node is responsible for, and uses the high-performance optimization of DLedger.\nI plan to optimize its performance in four directions：refactor the usage of DLedger on the Controller side, refactor the request interaction logic, multithreaded optimization, comprehensive correctness testing and performance testing.\nAfter this optimization is completed, the community will be provided with a high performance controller module and complete documentation and test reports",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_021",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/ShSzQCKe",
          "proposal_id": "OHF68Gc9",
          "short_description": "Based on the performance bottleneck issues in the current mode of RocketMQ, implement a high-performance, highly maintainable new version of the...",
          "slug": "rocketmq-dledger-controller-performance-optimization",
          "status": "completed",
          "student_name": "TheR1sing3un",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "RocketMQ DLedger Controller Performance Optimization"
        },
        {
          "code_url": "https://gist.github.com/trisha-melani-gsoc/ac9526ec11e7368207ef2a88bbb911f2",
          "description": "This project will upgrade Hadoop dependencies in Apache Gora repository and improve Geode datastore existing implementation for Apache Gora., that way Gora is apple communicate with Geode datastore, persist and query data as required.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_022",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/19qnve5z",
          "proposal_id": "XaVdMvXy",
          "short_description": "This project will upgrade Hadoop dependencies in Apache Gora repository and improve Geode datastore existing implementation for Apache Gora., that...",
          "slug": "gora-709-improve-geode-datastore-and-upgrade-hadoop-dependencies",
          "status": "completed",
          "student_name": "trisha-melani",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "GORA-709 Improve Geode datastore and upgrade Hadoop dependencies"
        },
        {
          "code_url": "https://docs.google.com/document/d/1O4XBiS7lvUb9iIz5c5UOL9lRZO2Jqs6NVV2l7lrVFKI/edit?usp=sharing",
          "description": "Through eventmesh‘s event bridge feature, we can connect data to heterogeneous data storage, we hope that the community can optimize the current eventbridge capability of EventMesh to realize the data connection of different event stores. We should verify the ability of different EventMesh cluster instances to synchronize data, sort out the corresponding verification step documents, and optimize the current EventMesh bridge features.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_023",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/8rkqnqNF",
          "proposal_id": "HEiftQLW",
          "short_description": "Through eventmesh‘s event bridge feature, we can connect data to heterogeneous data storage, we hope that the community can optimize the current...",
          "slug": "apache-eventmesh-optimize-the-event-bridge-on-eventmesh",
          "status": "completed",
          "student_name": "Yixiang Zhao",
          "student_profile": null,
          "tags": [],
          "title": "Apache EventMesh Optimize the event-bridge on EventMesh"
        },
        {
          "code_url": "https://github.com/SDUWYS/wys/blob/main/Google%20Summer%20of%20Code%202023%20Development%20of%20Dubbo%20Admin%20Dashboard%20UI%20Pages.md",
          "description": "Summary of the Development of Dubbo Admin Dashboard UI Pages:\nFirstly, I analyzed the specifications of the previous code in order to facilitate subsequent development and maintenance.Secondly, I optimized the functional modules that had already been implemented, and further upgraded some functions to make them more user-friendly.Finally, and most importantly, I analyzed the requirements for the new function, read through interface documents, implemented the interface, performed data joint debugging, and ultimately completed all functions and tested their functionality.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_024",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/tpu64rbb",
          "proposal_id": "OR5E5fVO",
          "short_description": "Summary of the Development of Dubbo Admin Dashboard UI Pages: Firstly, I analyzed the specifications of the previous code in order to facilitate...",
          "slug": "dubbo-gsoc-2023-development-of-dubbo-admin-dashboard-ui-pages",
          "status": "completed",
          "student_name": "yongshuai wang",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Dubbo GSoC 2023 - Development of Dubbo Admin Dashboard UI Pages"
        },
        {
          "code_url": "https://docs.google.com/document/d/1Kx_0rW7RqBerHXugttQhHKv3KpRFDEh7fZ2Hiafh69o/edit",
          "description": "Problem description:\nIn Apache Doris, dictionary encoding is performed during data writing and compaction. Dictionary encoding will be implemented on string data types by default. The dictionary size of a column for one segment is 1M at most. The dictionary encoding technology accelerates strings during queries.\n\nThe plans for this problem:\n1. Use automated coding methods to improve efficiency\n2. Optimize dictionary memory\n\nDeliverables:\nSome PRs for query layer dictionary memory optimization.\nSome PRs for storage layer coding method optimization.\nMonitoring items for storage layer memory.\nProper documentation and tests for the above-mentioned components.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2023_025",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2023/projects/D02XRff5",
          "proposal_id": "G9TRX73L",
          "short_description": "Problem description: In Apache Doris, dictionary encoding is performed during data writing and compaction. Dictionary encoding will be implemented on...",
          "slug": "gsocdorisdictionary-encoding-acceleration",
          "status": "completed",
          "student_name": "Yukang Lian",
          "student_profile": null,
          "tags": [],
          "title": "[GSoC][Doris]Dictionary Encoding Acceleration"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/programs/2023/organizations/apache-software-foundation"
    },
    "year_2024": {
      "num_projects": 20,
      "projects": [
        {
          "code_url": "https://github.com/zjregee/ovfs",
          "description": "Virtio is an open standard designed to enhance I/O performance between virtual machines (VMs) and host systems in virtualized environments. VirtioFS is an extension of the Virtio standard specifically crafted for file system sharing between VMs and the host. This is particularly beneficial in scenarios where seamless access to shared files and data between VMs and the host is essential. VirtioFS has been widely adopted in virtualization technologies such as QEMU and Kata Container.\n\nApache OpenDAL is a data access layer that allows users to easily and efficiently retrieve data from various storage services in a unified manner. In this project, our goal is to reference virtiofsd (a standard vhost-user backend, a pure Rust implementation of VirtioFS based on the local file system) and implement VirtioFS based on OpenDAL.\n\nThrough this project, VMs can access numerous data services through the file system interface with the assistance of the OpenDAL service daemon deployed on the host, all without their awareness. It ensures the efficiency of file system reading and writing in VMs through VirtioFS support. This storage-system-as-a-service approach conceals the details of the distributed storage system from VMs. This ensures the security of storage services, as VMs do not need to be aware of the information, configuration and permission credentials of the accessed storage service. Additionally, it enables the utilization of a new backend storage system without reconfiguring all VMs.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/SprO8wOO/",
          "proposal_id": null,
          "short_description": "Virtio is an open standard designed to enhance I/O performance between virtual machines (VMs) and host systems in virtualized environments. VirtioFS...",
          "slug": "ovfs-opendal-file-system-via-virtio",
          "status": "completed",
          "student_name": "zjregee",
          "student_profile": null,
          "tags": [
            "ios",
            "ml",
            "ai",
            "backend"
          ],
          "title": "OVFS, OpenDAL File System via Virtio"
        },
        {
          "code_url": "https://www.ganningxu.com/blog/google-summer-of-code-apache-airavata-cybershuttle",
          "description": "Currently, Apache Airavata Managed File Transfers (MFT) is accessed through a command line interface (CLI), using commands such as mft storage list. However, it is also possible to access MFT through the gRPC API. Thus, developing a desktop application for a user interface is entirely possible and would make MFT accessible to even more people. Such a user interface would have the following functionalities and deliverables:\n\n- Provide all the functionalities the MFT CLI provides, such as:\n- Start & stop a MFT instance\n- Storage Functionality\n    - Register storages (S3, Google Cloud Storage, Azure, Openstack SWIFT, SCP, FTP, Box, - DropBox, OData, Agent, HTTP)\n    - List storages\n    - Remove storages\n- File Functionality\n    - List files in storage\n    - Move files between storage endpoints\n    - Add files to storage\n    - Remove file from storage\n    - Upload files to storage\n- Search for data files between multiple storage endpoints\n- Get performance numbers (such as transfer rates in each agent) and other analytics\n\nSuch a user interface will likely involve the use of ElectronJS on the frontend and a node.js backend, which connects through the gRPC API to communicate with Airavata MFT.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/TXAWwjun/",
          "proposal_id": null,
          "short_description": "Currently, Apache Airavata Managed File Transfers (MFT) is accessed through a command line interface (CLI), using commands such as mft storage list....",
          "slug": "building-rich-user-interfaces-for-airavata-services",
          "status": "completed",
          "student_name": "Ganning Xu",
          "student_profile": null,
          "tags": [
            "api",
            "ai",
            "cloud",
            "ui",
            "frontend"
          ],
          "title": "Building Rich User Interfaces for Airavata Services"
        },
        {
          "code_url": "https://gist.github.com/mac-op/3736a9a76349c7abc4d2a064c8de42ef",
          "description": "UIMA is a framework for unstructured information management, in production use for about two decades. The framework is available in C++ and Java, where the C++ version  implements a subset of the features of the Java version. This project aims to implement the full framework in C++ through adding support for aggregate engines by mirroring that of the Java implementation.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/gMqxBugf/",
          "proposal_id": null,
          "short_description": "UIMA is a framework for unstructured information management, in production use for about two decades. The framework is available in C++ and Java,...",
          "slug": "support-for-aggregate-engines-in-apache-uima-cpp",
          "status": "completed",
          "student_name": "Huy T",
          "student_profile": null,
          "tags": [
            "java",
            "ai",
            "ui"
          ],
          "title": "Support for Aggregate Engines in Apache UIMA CPP"
        },
        {
          "code_url": "https://gist.github.com/cnzakii/6ec192eaaac5086369c0bf677412c9e6",
          "description": "The proposal aims to enhance Dubbo-python to meet the evolving needs of the AI sector by addressing compatibility issues, architectural limitations, and functionality gaps. Currently, Dubbo-python faces challenges due to its reliance on Python 2, deprecated libraries, and incomplete RPC communication capabilities, hindering its adoption within mainstream AI frameworks. To tackle these issues, the plan includes:\n1. Upgrading Dubbo-python to support Python 3 and modernizing its architecture following the Microkernel + Plugin design principle.\n2. Implementing complete RPC communication functionality, including server-side service exposure and client-side service invocation, with support for the new Triple protocol.\n3. Developing service governance capabilities such as service discovery, registration, and load balancing, including the design of a GPU metric-based load balancing algorithm to address GPU workload imbalances in AI frameworks.\n4. Writing comprehensive test codes to ensure the reliability of each functionality and providing detailed documentation to facilitate easier adoption and contribution to Dubbo-python.\nBy accomplishing these objectives, the aim is to transform Dubbo-python into a robust, high-performance RPC framework compatible with mainstream AI frameworks, thus empowering developers to build scalable and efficient AI systems.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/PxEnkiBZ/",
          "proposal_id": null,
          "short_description": "The proposal aims to enhance Dubbo-python to meet the evolving needs of the AI sector by addressing compatibility issues, architectural limitations,...",
          "slug": "dubbo-python-integration-ai-traffic-management",
          "status": "completed",
          "student_name": "Zikang Chen",
          "student_profile": null,
          "tags": [
            "python",
            "ai",
            "ui"
          ],
          "title": "Dubbo - Python integration & AI Traffic Management"
        },
        {
          "code_url": "https://gist.github.com/ButterBright/db5ae63583770ebbe54282342525712e",
          "description": "This project aims to enhance query efficiency through two main optimizations. Firstly, it will focus on improving stream filtering and sorting queries by reducing unnecessary I/O operations. Secondly, the project will leverage the Bluge API to optimize inverted index queries of measure through reducing the number of query executions. These optimizations will significantly improve the system's overall query performance.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/eIOi0A44/",
          "proposal_id": null,
          "short_description": "This project aims to enhance query efficiency through two main optimizations. Firstly, it will focus on improving stream filtering and sorting...",
          "slug": "optimization-of-the-query-subsystem-in-banyandb",
          "status": "completed",
          "student_name": "ButterBright",
          "student_profile": null,
          "tags": [
            "api",
            "ai"
          ],
          "title": "Optimization of the Query Subsystem in BanyanDB"
        },
        {
          "code_url": "https://gist.github.com/Sylvie-Wxr/5533163fbba47dc399b7408458a50c42",
          "description": "SkyWalking BanyanDB is an observability database designed to ingest, analyze, and store metrics, tracing, and logging data. The goal of this project is to implement a built-in monitoring feature for the SkyWalking BanyanDB cluster.  This will be achieved by developing database functionalities to store and extract node metrics in the cluster and by creating an overview page in the Web App to display the nodes status.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/s31z2duw/",
          "proposal_id": null,
          "short_description": "SkyWalking BanyanDB is an observability database designed to ingest, analyze, and store metrics, tracing, and logging data. The goal of this project...",
          "slug": "apache-skywalking-banyandb-cluster-monitoring",
          "status": "completed",
          "student_name": "Sylvie Wu",
          "student_profile": null,
          "tags": [
            "web",
            "database",
            "ui"
          ],
          "title": "Apache SkyWalking - BanyanDB Cluster Monitoring"
        },
        {
          "code_url": "https://github.com/apache/opendal/issues/5029",
          "description": "OpenDAL is a data access layer that allows users to easily and efficiently retrieve data from various storage services in a unified way. currently `ofs` can expose OpenDAL power in a `fuse` way that allow users to mount storage services locally.\n\nBut `fuse` is only support Linux and some UNIX platforms which limits the usage scenarios of `ofs`. So we need to support other popular platform i.e. Windows to extend its usage scenarios.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/LL5vQ6HN/",
          "proposal_id": null,
          "short_description": "OpenDAL is a data access layer that allows users to easily and efficiently retrieve data from various storage services in a unified way. currently...",
          "slug": "apache-opendal-ofs-via-cloudfilter-project-proposal",
          "status": "completed",
          "student_name": "Ho 229",
          "student_profile": null,
          "tags": [
            "ios",
            "cloud",
            "ux"
          ],
          "title": "Apache OpenDAL Ofs via CloudFilter Project Proposal"
        },
        {
          "code_url": "https://gist.github.com/SHA-4096/0402c337a87e239e05c3c43a40d688e8",
          "description": "Objectives:\n1. Develop toolsets to help unify the development experience using dubbo's IDL mode and Non-IDL mode  \n\n2. Develop a set of translation tools to translate in-code interface definition to Protobuf IDL, so that the interface defined in-code can be easily migrated to other programming languages.\n\nPlan:\n1. Community bonding\n2. Basic and extended type mapping between portobuf and non-IDL protocol types\n3. Add support to protocol specification in protobuf IDL\n4. Add support to reverse translation from in-code interface definition to protobuf IDL\n5. Wrap the toolsets into a easy-to-use CLI\n\nDeliveries:\n1. A CLI that unifies the development using dubbo's IDL and Non-IDL mode\n2. Protobuf extensions to help acturalize the features mentioned above",
          "difficulty": "beginner",
          "id": "proj_the-apache-software-_2024_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/d7xCkgQ1/",
          "proposal_id": null,
          "short_description": "Objectives: 1. Develop toolsets to help unify the development experience using dubbo's IDL mode and Non-IDL mode 2. Develop a set of translation...",
          "slug": "proposal-for-unified-idl",
          "status": "completed",
          "student_name": "Chales Xu",
          "student_profile": null,
          "tags": [],
          "title": "Proposal for Unified IDL"
        },
        {
          "code_url": "https://github.com/apache/incubator-hugegraph/wiki/%5BMemory-Management%5D-GSoC-2024-Final-Report",
          "description": "This project addresses the latency and response time variability issues in the hugegraph-server query engine by introducing memory management framework to it. Currently, the engine utilizes off-heap memory in most OLTP algorithms, but lacks the ability to control memory allocation per individual query, leading to potential out-of-memory (OOM) errors. The project aims to design and implement a unified memory management framework to address this limitation. This framework will include features such as lifecycle management of memory objects, memory capacity restrictions, and an allocator interface for efficient memory allocation and release. By implementing this framework, the project is expected to improve the stability and performance of the hugegraph-server, ultimately enhancing its usability and reliability for users.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/GhIkUpuq/",
          "proposal_id": null,
          "short_description": "This project addresses the latency and response time variability issues in the hugegraph-server query engine by introducing memory management...",
          "slug": "support-memory-management-module-for-apache-hugegraph",
          "status": "completed",
          "student_name": "Pengzna",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Support Memory Management Module For Apache HugeGraph"
        },
        {
          "code_url": "https://github.com/apache/nuttx/issues/11979#issuecomment-2307655305",
          "description": "NAND flashes have become a very popular medium of storage mainly due to their compactness and cheapness compared to their alternatives, among other advantages. But NAND flashes are accompanied by some unique challenges that need to be considered if a file system were to support such storage devices.\n\nApache NuttX is in need for such a file system, as it would mean multiple storage intensive systems using NuttX can shift to much cheaper NAND flash storage options.\n\nThus, this proposal aims to provide the design for mnemofs, a file system designed to support NAND flashes, keeping in mind the limitations of embedded systems, and a Real Time Operating System running on such systems.",
          "difficulty": "medium",
          "id": "proj_the-apache-software-_2024_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/JISwnjR5/",
          "proposal_id": null,
          "short_description": "NAND flashes have become a very popular medium of storage mainly due to their compactness and cheapness compared to their alternatives, among other...",
          "slug": "mnemofs-an-apache-nuttx-nand-flash-filesystem",
          "status": "completed",
          "student_name": "resyfer",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "mnemofs: An Apache NuttX NAND Flash Filesystem"
        },
        {
          "code_url": "https://github.com/apache/airavata-custos",
          "description": "Currently, Airavata MFT can be accessed through its command line interface and the gRPC API. However, its accessibility will be really enhanced if a Docker desktop-like application and a JupyterLab-S3-Browser-like Jupyter extension are provided for locally running Airavata MFT. \nSome proposed features for the app and the extension are:\n- Start / Stop MFT Instance\n- Register/ List/ Remove Storage endpoints\n- Access data (list, download, delete, upload) in configured storage endpoints\n- Move data between storage endpoints\n- Search data across multiple storage endpoints\n- Analytics - Performance numbers (data transfer rates in each agent)\n\nWe will use Electron to develop the desktop app. The Node.js backend of Electron will connect to Airavata MFT using gRPC to perform management operations. We will first develop an Airavata MFT Node SDK similar to the existing Python SDK. The Electron app and the Jupyter extension will then be built on top of this Node SDK. Publishing the SDK as a stand-alone npm package will also open possibilities for building new tools using Airavata MFT in future.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_011",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/wp8QUxkw/",
          "proposal_id": null,
          "short_description": "Currently, Airavata MFT can be accessed through its command line interface and the gRPC API. However, its accessibility will be really enhanced if a...",
          "slug": "implement-jupyter-extension-and-desktop-app-for-airavata-mft",
          "status": "completed",
          "student_name": "Shivang Mishra",
          "student_profile": null,
          "tags": [
            "python",
            "api",
            "ai",
            "docker",
            "ui"
          ],
          "title": "Implement Jupyter Extension and Desktop App for Airavata MFT"
        },
        {
          "code_url": "https://gist.github.com/melani-chamoda/bffa29c5b4844b87c9e8d52269cd0124",
          "description": "This project aims to upgrade Hadoop dependencies in Apache Gora repository. Apache Gora codebase is based on hadoop 2.x ( 2.5.2 ) and project proposes to upgrade to 3.x ( 3.4 ) Additionally this project aims to improve Geode datastore existing implementation for Apache Gora, that way Gora is apple communicate with Geode datastore, persist and query data as required.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_012",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/3HQFL9H1/",
          "proposal_id": null,
          "short_description": "This project aims to upgrade Hadoop dependencies in Apache Gora repository. Apache Gora codebase is based on hadoop 2.x ( 2.5.2 ) and project...",
          "slug": "gora-709-upgrade-hadoop-dependencies-in-apache-gora",
          "status": "completed",
          "student_name": "melani-chamoda",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "[GORA-709] Upgrade Hadoop dependencies in Apache Gora"
        },
        {
          "code_url": "https://github.com/YarBor/gsoc/blob/main/README.md",
          "description": "Build the traffic rule distribution process of dubbo-b8s, implement traffic rule push in various environments such as k8s, universal, mesh, enhance the traffic management of dubbo-go, adapt dubbo-go to the Service Mesh environment, write dubbo-go-xDS-client-sdk to implement dubbo-go's support for the xDS protocol, and write related demos.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_013",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/plyDlESx/",
          "proposal_id": null,
          "short_description": "Build the traffic rule distribution process of dubbo-b8s, implement traffic rule push in various environments such as k8s, universal, mesh, enhance...",
          "slug": "traffic-management-for-dubbo-go-and-dubbo-k8s-feature-enhancement-and-demonstration",
          "status": "completed",
          "student_name": "WangYibo",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "Traffic Management for Dubbo-go and Dubbo-k8s, feature enhancement and demonstration"
        },
        {
          "code_url": "https://github.com/apache/opendal/tree/main/integrations/unftp-sbe",
          "description": "OpenDAL is a data access layer that allows users to easily and efficiently retrieve data from various storage services in a unified way. oftp can expose OpenDAL power in FTP way that allow users to access storage services via FTP protocol.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_014",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/RBW1uuxq/",
          "proposal_id": null,
          "short_description": "OpenDAL is a data access layer that allows users to easily and efficiently retrieve data from various storage services in a unified way. oftp can...",
          "slug": "opendal-ftp-server-oftp",
          "status": "completed",
          "student_name": "George Miao",
          "student_profile": null,
          "tags": [],
          "title": "OpenDAL FTP Server (oftp)"
        },
        {
          "code_url": "https://github.com/apache/shardingsphere/pull/32396",
          "description": "Apache ShardingSphere(SS) Community focus on code quality and we ever used CodeCov as the test tool. However, when SS update JunitTest Version From 4 to 5. The CodeCov might can’t support service as before. We have fully instruction on code specification thus I will focus on create a code test scanner and we can use it to determine which code not write Junit test or not follow the code specification. After that I will figure out the correct file path to make the Jacoco works well and use the Sonar cloud generate report.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_015",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/CsAwI4xc/",
          "proposal_id": null,
          "short_description": "Apache ShardingSphere(SS) Community focus on code quality and we ever used CodeCov as the test tool. However, when SS update JunitTest Version From 4...",
          "slug": "runzes-proposal-for-ss-scan-and-create-issues-for-classes-that-have-not-implemented-unit-tests",
          "status": "completed",
          "student_name": "Tommy(Runze) Li",
          "student_profile": null,
          "tags": [
            "cloud"
          ],
          "title": "Runze's Proposal for [SS] Scan and create issues for classes that have not implemented unit tests"
        },
        {
          "code_url": "https://medium.com/@reebaq2/apache-beam-yaml-features-gsoc-2024-report-c39f01dacc1c",
          "description": "The aim of this project is to enhance the Beam Yaml API by introducing ML and IO transforms to provide the users with more functionalities. The suggested set of transforms to be implemented are: \n1. RunInference\n2. ReadFromSpanner\n3. WriteToSpanner\n4. Enrichment Transforms\n\nI also want to add three use cases for the Yaml API, providing end-to-end pipelines demonstrating the use of the newly implemented transforms. The suggested use cases are:\n1. Text processing with MLTransform and RunInference\n2. Processing tabular data from Spanner\n3. Enriching tabular customer data with Enrichment Transform. \n\nBy expanding the capabilities of the Yaml API, the goal is to streamline the process of constructing and managing data pipelines using Apache Beam. This improvement will enable users to tackle a wider array of data processing tasks with greater ease and efficiency, potentially attracting a broader audience to leverage Apache Beam for their data processing needs.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_016",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/KePyLXdR/",
          "proposal_id": null,
          "short_description": "The aim of this project is to enhance the Beam Yaml API by introducing ML and IO transforms to provide the users with more functionalities. The...",
          "slug": "build-out-beam-yaml-features",
          "status": "completed",
          "student_name": "Reeba Qureshi",
          "student_profile": null,
          "tags": [
            "api",
            "ml",
            "ai",
            "ui"
          ],
          "title": "Build out Beam Yaml features"
        },
        {
          "code_url": "https://github.com/itsayushpandey/GSoC2024",
          "description": "Apache Beam through its unified model for batch and streaming data-parallel processing pipelines, runners for executing them on a variety of distributed processing backends and ML specialized transforms within MLTransform (such as EmbeddingManager  and other MLTransformProvider) make it uniquely positioned for building out RAG (Retrieval Augmented Generation) based applications. These applications are one of the most useful and commonly being built applications on LLMs (Large Language Models).\n\nFor this project we will focus on building a knowledge base on a vector database for a text corpus, and enriching user's questions with matching text chunks using semantic search. This is a crucial part of any RAG applications and helps us in building the right prompt context for LLMs. \n\nWe will implement the following deliverables to achieve this:\n\n1. Build a Beam pipeline that takes in a batch text corpus from a public dataset as parameter to pipeline and uses MLTransform to generate and save Embeddings in batch mode to a vector database.\n- Initial scope: Wikipedia dataset with JinaAI Embeddings read from object storage and written to RedisIO to publish to known vector DB.\n\n2. Build a Beam pipeline that takes in stream of text questions from clients and enriches it with related texts from the vector DB.\n- Initial scope: KafkaIO based reading of queries which is populated by producers independently and published in a different topic for results.\n\n3. New enrichment handlers for vector database queries over Redis based Vector DB\n\nStretch goals:\n\n1. Implement enrichment handlers for OpenSearch (AWS supported)[4]\n2. Implement enrichment handlers for Vertex AI Vector Search (GCP Supported)[5]\n\n\nThe goal is to demonstrate semantic search building capabilities trivially using Beam and hence evaluation of search results is not tied to a broad benchmark (such as MTEB) for this project's scope.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_017",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/bOmqicBe/",
          "proposal_id": null,
          "short_description": "Apache Beam through its unified model for batch and streaming data-parallel processing pipelines, runners for executing them on a variety of...",
          "slug": "build-out-beam-use-cases-implement-semantic-search-pipelines",
          "status": "completed",
          "student_name": "itsayushpandey",
          "student_profile": null,
          "tags": [
            "ml",
            "ai",
            "database",
            "ui",
            "backend"
          ],
          "title": "Build out Beam Use Cases - Implement semantic search pipelines"
        },
        {
          "code_url": "https://shimo.im/docs/473QM8m8ByCn6l3w/",
          "description": "1.Examine the locking mechanism in RocketMQ and analyze any potential performance bottlenecks it may cause.\n2.Design flexible lock optimization strategies to improve message sending and processing performance\n3.Finally, the design of adaptive lock will be realized, the research results will be condensed into reports or articles, and our findings will be submitted to academic journals or conferences",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_018",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/rAINlqkW/",
          "proposal_id": null,
          "short_description": "1.Examine the locking mechanism in RocketMQ and analyze any potential performance bottlenecks it may cause. 2.Design flexible lock optimization...",
          "slug": "optimizing-lock-mechanisms-in-apache-rocketmq",
          "status": "completed",
          "student_name": "hqbfz",
          "student_profile": null,
          "tags": [],
          "title": "Optimizing Lock Mechanisms in Apache RocketMQ"
        },
        {
          "code_url": "https://github.com/rushabhvg/rushabhvg.github.io/blob/master/articles/end_report.md",
          "description": "The integration of Rust into Apache NuttX, an embedded Real-Time Operating System (RTOS) used across various platforms from 8-bit to 64-bit, aims to enhance the security and reliability of IoT applications. Rust, known for its safety and memory integrity, is seen as a promising solution to address vulnerabilities in IoT systems, such as buffer overflows and memory corruption. The project involves studying Rust for embedded systems and \"no_std\" environments, creating coding guidelines for Rust in NuttX, and developing a guide for these standards. It starts with converting simple NuttX applications, like the LED Blinky App, to Rust, gradually moving to more complex applications.\n\nThe deliverables include implementing Embedded Rust, C Interoperability, and Heap Memory Allocation in Rust, porting the LED Blinky App from C to Rust, and testing it on various Single-Board Computers. The project also aims to merge these items into NuttX Mainline as Pull Requests and add workarounds for NuttX's rustc build process. Documentation will cover a coding standard for Rust, setting up a local environment for Rust build, configuring NuttX to work with Rust, and building Rust firmware with NuttX.",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2024_019",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/6XD00y5S/",
          "proposal_id": null,
          "short_description": "The integration of Rust into Apache NuttX, an embedded Real-Time Operating System (RTOS) used across various platforms from 8-bit to 64-bit, aims to...",
          "slug": "apache-nuttx-apps-and-rust-integration",
          "status": "completed",
          "student_name": "Rushabh Gala",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Apache NuttX Apps and Rust Integration"
        },
        {
          "code_url": "https://github.com/1294566108/GSoC-2024-List/blob/main/list",
          "description": "With the launch of RocketMQ 5.0 architecture, the RocketMQ Dashboard has not been well adapted to RocketMQ 5.0. There have been issues with Dashboard being unable to create various themes for V5, lack of support for Proxy components, and incorrect master-slave synchronization metrics.\nTherefore, we need to adapt the RocketMQ Dashboard to the RocketMQ 5.0 architecture in this project to enhance its usability.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2024_020",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2024/projects/XF1NcQuS/",
          "proposal_id": null,
          "short_description": "With the launch of RocketMQ 5.0 architecture, the RocketMQ Dashboard has not been well adapted to RocketMQ 5.0. There have been issues with Dashboard...",
          "slug": "rocketmq-dashboard-supports-rocketmq-50-architecture-and-enhances-usability",
          "status": "completed",
          "student_name": "ZiweiYuan",
          "student_profile": null,
          "tags": [],
          "title": "RocketMQ Dashboard Supports RocketMQ 5.0 Architecture and Enhances Usability"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2024/organizations/apache-software-foundation/"
    },
    "year_2025": {
      "num_projects": 27,
      "projects": [
        {
          "code_url": null,
          "description": "Currently, Dubbo Python exposes a serialization function interface that requires users to implement their own serialization methods. For commonly used serialization formats such as JSON and Protobuf, users must manually configure them each time. To streamline this process, we aim to build a built-in serialization layer that provides support for these common serialization formats by default.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/CnQMbU0M",
          "proposal_id": "1Uh5Dsfu",
          "short_description": "Currently, Dubbo Python exposes a serialization function interface that requires users to implement their own serialization methods. For commonly...",
          "slug": "enhancing-dubbo-python-serialization",
          "status": "in-progress",
          "student_name": "AdityaYadav",
          "student_profile": null,
          "tags": [
            "python",
            "ml",
            "ai",
            "ui"
          ],
          "title": "Enhancing Dubbo Python Serialization"
        },
        {
          "code_url": null,
          "description": "Apache Kvrocks currently uses a minimalistic UI for its Controller, which limits usability and lacks advanced features. This project aims to revamp the Kvrocks Controller UI with a modern frontend stack (Next.js, Tailwind CSS) enhancing both functionality and user experience.\n\nKey deliverables include:\n\nA fully redesigned, responsive UI with clear navigation and real-time cluster visualization.\n\nSupport for single sign on (SSO) authentication.\n\nInterfaces for cluster slot migration and master node failover handling.\n\nIntuitive forms and dashboards for managing instances, namespaces, and configuration.\n\nThis improved UI will make it easier for developers and administrators to monitor and control Kvrocks clusters at scale, significantly enhancing the accessibility and robustness of the platform.",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2025_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/HH06mbPA",
          "proposal_id": "lSDmv1Qr",
          "short_description": "Apache Kvrocks currently uses a minimalistic UI for its Controller, which limits usability and lacks advanced features. This project aims to revamp...",
          "slug": "kvrocks-improve-the-controller-ui",
          "status": "in-progress",
          "student_name": "Agnik Misra",
          "student_profile": null,
          "tags": [
            "ai",
            "ui",
            "frontend"
          ],
          "title": "[Kvrocks] Improve the controller UI"
        },
        {
          "code_url": null,
          "description": "The current Apache Seata Server supports the Raft cluster mode, but the performance and throughput of the cluster are significantly limited due to the single leader in a single Raft group. Therefore, the goal is to extend Seata Server to support multi-raft capability.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/elIJRNz8",
          "proposal_id": "PDZwUEu1",
          "short_description": "The current Apache Seata Server supports the Raft cluster mode, but the performance and throughput of the cluster are significantly limited due to...",
          "slug": "extend-multi-raft-cluster-mode",
          "status": "in-progress",
          "student_name": "Andrew SEif",
          "student_profile": null,
          "tags": [],
          "title": "Extend multi-raft cluster mode"
        },
        {
          "code_url": null,
          "description": "The BeamVision extension revolutionizes interactive pipeline development in JupyterLab by transforming fragmented notebook visualizations into an integrated workspace, as envisioned in the original design document. At its core lies a dynamic side panel that fundamentally reimagines how users inspect Apache Beam pipelines - consolidating previously scattered visualizations while preserving the documented backward compatibility requirements. This architectural shift directly addresses the project's stated pain points of vertical space consumption and redundant JavaScript code by implementing the described collapsible interface and centralized rendering system. The solution carefully balances innovation with technical constraints through a hybrid approach combining kernel-side HTML generation for reliability with frontend D3.js rendering for interactivity, both explicitly prioritized in the project's technical specifications. Beyond basic visualization, the implementation delivers on the documented cluster management capabilities, providing seamless Flink/Dataproc integration exactly as outlined in the side panel use cases. Every component maintains strict adherence to the original vision - from the multi-tab comparison interface described in the design workflow to the incremental data loading strategy for large datasets. By systematically executing the documented requirements without introducing unsupported features, BeamVision transforms the proposal's vision of \"better UX when exploring pipeline states\" into a production-ready reality while laying foundations for future extensibility through the approved plugin architecture. The result is a purpose-built environment that finally unlocks Apache Beam's full potential within JupyterLab, precisely as the project architects intended.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/xswqwNdM",
          "proposal_id": "vxxey6Pd",
          "short_description": "The BeamVision extension revolutionizes interactive pipeline development in JupyterLab by transforming fragmented notebook visualizations into an...",
          "slug": "enhanced-interactive-pipeline-development-environment-for-jupyterlab",
          "status": "in-progress",
          "student_name": "Canyu Chen",
          "student_profile": null,
          "tags": [
            "java",
            "javascript",
            "ml",
            "ai",
            "ui"
          ],
          "title": "Enhanced Interactive Pipeline Development Environment for JupyterLab"
        },
        {
          "code_url": null,
          "description": "This project aims to transform HugeGraph-LLM's current GraphRAG system into an intelligent agent-based architecture that dynamically adapts to query intents. The existing system suffers from rigid workflows, coupled execution resources, and limited feedback mechanisms, causing inefficiency and high overhead in complex scenarios.\nI propose a three-layer solution:\nDynamic Awareness Layer: Implementing an LLM-based intent classifier that categorizes queries into complexity levels (L1-L4+) with >90% accuracy, using feature extraction and caching to achieve millisecond-level response time.\nTask Orchestration Layer: Creating a preemptive scheduling mechanism that prioritizes critical queries and isolates resources, preventing long-running operations from blocking high-priority tasks.\nConcurrent Execution Engine: Decoupling the RAG pipeline into independent operations with parallel execution capabilities and automatic degradation strategies when sub-operations fail.\nDeliverables include:\nAn intent classification system with millisecond-level matching\nA flexible task orchestration framework with dynamic routing\nA concurrent execution engine with intelligent fallback mechanisms\nA dialogue memory management module for context tracking\nA semi-automatic schema generator for graph model creation\nGraph algorithm enhancements for optimized knowledge retrieval\nComprehensive documentation and performance benchmarks\nThis architecture will significantly improve system performance (40% faster response for simple queries), increase throughput (30% improvement under high load), and enhance resource utilization while maintaining robust error handling.",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2025_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/ZVrEnq6S",
          "proposal_id": "7o7B4LC9",
          "short_description": "This project aims to transform HugeGraph-LLM's current GraphRAG system into an intelligent agent-based architecture that dynamically adapts to query...",
          "slug": "implement-agentic-graphrag-architecture-for-hugegraph",
          "status": "in-progress",
          "student_name": "Chaomei Yan",
          "student_profile": null,
          "tags": [
            "ios",
            "ai"
          ],
          "title": "Implement Agentic GraphRAG Architecture for HugeGraph"
        },
        {
          "code_url": null,
          "description": "Apache Beam is a unified programming model for authoring embarrassingly parallel batch and streaming data processing pipeline. The relatively new Beam YAML SDK was introduced in the spirit of making data processing easy, but it has gained little adoption for ML tasks and was not widely used with Kafka and Iceberg. We want to address this gap by introducing new illustrative examples and documentation for ML use cases and integration with Kafka and Iceberg using the YAML SDK.",
          "difficulty": "beginner",
          "id": "proj_the-apache-software-_2025_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/f4kiDdus",
          "proposal_id": "xcz1QIwo",
          "short_description": "Apache Beam is a unified programming model for authoring embarrassingly parallel batch and streaming data processing pipeline. The relatively new...",
          "slug": "beam-yaml-kafka-and-iceberg-user-accessibility",
          "status": "in-progress",
          "student_name": "Charles Nguyen",
          "student_profile": null,
          "tags": [
            "ml",
            "ai"
          ],
          "title": "Beam YAML, Kafka and Iceberg User Accessibility"
        },
        {
          "code_url": null,
          "description": "Apache Beam's test infrastructure is complex and difficult to manage manually. This project aims to improve resource management and security by introducing Infrastructure as Code (IaC) and automation tools.\n\nThe main objectives are:\n\n- GCP Resource Cleaner: Identify and safely delete unused or orphaned cloud resources.\n- Terraform Modules: Define and manage Beam's infrastructure in a declarative, reproducible way.\n- Key Management Utility: Securely create, rotate, and audit service account keys.\n- Monitoring Tools: Enforce security policies and trigger alerts based on GCP audit logs.",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2025_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/QRKMhW67",
          "proposal_id": "gDlovYdT",
          "short_description": "Apache Beam's test infrastructure is complex and difficult to manage manually. This project aims to improve resource management and security by...",
          "slug": "infrastructure-automation-and-cloud-resource-management-for-apache-beam",
          "status": "in-progress",
          "student_name": "Enrique Calderon",
          "student_profile": null,
          "tags": [
            "ai",
            "cloud"
          ],
          "title": "Infrastructure Automation and Cloud Resource Management for Apache Beam"
        },
        {
          "code_url": null,
          "description": "Apache StreamPipes is a platform that allows you to capture, modify and display IoT data streams. But currently, the part of displaying data is very limited. There are not many types of charts, and those that are implemented, have many missing options and features. The underlying  library ECharts can do more. This project aims to add these missing functions.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/muN9dJS6",
          "proposal_id": "6ztFEkSd",
          "short_description": "Apache StreamPipes is a platform that allows you to capture, modify and display IoT data streams. But currently, the part of displaying data is very...",
          "slug": "extend-visualization-capabilities-of-apache-streampipes",
          "status": "in-progress",
          "student_name": "Florian G",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Extend visualization capabilities of Apache StreamPipes"
        },
        {
          "code_url": null,
          "description": "The Airavata Cybershuttle Research Catalog is a web platform that enables researchers to share and run Jupyter Notebooks, GitHub repositories, datasets, and scientific models. It supports project creation by combining resources for collaborative, reproducible research, with direct cloud execution of notebooks and models.\n\nTo enhance flexibility and performance, a desktop application is being developed:\n\nWeb Research Catalog\n- Audience: General users\n- Pros: No installation required; easy access to shared resources\n- Cons: Limited by cloud compute resources\n\nLocal Research Catalog (Desktop App)\n- Audience: Power users needing high performance\n- Pros:\n    - Utilizes local machine resources (GPU, RAM) for better performance\n    - Offline access to notebooks, datasets, and models\n    - Integration with local tools and file systems\n    - Seamless synchronization with the web catalog when online\n    - Runs JupyterLab and VSCode sessions locally without needing Docker or external dependencies\n\nThe local agent is designed to be lightweight, extensible, and user-friendly, with built-in support for running scientific workflows entirely from a desktop environment.",
          "difficulty": "beginner",
          "id": "proj_the-apache-software-_2025_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/dBWuhuqs",
          "proposal_id": "ylxd4XzS",
          "short_description": "The Airavata Cybershuttle Research Catalog is a web platform that enables researchers to share and run Jupyter Notebooks, GitHub repositories,...",
          "slug": "airavata-research-catalog-local-agent",
          "status": "in-progress",
          "student_name": "Ganning Xu",
          "student_profile": null,
          "tags": [
            "web",
            "ml",
            "ai",
            "docker",
            "cloud"
          ],
          "title": "Airavata Research Catalog Local Agent"
        },
        {
          "code_url": null,
          "description": "Apache Seata's current service discovery relies on registries like Nacos and Zookeeper, which lack support for custom metadata. This limits the flexibility of client-side load balancing. \nThis project enhances Seata by adding metadata support to the registry module, enabling advanced load balancing strategies based on server-side attributes like weight and region. The result is improved resource utilization, enhanced scalability, and better overall system performance for Seata deployments .",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2025_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/jI0IGDJg",
          "proposal_id": "NLsLIfoz",
          "short_description": "Apache Seata's current service discovery relies on registries like Nacos and Zookeeper, which lack support for custom metadata. This limits the...",
          "slug": "unlocking-the-power-of-metadata-in-apache-seata-from-load-balancing-to-advanced-routing",
          "status": "in-progress",
          "student_name": "Guanlin Wu",
          "student_profile": null,
          "tags": [],
          "title": "Unlocking the Power of Metadata in Apache Seata From Load Balancing to Advanced Routing"
        },
        {
          "code_url": null,
          "description": "Problem:\nIn Apache RocketMQ 5.x POP orderly consumption, when a PushConsumer's ReceiveMessage response is lost due to network issues, the client generates a new attemptId for the next pull. However, the Broker blocks this new request because it still holds the original attemptId as active until its invisibleTime expires, causing consumption stalling.\n\nSolution:\n1. Enhance client-side logic (ProcessQueueImpl) to add an application-level timer for each ReceiveMessage request\n2. If timer expires without receiving response or definitive gRPC error:\n   • Client assumes response was lost\n   • Reuses original attemptId (instead of generating new one) for retry\n3. Leverages Broker's existing capability to handle reentrant requests with same attemptId\n\nDeliverables:\n• Modified Java client code (rocketmq-clients-java)\n• Comprehensive tests (unit & integration)\n• Updated documentation if needed\n• Pull Requests to relevant RocketMQ repos\n\nKey benefit: Prevents consumption stalls by ensuring retries use same attemptId when responses are lost.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_011",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/Nv98AHeF",
          "proposal_id": "KkmrNbGn",
          "short_description": "Problem: In Apache RocketMQ 5.x POP orderly consumption, when a PushConsumer's ReceiveMessage response is lost due to network issues, the client...",
          "slug": "optimizing-apache-rocketmqs-pop-orderly-consumption-process",
          "status": "in-progress",
          "student_name": "Kingcide",
          "student_profile": null,
          "tags": [
            "java"
          ],
          "title": "Optimizing Apache RocketMQ's POP Orderly Consumption Process"
        },
        {
          "code_url": null,
          "description": "This proposal aims to modernize Apache Airavata's administrative features by migrating the current Django-based portal to a React based single page application. This migration includes implementing features crucial to admin functionality, such as workspaces, groups, and settings.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_012",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/O22MG1px",
          "proposal_id": "hgpeh0sh",
          "short_description": "This proposal aims to modernize Apache Airavata's administrative features by migrating the current Django-based portal to a React based single page...",
          "slug": "airavata-django-to-react-migration-admin-functionality",
          "status": "in-progress",
          "student_name": "Krish Katariya",
          "student_profile": null,
          "tags": [
            "react",
            "ai"
          ],
          "title": "Airavata Django to React Migration: Admin Functionality"
        },
        {
          "code_url": null,
          "description": "The project Apache Mahout Refactoring the Website aims to modernize the site by deprecating old technologies and old blogs/posts, also the Qumat Section needs to be prioritised. The UI/UX improvements are needed which will be done through a structured format as detailed in the proposal. I have already contributed in Mahout and have a good level of understanding of the project.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_013",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/SvnaDehF",
          "proposal_id": "uu9W0QnD",
          "short_description": "The project Apache Mahout Refactoring the Website aims to modernize the site by deprecating old technologies and old blogs/posts, also the Qumat...",
          "slug": "apache-mahout-refactoring-the-website",
          "status": "in-progress",
          "student_name": "Krishna Dave",
          "student_profile": null,
          "tags": [
            "web",
            "ai",
            "ui",
            "ux"
          ],
          "title": "Apache Mahout Refactoring the Website"
        },
        {
          "code_url": null,
          "description": "Apache SkyWalking BanyanDB currently supports only local file systems through the remote.FS interface, which limits its flexibility in cloud-native environments. This project aims to extend remote.FS by implementing support for major object storage services including AWS S3, Google Cloud Storage, and Azure Blob Storage. Each backend will fully comply with the remote.FS interface to ensure seamless integration.\n\nThe implementation will include cloud-specific optimizations such as multipart uploads, resumable downloads, and SHA-256 checksum validation to ensure data integrity. Additionally, the system will handle rate limiting, transient errors, and support configurable retry strategies. The project will also include a unified error mapping layer and Prometheus-based monitoring metrics.\n\nDeliverables:\n\t•\tProduction-ready remote.FS implementations for AWS S3, GCS, and Azure Blob Storage.\n\t•\tUnit and integration tests using tools like GoMock and LocalStack.\n\t•\tLogging and observability features with structured logs and Prometheus metrics.\n\t•\tComplete documentation and setup guides.\n\t•\tCommunity demo and contribution-ready pull requests.\n\nThis enhancement will enable seamless and secure cloud deployments of BanyanDB, significantly reducing operational complexity while improving scalability and reliability.",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2025_014",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/MZsmKHO2",
          "proposal_id": "4CFPj7h8",
          "short_description": "Apache SkyWalking BanyanDB currently supports only local file systems through the remote.FS interface, which limits its flexibility in cloud-native...",
          "slug": "apache-skywalking-gsoc-2025-proposal-cloud-storage-integration-for-banyandb",
          "status": "in-progress",
          "student_name": "Lihan",
          "student_profile": null,
          "tags": [
            "ml",
            "ai",
            "cloud",
            "ui",
            "backend"
          ],
          "title": "Apache SkyWalking GSOC 2025 Proposal: Cloud Storage Integration for BanyanDB"
        },
        {
          "code_url": null,
          "description": "This proposal aims to implement HTTP/3 communication for Dubbo Triple in the Go language environment, enhancing the connection management capabilities of the Triple protocol in dubbo-go. The proposal will address the compatibility issues between Triple communication in dubbo-go and dubbo-java by implementing keep-alive functionality at the Triple protocol layer. Additionally, the proposal plans to organize and standardize the error codes of the Triple protocol and output necessary log information.\n\nBy developing a Triple HTTP/3 server and client, seamless and high-performance communication between Dubbo Java and Dubbo Go over the HTTP/3 protocol will be achieved. We will design a connection pool to effectively manage Triple connections and ensure the validity of connections through a PING-PONG mechanism between the server and client, thus realizing keep-alive functionality. Furthermore, the error codes of the Triple protocol will be standardized according to Dubbo Java's standards to facilitate developers in obtaining detailed log information during the debugging process.\n\nThe final deliverable of the proposal is to achieve high-performance, barrier-free communication between Dubbo Go and Dubbo Java through the Triple protocol, ensuring perfect compatibility and support for interaction via the HTTP/3 protocol. Users will be able to enjoy flexible keep-alive functionality and improve debugging efficiency through standardized error codes.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_015",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/iqigMBLJ",
          "proposal_id": "OlHvaxqb",
          "short_description": "This proposal aims to implement HTTP/3 communication for Dubbo Triple in the Go language environment, enhancing the connection management...",
          "slug": "dubbo-triple-protocol-for-go-language-implementation",
          "status": "in-progress",
          "student_name": "marsevilspirit",
          "student_profile": null,
          "tags": [
            "java",
            "ml",
            "ai"
          ],
          "title": "Dubbo triple protocol for go language implementation"
        },
        {
          "code_url": null,
          "description": "This project aims to add support for IEEE 802.3-2022 10BASE-T1x Ethernet in NuttX using MAC-PHY devices with the Open Alliance SPI interface. These low-cost Ethernet solutions are well-suited for embedded systems, aligning with NuttX’s target use cases.\n\nThe core deliverables include implementing a reusable driver infrastructure for Open Alliance 10BASE-T1x Serial Interface-compatible MAC-PHYs, with initial focus on the NCV7410 driver, supporting PLCA configuration, porting the driver to the ARM-based platform, and developing a test application. An optional goal is to include support for additional devices (e.g., ADIN1110) following the specification.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_016",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/bbWye78I",
          "proposal_id": "ENnHjBjF",
          "short_description": "This project aims to add support for IEEE 802.3-2022 10BASE-T1x Ethernet in NuttX using MAC-PHY devices with the Open Alliance SPI interface. These...",
          "slug": "nuttx-support-for-ieee-8023-2022-10base-t1x-ethernet-using-open-aliance-spi-mac-phys",
          "status": "in-progress",
          "student_name": "michal matias",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "NuttX Support for IEEE 802.3-2022 10BASE-T1x Ethernet using Open Aliance SPI MAC-PHYs"
        },
        {
          "code_url": null,
          "description": "The goal of this project is to enhance Apache Beam’s Python SDK by developing connectors for vector databases like Pinecone, Milvus and feature stores like Tecton. These integrations will improve support for ML use cases such as Retrieval-Augmented Generation (RAG) and feature engineering. By bridging Beam with these systems, this project will attract more users, particularly in the ML community.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_017",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/X32yGjqz",
          "proposal_id": "hkt6vrXx",
          "short_description": "The goal of this project is to enhance Apache Beam’s Python SDK by developing connectors for vector databases like Pinecone, Milvus and feature...",
          "slug": "beam-ml-vector-dbfeature-store-integrations-mohamed-awnallah-gsoc-proposal",
          "status": "in-progress",
          "student_name": "Mohamed Awnallah",
          "student_profile": null,
          "tags": [
            "python",
            "ml",
            "database"
          ],
          "title": "Beam ML Vector DB/Feature Store Integrations - Mohamed Awnallah GSoC Proposal"
        },
        {
          "code_url": null,
          "description": "Lucene.NET’s current replication system lacks seamless integration with ASP.NET Core and is not modular enough for use across diverse application types like Windows services or cloud-native tools. This proposal focuses on enhancing the `Lucene.Net.Replicator` by introducing full support for ASP.NET Core Dependency Injection (DI), simplifying configuration to a one-liner, and enabling real-time replication using technologies like WebSockets or gRPC. Additionally, it aims to modularize replication components to support non-web environments and build robust unit tests and real-world examples.\n\nDeliverables will include:\n- DI-based configuration system for easier integration in ASP.NET Core and beyond.\n- Real-time replication architecture replacing polling.\n- Support for Windows services, CLI tools, and distributed systems.\n- Comprehensive testing and documentation.\n\nThese changes will make Lucene.NET replication more developer-friendly, scalable, and production-ready.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_018",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/DWGSyADV",
          "proposal_id": "wlM5Hsy9",
          "short_description": "Lucene.NET’s current replication system lacks seamless integration with ASP.NET Core and is not modular enough for use across diverse application...",
          "slug": "replicator-and-dependency-injection-enhancements-for-lucenenet",
          "status": "in-progress",
          "student_name": "NehanKhan Pathan",
          "student_profile": null,
          "tags": [
            "web",
            "ml",
            "ai",
            "cloud",
            "ui"
          ],
          "title": "Replicator and Dependency Injection Enhancements for Lucene.NET"
        },
        {
          "code_url": null,
          "description": "In the current research ecosystem, datasets and trained machine learning models (e.g., LLMs, CNNs, etc.) are often scattered across various repositories and platforms, making discovery and reuse inefficient. This project proposes the design and development of a unified user interface system within Apache Airavata to consolidate and manage both datasets and models in one accessible platform. The contribution is aligned with the ticket: Come up with UX designs for Airavata data and model catalog. Through modern UI/UX design and seamless integration, this system will allow researchers and developers to find, preview, download, and reuse datasets and AI models effortlessly.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_019",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/t1hzdmFS",
          "proposal_id": "YTEJoXnB",
          "short_description": "In the current research ecosystem, datasets and trained machine learning models (e.g., LLMs, CNNs, etc.) are often scattered across various...",
          "slug": "airavata-designing-and-developing-the-model-and-data-catalog-interfaces-for-the-apache-airavata",
          "status": "in-progress",
          "student_name": "Nipuna Bandara",
          "student_profile": null,
          "tags": [
            "ml",
            "ai",
            "ui",
            "ux"
          ],
          "title": "[Airavata] - Designing and Developing the Model and Data Catalog Interfaces for the Apache Airavata"
        },
        {
          "code_url": null,
          "description": "This project aims to enhance connection pool management in Apache Seata’s AT/XA transaction modes by introducing a unified, user-friendly monitoring and configuration system.\n\nCurrently, Seata lacks a visual and configurable interface for observing and managing internal connection pools, which are essential for maintaining performance and stability in distributed transaction processing. This project addresses that gap by developing a new console dashboard that displays real-time connection pool metrics (such as active, idle, and total connections) and provides controls for adjusting parameters like minimum/maximum connections, timeouts, and keep-alive durations.\n\nThe solution will include front-end Vue components, back-end Spring Boot APIs, and a service layer to handle the core business logic. It will also include thorough unit and integration testing to ensure reliability and correctness.\n\nDeliverables include:\n1. A real-time dashboard for connection pool monitoring\n2. A dynamic console interface for configuration management\n3. Backend REST APIs and business logic for pool metrics and settings\n4. User and developer documentation\n5. Comprehensive unit and integration tests",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_020",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/EPXz1kVe",
          "proposal_id": "QbFiDXtf",
          "short_description": "This project aims to enhance connection pool management in Apache Seata’s AT/XA transaction modes by introducing a unified, user-friendly monitoring...",
          "slug": "enhancing-connection-pool-management-and-visualization-for-apache-seatas-atxa-transaction-modes",
          "status": "in-progress",
          "student_name": "Oscar Cheng",
          "student_profile": null,
          "tags": [
            "vue",
            "api",
            "ai",
            "backend"
          ],
          "title": "Enhancing Connection Pool Management and Visualization for Apache Seata’s AT/XA Transaction Modes"
        },
        {
          "code_url": null,
          "description": "This proposal outlines the development of an AI Agent for Apache HertzBeat using the Model Context Protocol (MCP), enabling natural language interaction with monitoring capabilities. The project will implement an MCP-compliant server and client architecture integrated with SpringAI, along with a chat-based frontend for the HertzBeat dashboard. This enhancement will make HertzBeat's monitoring features more accessible while serving as a reference implementation for AI integration in monitoring tools.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_021",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/MZlJ0wnB",
          "proposal_id": "1nKfLzUk",
          "short_description": "This proposal outlines the development of an AI Agent for Apache HertzBeat using the Model Context Protocol (MCP), enabling natural language...",
          "slug": "gsoc-proposal-ai-agent-for-apache-hertzbeat-with-mcp",
          "status": "in-progress",
          "student_name": "sarthakeash",
          "student_profile": null,
          "tags": [
            "ai",
            "frontend"
          ],
          "title": "GSoC Proposal: AI Agent for Apache HertzBeat with MCP"
        },
        {
          "code_url": null,
          "description": "Dubbo Proxyless mode refers to Dubbo directly communicating with the control plane and achieving capabilities such as Service Discovery and Service Governance through the xDS protocol.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_022",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/qlaBuhvs",
          "proposal_id": "PMdSAaxS",
          "short_description": "Dubbo Proxyless mode refers to Dubbo directly communicating with the control plane and achieving capabilities such as Service Discovery and Service...",
          "slug": "add-more-traffic-management-rule-support-for-dubbo-proxyless-mesh",
          "status": "in-progress",
          "student_name": "Shihao Hu",
          "student_profile": null,
          "tags": [],
          "title": "Add more traffic management rule support for Dubbo Proxyless Mesh"
        },
        {
          "code_url": null,
          "description": "The primary goal of this project is to develop a practical firmware updater for NuttX that leverages the NXBoot bootloader. The updater will transfer firmware over the Silicon Heaven (SHV) protocol, a remote procedure call system.\n\nAnother key objective is to implement SHV support for memory-constrained devices and adapt it for integration into NuttX, making it available for any application that utilizes SHV for remote procedure calls.\n\nThe firmware updater will also be integrated into the pysimCoder project—a rapid control prototyping suite capable of generating NuttX-compatible code for control applications. This integration will simplify the development workflow and make rapid control prototyping more convenient.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_023",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/whPaBXY8",
          "proposal_id": "pxVdkupp",
          "short_description": "The primary goal of this project is to develop a practical firmware updater for NuttX that leverages the NXBoot bootloader. The updater will transfer...",
          "slug": "firmware-upgrades-over-silicon-heaven-protocol-for-nxboot-demonstrated-on-pysimcoder",
          "status": "in-progress",
          "student_name": "Štěpán Pressl",
          "student_profile": null,
          "tags": [
            "api",
            "ai",
            "ui"
          ],
          "title": "Firmware Upgrades over Silicon-Heaven Protocol for NXboot Demonstrated on pysimCoder"
        },
        {
          "code_url": null,
          "description": "In scientific computing environments like Apache Airavata, users routinely configure and execute complex computational experiments involving multiple parameters, workflows, and external resources. Over time, a large corpus of these experiments accumulates — each capturing valuable insights, design patterns, and implicit best practices. Once identified, these templates can be used to generate new suggested experiments—both within and beyond previously explored areas. This facilitates exploration and accelerates the scientific experimentation process.",
          "difficulty": "advanced",
          "id": "proj_the-apache-software-_2025_024",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/haSb0RSS",
          "proposal_id": "HCNq9qWy",
          "short_description": "In scientific computing environments like Apache Airavata, users routinely configure and execute complex computational experiments involving multiple...",
          "slug": "identification-and-generation-of-computational-experiments-in-airavata",
          "status": "in-progress",
          "student_name": "svaibhav",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Identification and Generation of Computational Experiments in AIRAVATA"
        },
        {
          "code_url": null,
          "description": "Apache DolphinScheduler currently offers only bespoke OIDC support (e.g., Casdoor), which hampers its adoption in enterprises that rely on a variety of identity providers like Keycloak, Okta, or Azure AD. This project will introduce a new, pluggable OIDC authentication module—built atop the existing Nimbusds OAuth2 library—to enable configuration-driven integration with any standards-compliant OIDC IdP. On the backend, Java and Spring Security will be extended to load provider configurations, handle the Authorization Code Flow, and map or provision users against the existing schema without database changes. On the Vue.js frontend, the login page will dynamically render buttons for each configured IdP and initiate the appropriate login flow. Deliverables include the backend and frontend code, new configuration properties, JUnit/Mockito unit tests, full end-to-end login and provisioning tests, and comprehensive documentation detailing setup and usage.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_025",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/RoNSW60Q",
          "proposal_id": "ICXVC2Dg",
          "short_description": "Apache DolphinScheduler currently offers only bespoke OIDC support (e.g., Casdoor), which hampers its adoption in enterprises that rely on a variety...",
          "slug": "enhancing-apache-dolphinscheduler-with-generalized-oidc-authentication",
          "status": "in-progress",
          "student_name": "tusaryan",
          "student_profile": null,
          "tags": [
            "vue",
            "java",
            "ai",
            "database",
            "ui"
          ],
          "title": "Enhancing Apache DolphinScheduler with Generalized OIDC Authentication"
        },
        {
          "code_url": null,
          "description": "My project for GSoC 2025 focuses on improving the deployment process of Apache Airavata by containerizing its core services using Docker. Currently, Airavata services are packaged as Java bundles, which makes deployment complex, inconsistent across environments, and difficult to manage. My goal is to create Dockerfiles for each service and set up a complete Docker Compose environment for easy local development and testing. I will also integrate CI/CD pipelines using GitHub Actions or Jenkins to automate the build and deployment processes. This will not only simplify dependency management and make deployments more reliable but also improve the overall development experience for contributors. Throughout the project, I’ll optimize the Docker images for production use, support different configurations for development and production, and provide full documentation along with a final demo. With my background in DevOps, containerization, and open-source contributions including work on MetaCall, OpenMRS, Apache Hadoop, and Airavata itself I’m confident in my ability to deliver a high-quality solution that will benefit the Apache community.",
          "difficulty": "beginner",
          "id": "proj_the-apache-software-_2025_026",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/XV40d7XV",
          "proposal_id": "0LBSfBC2",
          "short_description": "My project for GSoC 2025 focuses on improving the deployment process of Apache Airavata by containerizing its core services using Docker. Currently,...",
          "slug": "containerized-deployment-of-airavata-services",
          "status": "in-progress",
          "student_name": "Yasindu Dissanayake",
          "student_profile": null,
          "tags": [
            "java",
            "ai",
            "docker",
            "ui"
          ],
          "title": "Containerized Deployment of Airavata Services"
        },
        {
          "code_url": null,
          "description": "Problem:\nThe current RocketMQ Dashboard suffers from outdated UI design, slow API responses, security vulnerabilities (e.g., plaintext passwords), and incomplete documentation. These issues hinder usability, performance, and adoption.\nSolution:\nI propose a comprehensive refactor to modernize the dashboard by:\nFrontend:  Replacing AngularJS/Bootstrap with modular components (e.g., ECharts for dynamic charts) and fixing misaligned UI elements.\nBackend:  Optimizing APIs via caching and async processing to reduce latency (e.g., topic queries from 30s to <1s).\nSecurity: Implementing Spring Security with BCrypt encryption, RBAC, and audit logs.\nInfrastructure: Updating Docker images and improving documentation with quick-start guides.\n\nDeliverables:\nModernized UI with responsive design and interactive charts.\nOptimized APIs with reduced response times.\nSecure authentication (RBAC + audit logging).\nUpdated Docker deployment and comprehensive documentation.",
          "difficulty": null,
          "id": "proj_the-apache-software-_2025_027",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/programs/2025/projects/gkHyVAIG",
          "proposal_id": "nPWTPVdi",
          "short_description": "Problem: The current RocketMQ Dashboard suffers from outdated UI design, slow API responses, security vulnerabilities (e.g., plaintext passwords),...",
          "slug": "modernizing-rocketmq-dashboard-ui-refactor-performance-optimization-security-enhancements",
          "status": "in-progress",
          "student_name": "许億驰",
          "student_profile": null,
          "tags": [
            "angular",
            "api",
            "ai",
            "docker",
            "ui"
          ],
          "title": "Modernizing RocketMQ Dashboard: UI Refactor, Performance Optimization & Security Enhancements"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/programs/2025/organizations/apache-software-foundation"
    }
  },
  "first_time": false,
  "contact": {
    "email": "mentors@community.apache.org",
    "guide_url": "https://community.apache.org/gsoc/",
    "ideas_url": "https://s.apache.org/gsoc2025ideas",
    "irc_channel": "https://wiki.apache.org/general/IRC",
    "mailing_list": "http://apache.org/foundation/mailinglists.html"
  },
  "social": {
    "blog": "https://blogs.apache.org/",
    "discord": null,
    "facebook": null,
    "github": null,
    "gitlab": null,
    "instagram": null,
    "linkedin": null,
    "mastodon": null,
    "medium": null,
    "reddit": null,
    "slack": null,
    "stackoverflow": null,
    "twitch": null,
    "twitter": "https://twitter.com/theasf",
    "youtube": null
  },
  "meta": {
    "version": 1,
    "generated_at": "2026-01-25T15:28:54.336Z"
  }
}