{
  "id": "692251e553dd9d7326d33e9b",
  "slug": "robocomp",
  "name": "RoboComp",
  "category": "Other",
  "description": "Open-source framework to develop robot components",
  "image_url": "https://summerofcode.withgoogle.com/media/org/robocomp/okal4wecq8dywr78-360.png",
  "img_r2_url": "https://pub-268c3a1efc8b4f8a99115507a760ca14.r2.dev/robocomp.webp",
  "logo_r2_url": null,
  "url": "https://robocomp.github.io/web/",
  "active_years": [
    2016,
    2017,
    2018,
    2019,
    2020,
    2021,
    2022
  ],
  "first_year": 2016,
  "last_year": 2022,
  "is_currently_active": false,
  "technologies": [
    "python",
    "c++",
    "cmake",
    "zeroc ice",
    "gnu/linux",
    "qt",
    "openscenegraph",
    "c",
    "ice - zeroc",
    "opencv",
    "c++11",
    "component-based development",
    "qt5",
    "c++17",
    "pytorch"
  ],
  "topics": [
    "robotics",
    "computer vision",
    "framework",
    "robotics simulation",
    "simulation",
    "multi-agent system",
    "component-based development",
    "Multi-agent Systems"
  ],
  "total_projects": 57,
  "stats": {
    "avg_projects_per_appeared_year": 8.14,
    "projects_by_year": {
      "year_2016": 5,
      "year_2017": 9,
      "year_2018": 8,
      "year_2019": 10,
      "year_2020": 10,
      "year_2021": 10,
      "year_2022": 5,
      "year_2023": null,
      "year_2024": null,
      "year_2025": null
    },
    "students_by_year": {
      "year_2016": 5,
      "year_2017": 9,
      "year_2018": 8,
      "year_2019": 10,
      "year_2020": 10,
      "year_2021": 10,
      "year_2022": 5,
      "year_2023": null,
      "year_2024": null,
      "year_2025": null
    },
    "total_students": 55
  },
  "years": {
    "year_2016": {
      "num_projects": 5,
      "projects": [
        {
          "code_url": "https://gist.github.com/BasilMVarghese/b66c11871bcee5cb769e4644cbcec7e2",
          "description": "<p>Two main reason for this to be an important idea.\n                (1) Sometimes we will have to work with component networks which contains hundreds  of      components.The current manager is not enough for managing   such a huge network system which in effect  dwarf the usefulness of the framework .\n                  (2)The possible users of the framework include people who are working  in electrical and mechanical domains of robotics also, People who  mostly use the inbuilt  components.For them it will be good to have all the functionalities under one roof.So it is necessary to have a tool which helps to launch, control and edit the components.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2016_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6372975016148992/",
          "proposal_id": null,
          "short_description": "Two main reason for this to be an important idea.\n                (1) Sometimes we will have to work with component networks which contains hundreds ...",
          "slug": "a-new-graphical-tool-for-deploying-components",
          "status": "completed",
          "student_name": "Basil",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "A new graphical tool for deploying components"
        },
        {
          "code_url": "https://github.com/Daniel1108/website/blob/gh-pages/_posts/gsoc2016/dgallegos/2016-08-20-dgallegosWeek11.md",
          "description": "<p>The project is about implementing a Qt5 and ROS support in RoboComp’s DSL</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2016_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6617925590974464/",
          "proposal_id": null,
          "short_description": "The project is about implementing a Qt5 and ROS support in RoboComp’s DSL",
          "slug": "qt5-and-ros-support",
          "status": "completed",
          "student_name": "dgallegos",
          "student_profile": null,
          "tags": [],
          "title": "Qt5 and ROS support"
        },
        {
          "code_url": "https://docs.google.com/document/d/1uJq8H5lG77iEgcvyJn-cyJoBo_Zf346DBmdx6OXVH3Q",
          "description": "<p>Object detection and recognition are central problems in computer vision literature and essential for a vision based library. Recent advances in Covolutional Neural Networks (CNN)s have made the detection have made the recognition problem tractable for large number of object categories that would have been very expensive with model based classification approaches. In this project I will implement state-of-art object recognition as well as object detection/localization technique for RoboComp library. The implementation will support both real images and rendered images from CAD model. The implementation will be based on CUDA library and allow user to train and test his models. Also, a caffe independent pure RoboComp based implementation for forward pass will be developed for a selected CNN. Another component based on open scene graph will designed that would allow reading of CAD models and interfacing with current RoboComp simulation framework. Selection of rich textured CAD models is an crucial for any detection algorithm. Therefore,  the proposed project will accompany a dataset of cleaned and textured CAD models for 5 object categories.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2016_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/4543387667529728/",
          "proposal_id": null,
          "short_description": "Object detection and recognition are central problems in computer vision literature and essential for a vision based library. Recent advances in...",
          "slug": "robocomp-object-detection-for-simulated-environments",
          "status": "completed",
          "student_name": "Harit",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "RoboComp: Object detection for simulated environments"
        },
        {
          "code_url": "http://robocomp.github.io/website/2016/08/20/yashWeek16",
          "description": "<p>This Project deals with writing a new component in RoboComp that will provide a naming and port service. When starting, components will now contact this new service to advertise its name, available interfaces and request a valid port. Other components starting later will be able to query the service for component names and interfaces, and therefore being able to establish their proxy connections in real time, eliminating the need for complex and tedious configuration files. Extensive tests with large networks of components will be performed and more advanced query capabilities for the service will be explored.</p>\n",
          "difficulty": "advanced",
          "id": "proj_robocomp_2016_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/4600633139134464/",
          "proposal_id": null,
          "short_description": "This Project deals with writing a new component in RoboComp that will provide a naming and port service. When starting, components will now contact...",
          "slug": "writing-a-name-and-port-service-for-running-components",
          "status": "completed",
          "student_name": "Yash Sanap",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Writing a name and port service for running components"
        },
        {
          "code_url": "https://ibarbech.github.io/AcGfSM_GSoC16/",
          "description": "<p>When you run robocompdsl in addition to create the file example .cdsl, will create an example file where state machine will be defined. When you run again robocompdsl with the path of construction this will create the state machine in generic files.</p>\n<p>To achieve the automatic generation of state machines, robocompdsl will read a file in which the state machine is defined. So the generic files are modified, creating in them the state machines, which can be accessed from specific files.</p>\n<p>· To achieve this in C++, I will use the Qt State Machine Framework class.</p>\n<p>I must also create the state machine in Python, this is a language booming. To do this, I have to look for information on how to create the state machine in Python</p>\n<p>· Also, a file that define the state machine (valid for C ++ and Python).</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2016_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2016/projects/6085194759012352/",
          "proposal_id": null,
          "short_description": "When you run robocompdsl in addition to create the file example .cdsl, will create an example file where state machine will be defined. When you run...",
          "slug": "automatic-code-generation-for-state-machines",
          "status": "completed",
          "student_name": "ibarbech",
          "student_profile": null,
          "tags": [
            "python",
            "ai"
          ],
          "title": "Automatic code generation for State Machines"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2016/organizations/6723762711953408/"
    },
    "year_2017": {
      "num_projects": 9,
      "projects": [
        {
          "code_url": "https://gist.github.com/Kmayankkr/61e52a764da1ec1dd96dd5ff366eb67e",
          "description": "<p>The highlyUnstable branch of robocomp has an advanced rcmanager, which aids for creation of the xml files in a simple and illustrative way, through a GUI. However, there are a few problems associated with it, like cluttering of large components graphs, unavailability of GUI for editing components, no support for graph panning, no support for component debugging, as well as insufficient documentation of the new tools. I intend to solve these problems through my GSoC project, whose elaborately described solutions can be found in my proposal.</p>\n",
          "difficulty": "advanced",
          "id": "proj_robocomp_2017_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5404869523406848/",
          "proposal_id": null,
          "short_description": "The highlyUnstable branch of robocomp has an advanced rcmanager, which aids for creation of the xml files in a simple and illustrative way, through a...",
          "slug": "graphic-deployment-tool",
          "status": "completed",
          "student_name": "Mayank_Kumar",
          "student_profile": null,
          "tags": [
            "ml",
            "ai",
            "ui"
          ],
          "title": "Graphic Deployment Tool"
        },
        {
          "code_url": "https://docs.google.com/presentation/d/1AN1_6moCLcTjmeyPX2aGd1fl6cLJwDTbMb8LpaXGcWE/edit?usp=sharing",
          "description": "<p>Project aims at designing a custom language for getting rid of the burden of textual programming and to provide abstraction and hide the underlying processes from the user and compress huge chunks of code into powerful <em>purpose-specific</em> commands. This set of commands is realized as <strong>Domain Specific Language</strong> and this language will eventually be translated to its <strong>Python</strong> equivalent for processing. The approach is <em>event-based</em> as well as <em>state-based</em>.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2017_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5233140759003136/",
          "proposal_id": null,
          "short_description": "Project aims at designing a custom language for getting rid of the burden of textual programming and to provide abstraction and hide the underlying...",
          "slug": "domain-specific-language-for-programming-the-learnbot-educational-robot",
          "status": "completed",
          "student_name": "Aniq Ur Rahman",
          "student_profile": null,
          "tags": [
            "python",
            "ai",
            "ui"
          ],
          "title": "Domain Specific Language for programming the Learnbot educational robot"
        },
        {
          "code_url": "https://ibarbech.github.io/IDE-for-programming-the-Learnbot/",
          "description": "<p>The Learnbot is a small robot which is used to teach to the children the world of robotics. This robot is designed to run simple programs. These programs are created by children, thus the code of these programs should be simple. So, I am interested in desing a Domain Specific Language (DSL) and a parser to this DSL that will translate the program in Learnbot DSL in python code.\nAlso, I  want make a GUI to add more funtions to Learnbot DSL.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2017_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5324479815221248/",
          "proposal_id": null,
          "short_description": "The Learnbot is a small robot which is used to teach to the children the world of robotics. This robot is designed to run simple programs. These...",
          "slug": "domain-specific-language-for-programming-the-learnbot-educational-robot",
          "status": "completed",
          "student_name": "Iván",
          "student_profile": null,
          "tags": [
            "python",
            "ai",
            "ui"
          ],
          "title": "Domain Specific Language for programming the Learnbot educational robot"
        },
        {
          "code_url": "https://aracelivegamagro.github.io/SocialNavigation_GSOC17/",
          "description": "<p>The project idea I would like to contribute to robocomp platform as a part of Google Summer of Code is a new component - or set of new RoboComp components - that allows robots to navigate in an environment with human(s) with social skills.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2017_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5351511802511360/",
          "proposal_id": null,
          "short_description": "The project idea I would like to contribute to robocomp platform as a part of Google Summer of Code is a new component - or set of new RoboComp...",
          "slug": "social-navigation-with-robocomp",
          "status": "completed",
          "student_name": "Araceli Vega Magro",
          "student_profile": null,
          "tags": [],
          "title": "Social navigation with Robocomp​"
        },
        {
          "code_url": "https://docs.google.com/document/d/1nCri4oe_ykMFzO3OaG7fQmZYHATM3ONYRBlgH92V-YM",
          "description": "<p>RoboComp is an open-source Robotics framework providing the tools to create and modify software components that communicate through public interfaces. It is based on DSL technology. In this proposal we seek to improve the robustness of the generated code using model checking techniques and good software engineering practices. The student will have to extend the current code generation tool, robocompdsl, to include verification points, asserts, parameter range control, etc independent of the specific functionality of the component. We expect that with this improvement the new generated components will be less prone to accidental crashes and easier to debug and maintain.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2017_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5577900602425344/",
          "proposal_id": null,
          "short_description": "RoboComp is an open-source Robotics framework providing the tools to create and modify software components that communicate through public...",
          "slug": "introducing-robust-code-generation-techniques-in-robocomp",
          "status": "completed",
          "student_name": "Nikhil Abraham",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Introducing robust code generation techniques in Robocomp"
        },
        {
          "code_url": "https://gist.github.com/jainlashit/e017f7fa1bf1a319c82bd92ca640ec96",
          "description": "<p>Automated Planning involves taking actions to reach the goal. The problem is that most of the practical situations have lots of actions involved, and given a situation, some of these actions might be unnecessary for computing the plan. \nTherefore planning agents take a lot of time for computing plans because they might be considering redundant actions while planning.</p>\n<p>The first part of this project is to use Machine Learning algorithms to learn which actions can be useful for computing the plan. Therefore the idea is to train our learning algorithms on many such instances, and given a planning problem, output a probability distribution over all the actions (which indicates the relevance of each action).</p>\n<p>We'll be applying following learning algorithms for getting the probability distribution over actions:</p>\n<ol>\n<li>Bayes Classifier</li>\n<li>Artificial Neural Networks</li>\n</ol>\n<p>The second part of the project is to improve AGGLEditor. For this part, we’ll resolve bugs that are present in the current version of the editor. Documentation and tutorials for AGGLEditor will also be added.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2017_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/6257780235173888/",
          "proposal_id": null,
          "short_description": "Automated Planning involves taking actions to reach the goal. The problem is that most of the practical situations have lots of actions involved, and...",
          "slug": "learning-useful-actions-for-efficient-planning",
          "status": "completed",
          "student_name": "Lashit Jain",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Learning useful Actions for efficient planning"
        },
        {
          "code_url": "https://yohanmr.github.io/",
          "description": "<p>The aim of this project is to integrate social behaviors into the RoboComp navigation agent. Mobile robots that encounter people on a regular basis must react to them in some way or the other. Traditional robot control algorithms for path planning and obstacle avoidance treat all sensor readings identically, as foreign objects that must be avoided. However, for a mobile robot that operates around people, these traditional algorithms may not follow the social norms. Even simple conventions like move to the right when a person is encountered might not be honored by these algorithms. However, people would want to, or rather tend to perceive robots-particularly assistive robots, as human like. So catering to this need social behavior will be implemented via certain cost functions.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2017_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/4821890795307008/",
          "proposal_id": null,
          "short_description": "The aim of this project is to integrate social behaviors into the RoboComp navigation agent. Mobile robots that encounter people on a regular basis...",
          "slug": "social-navigation-with-robocomp",
          "status": "completed",
          "student_name": "Yohan M R",
          "student_profile": null,
          "tags": [
            "react",
            "mobile",
            "ai"
          ],
          "title": "Social Navigation with RoboComp"
        },
        {
          "code_url": "https://github.com/brickbit/web/blob/master/gsoc/2017/brickbit/My%20progress.md",
          "description": "<p>One proposal to redesign Learnbot to solve current problems and make the robot more attractive and expressive</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2017_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/4841577180561408/",
          "proposal_id": null,
          "short_description": "One proposal to redesign Learnbot to solve current problems and make the robot more attractive and expressive",
          "slug": "redesign-of-learnbot-to-improve-its-features-and-functionalities",
          "status": "completed",
          "student_name": "brickbit",
          "student_profile": null,
          "tags": [],
          "title": "Redesign of Learnbot to improve its features and functionalities"
        },
        {
          "code_url": "https://gist.github.com/lovemehta/ca0799f36ad3a2436307f98773ddc404",
          "description": "<p>This project aims to extend the current  DSL based component code generator to also generate RoboComp components that  can be run in the browser. The new components generated will be using javascript and as an html file should be able to be deployed in the browser and also to communicate with the non JS components already developed earlier (laser, keyboardcontroller, joystick etc.).  It is an interesting diversion from current robotics technologies based on C++/ python to use JavaScript to code some highly concurrent components.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2017_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2017/projects/5971490868559872/",
          "proposal_id": null,
          "short_description": "This project aims to extend the current  DSL based component code generator to also generate RoboComp components that  can be run in the browser. The...",
          "slug": "javascript-support",
          "status": "completed",
          "student_name": "Love Mehta",
          "student_profile": null,
          "tags": [
            "python",
            "java",
            "javascript",
            "ml",
            "ai"
          ],
          "title": "Javascript Support"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2017/organizations/5477575937753088/"
    },
    "year_2018": {
      "num_projects": 8,
      "projects": [
        {
          "code_url": "https://github.com/psy2d/gsoc-2018-report/blob/master/report.md",
          "description": "<p>Learnbot is a small low-cost robot designed to develop computational thinking in kids of age 10 and above. Presently, Learnbot can be programmed to show emotions via a display. However, it does not have the ability to recognize human emotions. Having this ability would help improve the Human-Robot Interaction(HRI) functions in Learnbot.</p>\n<p>This project aims at applying state-of-the-art techniques to create a fast, accurate and robust emotion recognizer. It would be able to recognize 5 basic emotions: Happiness, Sadness, Anger, Surprise, Neutral, based on facial expressions. This involves training a Convolutional Neural Network based classifier.</p>\n<p>The ability to recognize emotions would be added as a new component in Learnbot. Other components would be able to access the data generated by this component through an interface.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2018_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5676453324652544/",
          "proposal_id": null,
          "short_description": "Learnbot is a small low-cost robot designed to develop computational thinking in kids of age 10 and above. Presently, Learnbot can be programmed to...",
          "slug": "emotion-recognition-component-for-learnbot",
          "status": "completed",
          "student_name": "Sayali Deshpande",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Emotion Recognition Component for Learnbot"
        },
        {
          "code_url": "https://aracelivegamagro.github.io/HumanCenteredRobotNavigation_GSOC18/",
          "description": "<p>My proposal consists on transform the fixed personal space used actually in Robocomp into an adaptive space, depending of the spatial context (there is difference, for instance, between a narrow corridor and a room).  The main idea is to change the values that defines the personal space function in order to adapt the personal space to allow the robot to navigate around the person without problems, adapting it to the spatial context.  Besides, I would like to extend the social navigation agent, including other typical social behaviors: crossing people in corridors, approaching to humans in human-robot interaction, etc. In this respect, it would be interesting to study how these algorithms are also integrated into the planner and mission agents, and how define the priority between these missions by defining a social behavior planner.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2018_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5692367319334912/",
          "proposal_id": null,
          "short_description": "My proposal consists on transform the fixed personal space used actually in Robocomp into an adaptive space, depending of the spatial context (there...",
          "slug": "improving-the-human-centered-robot-navigation-agent",
          "status": "completed",
          "student_name": "Araceli Vega Magro",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Improving the Human-centered Robot Navigation Agent"
        },
        {
          "code_url": "https://github.com/ljmanso/objectDetection2",
          "description": "<p>I think about how to improve the RoboComp system by adding visual detection mechanisms to the mobile robots. This provides to the robot all the information needed to predict its short-term environment and react better than a robot without this technology (it could look less human, it couldn't know about its probable near future so it couldn't react to it). That is to say, if a person passes in front of the robot, probably, it can't know it to react and border the person, because it is an unpredictable event. But, with this technology, if a human crosses ahead, the robot detects a change in its environment and it can change its path to not collide with the human. I have used RoboComp before and I know that it is a good software that can be greatly improve with this system.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2018_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5755683257450496/",
          "proposal_id": null,
          "short_description": "I think about how to improve the RoboComp system by adding visual detection mechanisms to the mobile robots. This provides to the robot all the...",
          "slug": "visual-detection-mechanisms-in-mobile-robots",
          "status": "completed",
          "student_name": "CristinaMG",
          "student_profile": null,
          "tags": [
            "react",
            "mobile"
          ],
          "title": "Visual Detection Mechanisms in Mobile Robots."
        },
        {
          "code_url": "https://gist.github.com/ksakash/ea6c21487df14409a860787ff7a7f66d",
          "description": "<p>Simulation plays an important role in robotics. Through simulation we can save valuable time and resources to test our algorithms. Often robotics require expensive sensors and hardware which is not accessible to everyone.</p>\n<p>Currently RoboComp uses RoboComp Innermodel Simulator (RCIS), an inbuilt simulator, to check its applications and algorithms. It provides a lot of basic tools and features to easily test and verify an application developed by a developer. But it has some shortcomings.</p>\n<p>To my understanding, the aim of this project is to provide a platform for the developers to quickly check the changes and validity of the application developed by them. To integrate the RoboComp framework and Gazebo simulator in such a way that it inherits the structure of RoboComp interface, uses the features provided by Gazebo to its fullest and is able to fulfill the needs of developer in the most efficient way.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2018_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5069507739516928/",
          "proposal_id": null,
          "short_description": "Simulation plays an important role in robotics. Through simulation we can save valuable time and resources to test our algorithms. Often robotics...",
          "slug": "gazebo-robocomp-integration",
          "status": "completed",
          "student_name": "Akash Kumar Singh",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Gazebo-RoboComp Integration"
        },
        {
          "code_url": "https://github.com/Joanes04/Robocomp-ZeroC-JS",
          "description": "<p>My proposal is based on getting full support for JavaScript within the RoboComp framework. For this, the current state of generation of written components in the JavaScript language must be improved. Last year during the 2017 GSoC the functionality of the RoboComp component generator was extended to provide component supports based on NodeJS. A first approximation was achieved but still lacks robustness, reliability and should be extended to include more features.\nIn addition, recently Zeroc ICE has added support for JavaScript interfaces, therefore the component generator must be extended to support this feature, both as a server and as a client. The component model of RoboComp must be able to generate components in this language with the same functionality as its counterparts in C ++ and Python, thus achieving complete support for JavaScript within RoboComp.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2018_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5248878257373184/",
          "proposal_id": null,
          "short_description": "My proposal is based on getting full support for JavaScript within the RoboComp framework. For this, the current state of generation of written...",
          "slug": "javascript-support",
          "status": "completed",
          "student_name": "José Alberto Andújar",
          "student_profile": null,
          "tags": [
            "python",
            "java",
            "javascript"
          ],
          "title": "JavaScript support"
        },
        {
          "code_url": "https://github.com/coolprinshu123/Collaborative-Robotics/blob/master/index.md",
          "description": "<p>LearnBlock is the programing tool designed for easy usage of the Learnbot robot. It is meant to be used by students and to help them learn new concepts by the usage of robotics programming. This idea involves the extension of the Learnblock programming tool to manage collaborative robotics between learnbots. I will develop a system that enables Learnbot to communicate between and offer this option through the learnblock tool to the end user. Finally a use case example of these collaborative robotics tool will be developed and tutorials produced for future users and developers of the platform.</p>\n",
          "difficulty": "beginner",
          "id": "proj_robocomp_2018_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/4685928303951872/",
          "proposal_id": null,
          "short_description": "LearnBlock is the programing tool designed for easy usage of the Learnbot robot. It is meant to be used by students and to help them learn new...",
          "slug": "learnblock-learnbot-programming-language-extension-for-collaborative-robotics",
          "status": "completed",
          "student_name": "Prinshu Kumar",
          "student_profile": null,
          "tags": [],
          "title": "Learnblock (Learnbot programming language) extension for collaborative robotics"
        },
        {
          "code_url": "https://gist.github.com/sparsh789/1f2cca0c3d069912fd78e0693ee78137",
          "description": "<p>The existing RCIS simulator is not very efficient when our robot get more complex so we need more advanced functions in RCIS. This project is to improve the current RCIS with new functions dealing with contact physics. Currently RCIS has only collision detection feature. We have to add more functionalities like what happen after collision with the help of collision angle, gravity and contact physics.</p>\n",
          "difficulty": "advanced",
          "id": "proj_robocomp_2018_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5960282882965504/",
          "proposal_id": null,
          "short_description": "The existing RCIS simulator is not very efficient when our robot get more complex so we need more advanced functions in RCIS. This project is to...",
          "slug": "rcis-improving-robocomp-simulator-with-contact-physics",
          "status": "completed",
          "student_name": "Sparsh",
          "student_profile": null,
          "tags": [],
          "title": "RCIS: improving RoboComp simulator with contact physics"
        },
        {
          "code_url": "https://gist.github.com/mariabohorquez/1810d41aeb00d370d68ff74a50cb5563",
          "description": "<p>Robocomp current tutorials are simple and cover just the basics. Improved tutorials and use cases need to be created for Robocomp to be a framework friendly for beginners as well as more advanced users.</p>\n<p>Working on creating examples of how Robocomp can be implemented, and why it should be used, would make it more accessible to the general public. As will improving the \"How to Contribute Page\", and making pull requests templates would make it easier to collaborate for more advance developers.</p>\n<p>Getting Robocomp available in other operating systems it's necessary to making it more well-known, in other Linux distros as well as Windows. This can be done with virtual machines images or making tutorials to download it with their respective dependencies on each OS.</p>\n<p>In summary, Robocomp would be benefited from offering a better user experience and a more seamlessly transition for collaborators to work on it.</p>\n",
          "difficulty": "beginner",
          "id": "proj_robocomp_2018_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2018/projects/5195628246204416/",
          "proposal_id": null,
          "short_description": "Robocomp current tutorials are simple and cover just the basics. Improved tutorials and use cases need to be created for Robocomp to be a framework...",
          "slug": "generation-of-new-use-cases-tutorials-and-reference-information-for-robocomp",
          "status": "completed",
          "student_name": "Maria Bohórquez",
          "student_profile": null,
          "tags": [
            "ml",
            "ai",
            "ux"
          ],
          "title": "Generation of new use cases, tutorials and reference information for RoboComp"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2018/organizations/5504242315952128/"
    },
    "year_2019": {
      "num_projects": 10,
      "projects": [
        {
          "code_url": "https://jmagundezg.github.io/GSoC-2019-SwarmComm/",
          "description": "<p>Swarm robotics is an approach to the coordination of large numbers of robots in order to tackle a given task inspired by the observation of social animals and their behaviour, making individuals tasks to resolve group problems. My proposal to this idea is to implement examples of collective behaviors using swarm robotics strategies in new or old scenarios of the RoboComp RCIS simulator, like collective exploration of the scenario, patterns formation, morphogenesis or another collective activities. Also, there would be a verbal or non-verbal communication between the swarm components in order to send some commands to the crowd.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2019_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5439300831805440/",
          "proposal_id": null,
          "short_description": "Swarm robotics is an approach to the coordination of large numbers of robots in order to tackle a given task inspired by the observation of social...",
          "slug": "new-examples-and-scenarios-for-swarm-robotics-in-robocomp",
          "status": "completed",
          "student_name": "José Manuel Agúndez",
          "student_profile": null,
          "tags": [
            "ios"
          ],
          "title": "New examples and scenarios for swarm robotics in RoboComp"
        },
        {
          "code_url": "https://gist.github.com/elebarr/d98ee5c191b0cbccd45e7a93612159a7",
          "description": "<p>RoboComp is an open-source robotics framework that affords the tools to create software components. These components communicate through interfaces and can be generated and modified by the tool Robocompdsl.</p>\n<p>Components’ configuration and parameters are specified in a CDSL file, that is used by Robocompdsl to generate the component in one of the three possible languages: Python, C++, and C++11.</p>\n<p>Until now, these components could only be created executing the tool from the command line. The aim of this project is to develop Robocompdsl-gui, a graphical interface for Robocompdsl to make the user experience more enjoyable and to avoid programming errors.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2019_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5442187049828352/",
          "proposal_id": null,
          "short_description": "RoboComp is an open-source robotics framework that affords the tools to create software components. These components communicate through interfaces...",
          "slug": "robocompdsl-gui-a-graphical-interface-for-robocompdsl",
          "status": "completed",
          "student_name": "Elena Barranco",
          "student_profile": null,
          "tags": [
            "python",
            "ai",
            "ui"
          ],
          "title": "Robocompdsl-gui: a graphical interface for Robocompdsl"
        },
        {
          "code_url": "https://gist.github.com/t2shashwat/57c02f6c7002e712afc92b23299e654d",
          "description": "<p>Building an interactive robotic simulator in order to simulate the complex real world. As real worlds are dynamic in nature we need a simulator where these type of environment can be provided to the robot.</p>\n",
          "difficulty": "advanced",
          "id": "proj_robocomp_2019_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/4996884521811968/",
          "proposal_id": null,
          "short_description": "Building an interactive robotic simulator in order to simulate the complex real world. As real worlds are dynamic in nature we need a simulator where...",
          "slug": "interactive-rcis-project-proposal",
          "status": "completed",
          "student_name": "Shashwat Shrivastava",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "Interactive RCIS Project Proposal"
        },
        {
          "code_url": "https://github.com/Joanes04/serious-game-robocomp-GSOC",
          "description": "<p>My proposal aims to create a new component that allows to store the representation of the robot’s world over time, as well as query it. For this, it is necessary to store the graph structure used to represent the knowledge of the world that the robot possesses. In RoboComp, when robots need to perform complex tasks, its behaviour is based on missions. The mission begin from an initial state and through different transitions reaches a final state, that is, the robot completes the mission. The states are represented by a graph. \nMy proposal is to use a JSON structure to store this graph. This allows its storage as a collection of documents in MongoDB. Consequently, each document could represent a state of the robot. Also, this slot is intended to study the viability of Neo4J for this purpose, as far as I am concerned, the best option would be to use the polyglot persistence, that consists in to use the database best suited for the type of data, in our case MongoDB, and in to use the database best suited for the type of queries, in our case Neo4j. Specifically I think that Neo4j Doc Manager could be our best choice.</p>\n",
          "difficulty": "advanced",
          "id": "proj_robocomp_2019_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5004232925642752/",
          "proposal_id": null,
          "short_description": "My proposal aims to create a new component that allows to store the representation of the robot’s world over time, as well as query it. For this, it...",
          "slug": "storage-of-the-graph-based-world-representation-used-in-robocomp",
          "status": "completed",
          "student_name": "Alberto Andújar",
          "student_profile": null,
          "tags": [
            "ai",
            "database",
            "ui"
          ],
          "title": "Storage of the graph-based world representation used in RoboComp"
        },
        {
          "code_url": "https://medium.com/@nikhilbansal3456/gsoc-2019-final-report-of-robocomp-v-rep-integration-5442bfc6d3d3?source=friends_link&sk=849ff22ec790129a5bcfdb2f1df65d7b",
          "description": "<p>RoboComp’s existing simulator, RCIS, is based on OpenSceneGraph technology and custom made actuators and sensor. This project is to build prototypes of robotics simulation using V-REP and use its APIs to connect them to RoboComp ecosystem. Specifically, the project consists of implementing RoboComp omnirobot, joint motor, laser, RGBD interfaces and create a model of other  RoboComp’s robots in V-REP.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2019_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5371818305650688/",
          "proposal_id": null,
          "short_description": "RoboComp’s existing simulator, RCIS, is based on OpenSceneGraph technology and custom made actuators and sensor. This project is to build prototypes...",
          "slug": "testing-and-comparison-of-alternative-robotic-simulators",
          "status": "completed",
          "student_name": "Nikhil-Bansal",
          "student_profile": null,
          "tags": [
            "api",
            "ui"
          ],
          "title": "Testing and comparison of alternative robotic simulators"
        },
        {
          "code_url": "https://gist.github.com/liu-oryol/08e7632d81ae1e1bb70355ddb6c5af51",
          "description": "<p>The task of recognizing and predicting human daily activities is a trending topic nowadays,  and  a  lot  of  research  has  been  developed  around  it,  accompanied with the creation of algorithms that achieve state-of-the-art results on different human activity data sets: CAD-60 or CAD-120, UTKinect-Action, Florence3D-Action data sets, etc.  The application of a machine that can detect a person’s actions is broad.  It has been developed for gaming, Human-Computer interac-tion or Active and Assistive Living.</p>\n<p>For the development of RoboComp's framework, my work will be based on the article of Premebida, Souza and Faria (2017) where the proposed algorithm reached an accuracy of 94.74% and  a  recall  of  94.74  % on CAD-60, which is considered as a state-of-the-art result.  These articles are mainly based on Dynamic Bayesian Networks and a Dynamic Bayesian Mixture Model (Faria,Premebida,Nunes(2014)). Other works will be taken in account to take advantage of what we have available, combining machine learning approaches with mathematics to get robust results, such as the introduction of Partial Differential Equations or Lie groups, explained, for example, in Vemulapalli et al. (2014)</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2019_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/6201176222072832/",
          "proposal_id": null,
          "short_description": "The task of recognizing and predicting human daily activities is a trending topic nowadays,  and  a  lot  of  research  has  been  developed  around ...",
          "slug": "development-of-human-activity-recognition-component",
          "status": "completed",
          "student_name": "Liubove Orlov Savko",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Development of human activity recognition component"
        },
        {
          "code_url": "https://gist.github.com/adityaaggarwal97/4adbb90dd5aa9280d1ddbdc050e5db61",
          "description": "<p>Aim of this project is to develop a People Identification System with the following two capabilities.</p>\n<ol>\n<li>Given an image identify all the faces in it and return labels of identified people. </li>\n<li>Classify new persons and use incremental learning techniques to recognize it later.</li>\n</ol>\n<p>This component will allow for a more enriched interaction between robots and humans by enabling robots to make better decisions based on the input from different categories of people.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2019_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/4951617697218560/",
          "proposal_id": null,
          "short_description": "Aim of this project is to develop a People Identification System with the following two capabilities.\n\nGiven an image identify all the faces in it...",
          "slug": "people-identification-component-for-the-ebo-educational-robot",
          "status": "completed",
          "student_name": "Aditya Aggarwal",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "People identification component for the EBO educational robot"
        },
        {
          "code_url": "https://inajarrob.github.io/GSoC-2019-TextToSpeech/",
          "description": "<p>My project is based on the fact that the offline component to be created for EBO gives it the ability to speak through a TTS modulating the voice depending on their mood and also this contains a dictionary of phrases created by the child and thus offer the possibility that the robot has a wide range of phrases with which the child feels identified and that he does not have the obligation to specify a phrase whenever he wants to speak.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2019_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5950500120297472/",
          "proposal_id": null,
          "short_description": "My project is based on the fact that the offline component to be created for EBO gives it the ability to speak through a TTS modulating the voice...",
          "slug": "development-of-a-text-to-speech-component-that-operates-offline-for-the-ebo-educational-robot",
          "status": "completed",
          "student_name": "Isabel Najarro Borrego-1",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Development of a Text To Speech component that operates offline for the EBO educational robot"
        },
        {
          "code_url": "https://gist.github.com/Ronit-j/6768953b8076ce97a20ee2dc6d0dfa66",
          "description": "<p>Machines have been socially aware but the efforts to be put into making them socially aware or their behavior to be socially acceptable are tremendous. This is an effort in the same direction to make a machine more socially aware with the help of machine learning techniques using graph data. Graph data is better able to extract the semantics of the environment. This project focuses on the graphical representation of a scenario which helps us to derive the social acceptability score of a robot. Hence, using graph data coupled with the power of machine learning, this project is a step closer to social intelligence embedded in robots.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2019_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/6299515403894784/",
          "proposal_id": null,
          "short_description": "Machines have been socially aware but the efforts to be put into making them socially aware or their behavior to be socially acceptable are...",
          "slug": "learning-acceptable-social-behaviour-using-machine-learning-techniques",
          "status": "completed",
          "student_name": "Ronit Jorvekar",
          "student_profile": null,
          "tags": [],
          "title": "Learning acceptable social behaviour using machine learning techniques"
        },
        {
          "code_url": "https://mfedoseeva.github.io/GSOC19-har-project-robocomp/",
          "description": "<p>Understanding actions and interactions of humans from the RGB-D sensor input can significantly improve cognitive functions of robots and help safely and smoothly incorporate them in the world of humans. Human activity recognition component will thus be a significant addition to the functionality of RoboComp.\nHuman activity recognition in the video is an interesting and challenging task and recent research shows that there are different ways to address the spatial properties of human actions and their temporal dynamics. In the course of this  project I plan to start with the simpler LSTM architectures and iteratively  test and improve the model to achieve state-of-the art results on the selected datasets with the final goal of providing ready-to-use RoboComp components.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2019_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2019/projects/5145834843275264/",
          "proposal_id": null,
          "short_description": "Understanding actions and interactions of humans from the RGB-D sensor input can significantly improve cognitive functions of robots and help safely...",
          "slug": "development-of-a-human-activity-recognition-component",
          "status": "completed",
          "student_name": "Mariyam Fedoseeva",
          "student_profile": null,
          "tags": [],
          "title": "Development of a human activity recognition component"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2019/organizations/6183862000943104/"
    },
    "year_2020": {
      "num_projects": 10,
      "projects": [
        {
          "code_url": "https://github.com/notabee/GSoC20-Report/blob/master/Report.md",
          "description": "<p>Aim of this project is to introduce machine learning methods to learn about the surroundings for a robot’s navigation, we want to develop an agent which will learn all the corner cases and conditions which it needs, to properly navigate, without stating some predefined rules. The whole process of learning will be carried out by using the data it will get fed in such surroundings during real life scenarios. This project will be an expansion of the previous work “Learning socially acceptable behavior using machine learning techniques on graph data” (<a href=\"https://github.com/robocomp/sngnn\" target=\"_blank\">https://github.com/robocomp/sngnn</a>) in that project algorithms were developed to produce a single score for the robot to navigate, but it required high number of queries to work. This time we are aiming for generating these scores as a heatmap(such as the heat maps shown in <a href=\"https://ljmanso.com/sngnn\" target=\"_blank\">https://ljmanso.com/sngnn</a>) which can produce all the scores at once, this will be more efficient and faster than the previous work done. To solve this issue of generating all the scores at once we will try to generate a bitmap image using CNNs. As we are dealing with graphs of scenarios here we will be using GNNs.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2020_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/6595025401544704/",
          "proposal_id": null,
          "short_description": "Aim of this project is to introduce machine learning methods to learn about the surroundings for a robot’s navigation, we want to develop an agent...",
          "slug": "efficient-acceptable-social-behaviour-using-machine-learning-techniques",
          "status": "completed",
          "student_name": "Rishabh Baghel",
          "student_profile": null,
          "tags": [
            "ios",
            "ai",
            "ui"
          ],
          "title": "Efficient acceptable social behaviour using machine learning techniques"
        },
        {
          "code_url": "https://gist.github.com/jmi2k/4749fb0c63a053661bc85cf12aedabcc",
          "description": "<p>This project aims to endow <em>LearnBlock</em> with the ability to determine the different syntax-errors of a program and to display those errors in both, the visual program and the Block-Text code. Those parts of the code containing a syntax-error will be highlighted. In addition, information about the kind of error and some guidelines on how to correct will be displayed as long as the user asks for it (for instance, clicking on a highlighted statement or block).</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2020_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5719678351048704/",
          "proposal_id": null,
          "short_description": "This project aims to endow LearnBlock with the ability to determine the different syntax-errors of a program and to display those errors in both, the...",
          "slug": "syntax-error-highlighter-for-learnblock",
          "status": "completed",
          "student_name": "José Miguel Sánchez",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Syntax-error highlighter for LearnBlock"
        },
        {
          "code_url": "https://gist.github.com/DarkGeekMS/ab9abdad83d7f993f52f7f33d214be32",
          "description": "<p>The ability of a robot to detect, grasp and manipulate objects is one of the key challenges in building an intelligent humanoid robot. For a collaborative robot, dealing with objects is a key part of its job and its ability to manipulate objects starts with the accuracy of grasping. Intelligent control of a robotic arm to manipulate objects is based on detecting the object and understanding its pose. Precise 3D poses of the objects are necessary to achieve a successful grasp on the objects. We can use the available data from the surrounding environment to recognize the objects poses. In our environment, the data provided will be RGBD frames. Recent work in Deep Learning has achieved amazing results in the problem of 3d pose estimation using RGBD data.</p>\n<p>In this project, we will work to integrate a pose estimation component to RoboComp using some state-of-art work in Deep Learning. The output poses will be visualized in V-REP simulator and used to drive the new Kinova Gen3 arm, in order to precisely grasp and manipulate some objects.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2020_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5455125545484288/",
          "proposal_id": null,
          "short_description": "The ability of a robot to detect, grasp and manipulate objects is one of the key challenges in building an intelligent humanoid robot. For a...",
          "slug": "dnns-for-precise-manipulation-of-household-objects",
          "status": "completed",
          "student_name": "Mohamed Shawky",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "DNN’s for precise manipulation of household objects"
        },
        {
          "code_url": "https://github.com/rahulkatiyar19955/gsoc-gui-dev/blob/master/report.md",
          "description": "<p>This Graphical User Interface is responsible for the Robot's controlling and monitoring. This uses CORTEX architecture which is a cognitive robotics architecture and communicate through a graph structure called Deep State Representation (DSR).</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2020_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5247158732718080/",
          "proposal_id": null,
          "short_description": "This Graphical User Interface is responsible for the Robot's controlling and monitoring. This uses CORTEX architecture which is a cognitive robotics...",
          "slug": "robocomp-gui-development",
          "status": "completed",
          "student_name": "Rahul Katiyar",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "Robocomp GUI development"
        },
        {
          "code_url": "https://gist.github.com/Kanav-7/5cbe51c3575fa44debb5705fa0597900",
          "description": "<p>One of the capabilities of the robot is to efficiently communicate with humans, either through voice or gestures. Currently, EBO is equipped with components that enable it to perform social tasks like face detection, emotion recognition, people identification, etc. The aim of this project is to add upon the existing functionalities by integrating a ‘Hand Gesture Recognition Component’. Hand Gestures are very significant for human-robot interaction. This component can be used as a tool to enable communication between robots and humans. Furthermore, this component will enable the robot to understand American Sign Language (ASL), which will be a really efficient way of communication.</p>\n<p>RoboComp is also working on the Human Activity Recognition project. Hand Gestures are a key component in both natural and social human activities. This component when integrated with the Human Activity Recognition Component can be used for various use cases (like detecting commands given by hands), which adds value to this project.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2020_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5310102854172672/",
          "proposal_id": null,
          "short_description": "One of the capabilities of the robot is to efficiently communicate with humans, either through voice or gestures. Currently, EBO is equipped with...",
          "slug": "hand-gesture-recognition-component",
          "status": "completed",
          "student_name": "Kanav",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Hand Gesture Recognition Component"
        },
        {
          "code_url": "https://gist.github.com/palash16/50ce44d356cdbf44dc82586389c8cd97",
          "description": "<p>We are living in a world where a cognitive robot can act as a human assistant and has the potential to offer social experiences through human-robot interactions. To foster this coexistence, a robot should be able to infer human emotions allowing for a more meaningful and enriched interaction between robots and humans. This project aims to design an emotion recognition component which will help establish an affective loop between humans and robots.</p>\n<p>In order to achieve this I plan to benchmark the well-known publicly available state-of-the-art image and video datasets for classical machine learning algorithms and deep learning based approaches. Based on my observations and evaluation metrics I propose to integrate a trained model with the emotion recognition component in the robocomp codebase.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2020_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/6493455699673088/",
          "proposal_id": null,
          "short_description": "We are living in a world where a cognitive robot can act as a human assistant and has the potential to offer social experiences through human-robot...",
          "slug": "integration-of-an-emotion-recognition-component-in-robocomp",
          "status": "completed",
          "student_name": "Palash Agarwal",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Integration of an emotion recognition component in RoboComp"
        },
        {
          "code_url": "https://github.com/robocomp/robocomp-aston/tree/master/components/detection/HumanIdentification",
          "description": "<p>In Robotics, it is crucial to identify humans and efficiently distinguish them. This gives the ability to perform further challenging tasks such as personalized interactions, social navigation and surveillance. Currently, Robocomp only uses face recognition for human identification. The aim of this project is to integrate other modalities, such as rgb image, skeleton-based pose and silhouette of the body. Using these modalities various human identification components, namely gait recognition and person re-identification, will be integrated into Robocomp</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2020_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/4939459423895552/",
          "proposal_id": null,
          "short_description": "In Robotics, it is crucial to identify humans and efficiently distinguish them. This gives the ability to perform further challenging tasks such as...",
          "slug": "human-recognition-identification-using-multi-modal-perception-system",
          "status": "completed",
          "student_name": "Shubh Maheshwari",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Human recognition (identification) using multi-modal perception system"
        },
        {
          "code_url": "https://github.com/RishiGondkar/GSoC-2020/blob/master/report.md",
          "description": "<p>The navigation of a robot in an environment with humans is a subject with enormous interest in the last years. To be accepted in these types of scenarios, it is important that the robot navigate respecting social norms, for example, avoiding getting too close to humans, avoiding interrupting a conversation or asking permission to pass through a blocked path. This project aims to describe the dialogue manager, besides the corpus that allows establishing dialogues between the robot and the humans in real situations to improve the behavior of the robot navigation system, making it more socially accepted. The dialogue manager will be a RoboComp agent, which reads information from the robot’s world representation (a graph) and adapts the conversation to the current situation (e.g, according to the age of people, genre, etc).</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2020_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/6266448592240640/",
          "proposal_id": null,
          "short_description": "The navigation of a robot in an environment with humans is a subject with enormous interest in the last years. To be accepted in these types of...",
          "slug": "human-robot-dialogue-and-collaboration-for-social-navigation",
          "status": "completed",
          "student_name": "Rishi Gondkar",
          "student_profile": null,
          "tags": [
            "ios",
            "ai"
          ],
          "title": "Human-robot dialogue and collaboration for social navigation."
        },
        {
          "code_url": "https://gist.github.com/ksakash/e3ea536981d9c8ab88c98766ff41d04b",
          "description": "<p>C++ as a programming language comes in handy in case of performance oriented applications for example: a simulator. But when it comes to rapidly prototyping of applications and ease of use of APIs, it lags behind other languages like python which is one of the most widely used languages just because of this reason and also due to the plethora of libraries that it provides. So, binding the C++ APIs and exposing them to the python interface can be helpful in extending the use of innermodel lib to beginner developers with minimal knowledge of programming. By exposing C++ APIs to python we are achieving two things at the same time: getting the performance from C++ and ease of use through python, which can also increase contributions from the dev community and later help in the development of innermodel lib or robocomp in general.</p>\n",
          "difficulty": "beginner",
          "id": "proj_robocomp_2020_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5194611217137664/",
          "proposal_id": null,
          "short_description": "C++ as a programming language comes in handy in case of performance oriented applications for example: a simulator. But when it comes to rapidly...",
          "slug": "python3-bindings-for-innermodel-library",
          "status": "completed",
          "student_name": "Akash Kumar Singh",
          "student_profile": null,
          "tags": [
            "python",
            "api"
          ],
          "title": "Python3 bindings for InnerModel Library"
        },
        {
          "code_url": "https://niveditarufus.github.io/",
          "description": "<p>Humans and robots coexist together in today's world and to make these interactions more meaningful, one of the capacities that a robot must certainly perform is to understand the people it is interacting with human beings, and sometimes the knowledge of how many people the robot needs to interact with becomes crucial information. The aim of this project is to add upon the existing functionalities of the ‘People Counter’ in the ‘Human Detection Component’ allowing a more enriched interaction between robots and humans. This will allow the robot to make better decisions based on the density of people present in the area.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2020_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2020/projects/5202658475900928/",
          "proposal_id": null,
          "short_description": "Humans and robots coexist together in today's world and to make these interactions more meaningful, one of the capacities that a robot must certainly...",
          "slug": "software-agent-for-estimating-occupancy-in-medium-and-large-buildings-using-rgb-cameras",
          "status": "completed",
          "student_name": "Nivedita Rufus",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Software agent for estimating occupancy in medium and large buildings using RGB cameras"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2020/organizations/6622081011154944/"
    },
    "year_2021": {
      "num_projects": 10,
      "projects": [
        {
          "code_url": "https://github.com/Estox/GSoC2021-Webots-Integration",
          "description": "<p>This is a proposal for no. 15 project idea - \"Webots integration with RoboComp\".\nAs the title indicates, the project aims at integrating RoboComp with Webots and making it possible to open simulations created in RoboComp on Webots simulator.\nTo achieve it we need to get very good understanding of the .proto and .wbt extensions made in Webots and somehow reconstruct the logic from RoboComp to make it understandable for Webots. We can do that using Python classes and objects to interact between the files and programs.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2021_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/6639022675329024/",
          "proposal_id": null,
          "short_description": "This is a proposal for no. 15 project idea - \"Webots integration with RoboComp\".\nAs the title indicates, the project aims at integrating RoboComp...",
          "slug": "webots-integration",
          "status": "completed",
          "student_name": "Kacper Kujawski",
          "student_profile": null,
          "tags": [
            "python",
            "web",
            "ai"
          ],
          "title": "Webots integration"
        },
        {
          "code_url": "https://gist.github.com/rongtuech/e23d9293186f6f0563ccba77d559d899",
          "description": "<p>The main topic can be divided into two parts:</p>\n<p>+Body and hand detection:  I apply the lightweight Openpose model, MediaPipe library, and the optical flow algorithm. The combination can process in real-time and with a lightweight model, so it is suitable for edge devices.</p>\n<p>+Gesture recognition: There are two main approaches for this problem: image-appearance-based models and pose-based models. These two are different in types of input data. The first approach's input is only images, while the second one's input is extracted poses from photos.</p>\n<p>+Extension: Currently, the robot can only learn the gesture from the predefined patterns, which appear in the training data. However, the training dataset is not always available for all motions. Therefore, by applying some unsupervised techniques, the robot can recognize some gestures without any supervised dataset.</p>\n<p>In this project: Four components will be published: BodyHandJointsDetector, ImageBaseGesture-Recognition, PoseBasedGestureRecognition, and UnsupervisedGestureRecognition. I will also code the testing client for each approach.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2021_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5691934034624512/",
          "proposal_id": null,
          "short_description": "The main topic can be divided into two parts:\n+Body and hand detection:  I apply the lightweight Openpose model, MediaPipe library, and the optical...",
          "slug": "sign-language-recognition",
          "status": "completed",
          "student_name": "Trung Ngo Tan",
          "student_profile": null,
          "tags": [
            "api",
            "ai",
            "ui"
          ],
          "title": "Sign Language Recognition"
        },
        {
          "code_url": "https://github.com/robocomp/sngnn/tree/master/SNGNN-RL",
          "description": "<p>With the advent of Machine Learning, one can learn such heuristics and use them as cost functions in conventional path planners. SNGNN-1D is one such Graph Neural Network based Machine Learning algorithm which evaluates the static scenes generated randomly from the point of view of the robot. In short, it outputs a score between 0-100 which shows how good the robot’s position is with respect to its surroundings. This score, for every state in the room, is used to generate a heat map that is used by A* algorithm to plan a path to the goal position. The problem with this implementation is that it is computationally expensive and is relatively slow, also SNGNN has been trained using static scenes and does not factor in dynamic settings for example, walking humans, which is a very common scenario in a social setting. A more cost effective way to carry out this task would be to train a policy to reach the goal. However, it is difficult to structure a reward function for complex environments. In such cases, Reinforcement Learning is a promising pursuit that can make use of SNGNN-1D as a reward function because it scores the robot’s presence in the room with respect to its surroundings.</p>\n",
          "difficulty": "advanced",
          "id": "proj_robocomp_2021_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5472062881136640/",
          "proposal_id": null,
          "short_description": "With the advent of Machine Learning, one can learn such heuristics and use them as cost functions in conventional path planners. SNGNN-1D is one such...",
          "slug": "improvement-of-a-social-navigation-component",
          "status": "completed",
          "student_name": "Aditya Kapoor",
          "student_profile": null,
          "tags": [
            "ml",
            "ai",
            "ui"
          ],
          "title": "Improvement of a Social Navigation component"
        },
        {
          "code_url": "https://alexfdez1010.github.io/web/GSOC2021",
          "description": "<p>Implementing a neural network with transfer learning for a new component of object detection in LearnBlock</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2021_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5487554727510016/",
          "proposal_id": null,
          "short_description": "Implementing a neural network with transfer learning for a new component of object detection in LearnBlock",
          "slug": "an-object-detection-component-for-learnblock",
          "status": "completed",
          "student_name": "Alejandro Fernández",
          "student_profile": null,
          "tags": [],
          "title": "An object detection component for LearnBlock"
        },
        {
          "code_url": "https://github.com/dev-kasibhatla/gsoc-conversationalAgent",
          "description": "<p>Interaction of a robot with the operator (human) is an important and daunting task. The aim of this project would be to create a clean, modern and modular Graphical User Interface (GUI) for the conversationalAgent component of RoboComp Viriato. The desktop application will be written using the Electron framework. The app would support one or more open source free to use Text to Speech engines like Mimic or MaryTTS. Combining such a TTS engine with a translation engine can enable the robot to converse in any of the given languages with the user.\nLeveraging various conversational skills provided by the chosen TTS engine like Mycroft’s Mimic (for example, intents, statements, prompts, confirmations, conversational context) can further help make the conversation feel more real and closer to an actual human conversation.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2021_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5078415975120896/",
          "proposal_id": null,
          "short_description": "Interaction of a robot with the operator (human) is an important and daunting task. The aim of this project would be to create a clean, modern and...",
          "slug": "graphical-user-interface-for-affective-human-robot-interactions",
          "status": "completed",
          "student_name": "Aditya Kasibhatla",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Graphical-User Interface for affective human-robot interactions"
        },
        {
          "code_url": "https://github.com/robocomp/robocomp-robolab/tree/master/components/detection/trafficMonitoringInOutdoorEnv",
          "description": "<p>In today’s world, a lot of educated decisions are made using the information collected by robots and are aided by the inferences given by the software agents which make use of the information collected by the other machines and robots. One such crucial field, where the software agents can contribute is “Pedestrian and Vehicle Traffic Monitoring”, where they can help us identify the hotspots and conflict zones like Pedestrian Crossings, Traffic Signals, Traffic jams, etc. The aim of this project will be to achieve this by using detection networks and depth networks or localisation/pose estimation networks or by building upon the existing functionalities  like “peopleCounter_SSDCNet” components already present in the robocomp repository. Through this, the information provided by machines like RGB cameras can be exploited maximally to make better decisions based on the density of people and vehicles present in an area.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2021_006",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/6247686998589440/",
          "proposal_id": null,
          "short_description": "In today’s world, a lot of educated decisions are made using the information collected by robots and are aided by the inferences given by the...",
          "slug": "software-agent-for-traffic-and-pedestrian-traffic-monitoring-in-outdoor-environments-using-rgb-cameras",
          "status": "completed",
          "student_name": "Amarthya Sasi Kiran",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Software agent for traffic and pedestrian traffic monitoring in outdoor environments using RGB cameras."
        },
        {
          "code_url": "https://github.com/Yasmin-Hesham/optimizer",
          "description": "<p>The field of Model Predictive Control (MPC) has seen tremendous progress. The algorithms and high-level software available to solve challenging nonlinear optimal control problems are significantly used\nin mobile robots to optimize in real-time their path following and navigation. In order to solve Non-Linear Programming Problems (NLP) – which is considered the general form –, we will use CasADi, an open-source tool to solve non-linear optimization problems. Also, the robot should be able to avoid obstacles in real-time by taking\ninto consideration some constraints and penalizing the control values. In practice, previous maps and laser values are combined to create a list of convexified obstacle-free regions. To comply with the real-time requirements of a physical robot, the algorithm will be able to adapt – also in real-time –to the current situation by trading off between execution time and the number of constraints.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2021_007",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/4888220159967232/",
          "proposal_id": null,
          "short_description": "The field of Model Predictive Control (MPC) has seen tremendous progress. The algorithms and high-level software available to solve challenging...",
          "slug": "simultaneous-path-planning-and-following-using-model-predictive-control-spaf",
          "status": "completed",
          "student_name": "Yassmin Hesham",
          "student_profile": null,
          "tags": [
            "mobile",
            "ai",
            "ui"
          ],
          "title": "Simultaneous path planning and following using Model Predictive Control (SPAF)"
        },
        {
          "code_url": "https://docs.google.com/document/d/1mqUB373x1gFD2RtUp0wUqp7JwJnOpD3xQP4l9MixEos/edit?usp=sharing",
          "description": "<p>AGM (Active Grammar-based Modeling) is a Project with the objective of proposing a detailed description of how the software modules of the robots can interact with each other, and a world model structure. AGM was designed on Python2, and now Robolab, the organization to which I am proposing this project, wants to port it to Python 3. These would be the main objective of this project, to port AGM from Python 2 to Python 3.</p>\n<p>This objective requires two very different parts:</p>\n<p>The first part is the port from Python 2 to Python 3 in itself. This means the changing of the code to adapt AGM to the new version of Python. However, this alone is not enough.</p>\n<p>The second part is testing. Tests are required to check if the program is working as it is supposed to work. On programs like these, it is very important to run tests to assure that each part is ported correctly. If tests are not run, there is a risk that certain parts of the code not commonly used do not work correctly or return errors. In short, the objective of this part of the project is to effectively test the program to assure that the port is working correctly. Coverage is a part of this process too, so we also need to do it.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2021_008",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5168969689858048/",
          "proposal_id": null,
          "short_description": "AGM (Active Grammar-based Modeling) is a Project with the objective of proposing a detailed description of how the software modules of the robots can...",
          "slug": "port-of-agm-from-python-2-to-python-3",
          "status": "completed",
          "student_name": "Fernando Martin",
          "student_profile": null,
          "tags": [
            "python",
            "ai",
            "ui"
          ],
          "title": "Port of AGM from Python 2 to Python 3"
        },
        {
          "code_url": "https://github.com/robocomp/robocomp-robolab/tree/master/components/detection/DetectingElements",
          "description": "<p>The detection of risk situations during the navigation of mobile robots is an essential task for future applications. The goal is to create a software agent in Robocomp with the aim of improving vehicle driving, using deep learning and computer vision techniques.</p>\n<p>The main idea is to use one or several RGB cameras placed in a vehicle for lane detection, pedestrian detection, vehicle detection, sign detection and more elements that affect driving. To perform this task, it is possible to work either with real datasets of cameras placed in vehicles or to use the Carla vehicle driving simulator.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2021_009",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5189931814617088/",
          "proposal_id": null,
          "short_description": "The detection of risk situations during the navigation of mobile robots is an essential task for future applications. The goal is to create a...",
          "slug": "computer-vision-for-detecting-elements-of-a-vehicles-environment-with-robocomp",
          "status": "completed",
          "student_name": "Garv Tambi",
          "student_profile": null,
          "tags": [
            "mobile",
            "ai"
          ],
          "title": "Computer vision for detecting elements of a vehicle’s environment with RoboComp"
        },
        {
          "code_url": "https://gist.github.com/vaibhawkhemka/1b832b198ebffed607804238d2d1cee4",
          "description": "<p>Depth Estimation is one of the attractive research areas in computer vision. The motivation of this project is to estimate depth without the use of LIDAR sensors or other related costly setups. And it also makes the robot more robust and efficient to carry out any task.</p>\n",
          "difficulty": null,
          "id": "proj_robocomp_2021_010",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2021/projects/5196785273798656/",
          "proposal_id": null,
          "short_description": "Depth Estimation is one of the attractive research areas in computer vision. The motivation of this project is to estimate depth without the use of...",
          "slug": "monocular-depth-estimation-from-rgb-signals",
          "status": "completed",
          "student_name": "Vaibhaw Khemka",
          "student_profile": null,
          "tags": [],
          "title": "Monocular Depth Estimation from RGB signals"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2021/organizations/6285571999137792/"
    },
    "year_2022": {
      "num_projects": 5,
      "projects": [
        {
          "code_url": "https://github.com/robocomp/robocomp-pick-and-place/tree/dani_branch",
          "description": "Reinforcement learning is an established discipline for the automatic acquisition of control programs from a reward signal. Some early limitations arising from the necessary limited dimension of sensor spaces have been overcome with the integration of DNN as efficient reducers of large input data. In this project we want to apply RL as an online method to improve an existing grasping algorithm. Using a Kinova Gen3 arm simulated in CoppeliaSIm, that already performs a pick and place operation using a gripper with multiple force and distance sensors, the goal is to improve the current grasping performance by running RL algorithms that learn from the existing algorithm and, eventually, replace it to continue is adaptation to the specificities of the environment. If the experiments proceeds as expected, a second stage will try to transfer the learned controller to the grasping of a new target object in the scene, for example, from a block to a cup. All the experiments will be performed with RoboComp’s robotics cognitive architecture CORTEX, and the tools and existing agents already developed and tested.",
          "difficulty": null,
          "id": "proj_robocomp_2022_001",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/jJ8o0Wpc/",
          "proposal_id": null,
          "short_description": "Reinforcement learning is an established discipline for the automatic acquisition of control programs from a reward signal. Some early limitations...",
          "slug": "reinforcement-learning-for-pick-and-place-operations",
          "status": "completed",
          "student_name": "Daniel Peix",
          "student_profile": null,
          "tags": [
            "ui"
          ],
          "title": "Reinforcement Learning for pick and place operations"
        },
        {
          "code_url": "https://github.com/robocomp/gsoc22-socnavenv",
          "description": "Socially aware path planning enables a robot to navigate through a crowded environment causing the least amount of discomfort to the surrounding people. Building upon the work done in GSoC '21, the aim of the project is to account for the interactions between the different entities in the environment by adding interaction nodes between entities in the graph representation. A way in which the robot can also come up with interaction nodes would also be looked into.Finally, the project also aims to compare SNGNN-RL's performance with the current baseline.",
          "difficulty": null,
          "id": "proj_robocomp_2022_002",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/So3JrqTr/",
          "proposal_id": null,
          "short_description": "Socially aware path planning enables a robot to navigate through a crowded environment causing the least amount of discomfort to the surrounding...",
          "slug": "extending-the-social-navigation-component-to-realistic-scenarios",
          "status": "completed",
          "student_name": "Sushant Sreeram Swamy",
          "student_profile": null,
          "tags": [
            "ios",
            "ai",
            "ui"
          ],
          "title": "Extending the Social Navigation component to realistic scenarios"
        },
        {
          "code_url": "https://kaustabpal.github.io/gsoc_22_report",
          "description": "I am proposing the use of Convex Inner Approximations to plan the trajectories. The Convex Inner Approximation method finds kinodynamically feasible trajectories that guarantees collision avoidance. It also finds the trajectories in fewer iterations and as a result is much faster than traditional obstacle avoidance constraints.",
          "difficulty": null,
          "id": "proj_robocomp_2022_003",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/Ci8WKoJ7/",
          "proposal_id": null,
          "short_description": "I am proposing the use of Convex Inner Approximations to plan the trajectories. The Convex Inner Approximation method finds kinodynamically feasible...",
          "slug": "model-predictive-control-for-obstacle-avoidance",
          "status": "completed",
          "student_name": "Kaustab Pal",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Model Predictive Control for obstacle avoidance"
        },
        {
          "code_url": "https://github.com/swatidantu/DSR_ASMC",
          "description": "Self-adaptation is a key ability for future autonomous robots. Thanks to this capability, a robot is able to automatically adapt to changes during its operation. In the case of autonomous navigation, if the robot is endowed with this skill, it can automatically adjust a set of free parameters to improve its functioning given a cost function or metric. The effect of this adaptation is safer, more efficient, and, possibly, better socially aware navigation. The aim of this project would be to design and implement a sliding variable based adaptive controller that can self-adapt under varying circumstances. Through this the robot would be able to successfully navigate and self adapt under social constraints as well if required.",
          "difficulty": null,
          "id": "proj_robocomp_2022_004",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/dWqGmh50/",
          "proposal_id": null,
          "short_description": "Self-adaptation is a key ability for future autonomous robots. Thanks to this capability, a robot is able to automatically adapt to changes during...",
          "slug": "self-adaptive-controller-for-path-following",
          "status": "completed",
          "student_name": "Swati Dantu",
          "student_profile": null,
          "tags": [
            "ai",
            "ui"
          ],
          "title": "Self-Adaptive controller for path following"
        },
        {
          "code_url": "https://github.com/robocomp/robocomp-pick-and-place/tree/sac_her",
          "description": "The aim of the project is to train a optimal controller using Deep Reinforcement Learning for pick and place operations. The agent improves from a existing grasping policy by learning and finetuning online using RL. This can be achieved using a couple of ways: 1) Behaviour Cloning and then finetuning the pretrained model online 2) Using an Offline RL algorithm like Conservative Q-Learning(CQL). Once an optimal controller is developed, this policy will be trained again to grasp a new object using Transfer Learning.",
          "difficulty": null,
          "id": "proj_robocomp_2022_005",
          "mentor_names": [],
          "project_url": "https://summerofcode.withgoogle.com/archive/2022/projects/XJDzk1aT/",
          "proposal_id": null,
          "short_description": "The aim of the project is to train a optimal controller using Deep Reinforcement Learning for pick and place operations. The agent improves from a...",
          "slug": "reinforcement-learning-for-pick-and-place-operations",
          "status": "completed",
          "student_name": "Vamsi Anumula",
          "student_profile": null,
          "tags": [
            "ai"
          ],
          "title": "Reinforcement Learning for pick and place operations"
        }
      ],
      "projects_url": "https://summerofcode.withgoogle.com/archive/2022/organizations/robocomp/"
    },
    "year_2023": null,
    "year_2024": null,
    "year_2025": null
  },
  "first_time": false,
  "contact": {
    "email": "pbustosgarciadecastro@gmail.com",
    "guide_url": null,
    "ideas_url": null,
    "irc_channel": "https://gitter.im/robocomp/robocomp/robocomp-gsoc",
    "mailing_list": "https://gitter.im/robocomp/robocomp/robocomp-gsoc"
  },
  "social": {
    "blog": "https://robocomp.github.io/web/blog/index",
    "discord": null,
    "facebook": null,
    "github": null,
    "gitlab": null,
    "instagram": null,
    "linkedin": null,
    "mastodon": null,
    "medium": null,
    "reddit": null,
    "slack": null,
    "stackoverflow": null,
    "twitch": null,
    "twitter": null,
    "youtube": null
  },
  "meta": {
    "version": 1,
    "generated_at": "2026-01-25T15:28:54.116Z"
  }
}